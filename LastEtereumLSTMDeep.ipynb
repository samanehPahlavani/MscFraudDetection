{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/samanehPahlavani/MscFraudDetection/blob/main/LastEtereumLSTMDeep.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8C0gi-ouCuyy"
      },
      "source": [
        "# Connect Google Drive For Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "TnT44zOYCvsY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85f870ed-fb53-43b5-931a-4b65f91f2cd5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U_LiaLFyCz2Y"
      },
      "source": [
        "#Libraries\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "g38JUFNsNffx"
      },
      "outputs": [],
      "source": [
        "####Libraries Import\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import os\n",
        "\n",
        "%matplotlib inline\n",
        "import sklearn\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.over_sampling import RandomOverSampler\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "EebzlEOoPIQn"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "from sklearn.model_selection import StratifiedKFold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "7cvVXdoHMgCq"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression # for Logistic Regression Algorithm\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "GY3_rgI6YLiJ"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.svm import SVR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "JBCJ9U8eMjtp"
      },
      "outputs": [],
      "source": [
        "from sklearn import metrics # for checking the model accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "k2wy9jCTOLbb"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import cross_val_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "g56ZnvPVUER-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b57ba065-683d-4c67-bcf5-51adfdaab942"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas_ml in /usr/local/lib/python3.10/dist-packages (0.6.1)\n",
            "Requirement already satisfied: pandas>=0.19.0 in /usr/local/lib/python3.10/dist-packages (from pandas_ml) (1.5.3)\n",
            "Requirement already satisfied: enum34 in /usr/local/lib/python3.10/dist-packages (from pandas_ml) (1.1.10)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.19.0->pandas_ml) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.19.0->pandas_ml) (2023.4)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.19.0->pandas_ml) (1.25.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas>=0.19.0->pandas_ml) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install pandas_ml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "jWDU5PrOZQaG"
      },
      "outputs": [],
      "source": [
        "# Import the necessary libraries\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "jPgfSJ2bJ0OW"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, cohen_kappa_score\n",
        "from sklearn.model_selection import train_test_split, KFold"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time"
      ],
      "metadata": {
        "id": "MKgdfRpW0y_Z"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4f8O4rioDCxX"
      },
      "source": [
        "# Functions Def"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Yc0vpXMON1HI"
      },
      "outputs": [],
      "source": [
        "def LoadData(data):\n",
        "  warnings.filterwarnings('ignore')\n",
        "  pd.options.display.max_columns = None\n",
        "  pd.options.display.max_rows = None\n",
        "  df = pd.read_csv(os.path.join(\"/content/drive/MyDrive/EtherFirstDataSet/\", data+\".csv\"))\n",
        "  return df\n",
        "#Load datas\n",
        "def preprocessing():\n",
        "\n",
        "  df1 = LoadData(str(1))\n",
        "  df2 = LoadData(str(2))\n",
        "\n",
        "  df1_fillna = df1.copy()\n",
        "  df2_fillna = df2.copy()\n",
        "\n",
        "  #Drop Most None Related Value Features\n",
        "  df1_fillna.drop([\"ERC20_uniq_rec_token_name\",\"ERC20_uniq_sent_token_name\",\"ERC20_avg_val_sent\",\"ERC20_max_val_sent\",\"ERC20_min_val_sent\",\"ERC20_avg_val_rec\",\"ERC20_max_val_rec\",\"ERC20_min_val_rec\",\"ERC20_uniq_rec_contract_addr\",\"ERC20_uniq_sent_addr_1\",\"ERC20_uniq_sent_addr\",\"ERC20_total_Ether_sent_contract\",\"ERC20_total_ether_sent\",\"ERC20_total_Ether_received\",\"ERC20_most_rec_token_type\",\"ERC20_most_sent_token_type\"], axis=1, inplace=True)\n",
        "  df1_fillna.drop([\"ERC20_uniq_rec_addr\",\"Total_ERC20_tnxs\",\"Time_Diff_between_first_and_last_Mins\",\"total_ether_sent_contracts\"], axis=1, inplace=True)\n",
        "  df2_fillna.drop([\"minTimeBetweenSentTnx\",\"maxTimeBetweenSentTnx\",\"minTimeBetweenRecTnx\",\"maxTimeBetweenRecTnx\",\"lifetime\",\"activityDays\",\"dailyMax\",\"ratioRecSent\",\"ratioSentTotal\",\"ratioRecTotal\",\"giniSent\",\"giniRec\",\"txFreq\",\"stdBalanceEth\"], axis=1, inplace=True)\n",
        "\n",
        "  #Rename Columns\n",
        "  selected_columns = [\"address\",\"flag\",\"avgTimeBetweenRecTnx\",\"avgTimeBetweenSentTnx\",\"sentTransactions\" ,\"receivedTransactions\", \"createdContracts\" ,\"Average_of_numUniqRecAddress\" ,\"Average_of_numUniqSentAddress\"\n",
        "  ,\"minValReceived\"\n",
        "  ,\"maxValReceived\"\n",
        "  ,\"avgValReceived\"\n",
        "  , \"minValSent\"\n",
        "  , \"maxValSent\"\n",
        "  ,\"avgValSent\"\n",
        "  ,\"totalTransactions\"\n",
        "  ,\"totalEtherSent\"\n",
        "  ,\"totalEtherReceived\"\n",
        "  ,\"totalEtherBalance\"    ]\n",
        "\n",
        "  df2_fillna = df2[selected_columns].copy()\n",
        "\n",
        "  df2_fillna.columns = [\"Address\"\n",
        "  ,\"FLAG\"\n",
        "  ,\"Avg_min_between_received_tnx\"\n",
        "  ,\"Avg_min_between_sent_tnx\"\n",
        "  ,\"Sent_tnx\"\n",
        "  ,\"Received_Tnx\"\n",
        "  ,\"Number_of_Created_Contracts\"\n",
        "  ,\"Average_of_Unique_Received_From_Addresses\"\n",
        "  ,\"Average_of_Unique_Sent_To_Addresses\"\n",
        "  ,\"min_value_received\"\n",
        "  ,\"max_value_received \"\n",
        "  ,\"avg_val_received\"\n",
        "  ,\"min_val_sent\"\n",
        "  ,\"max_val_sent\"\n",
        "  ,\"avg_val_sent\"\n",
        "  ,\"total_transactions_including_tnx_to_create_contract\"\n",
        "  ,\"total_Ether_sent\"\n",
        "  ,\"total_ether_received\"\n",
        "  ,\"total_ether_balance\"\n",
        "  ]\n",
        "\n",
        "  merged_df = pd.merge(df1_fillna, df2_fillna, how='outer')\n",
        "  df_filtered = merged_df.drop_duplicates(subset='Address', keep='first')\n",
        "  return df_filtered\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "qAZ3JtKZO8RO"
      },
      "outputs": [],
      "source": [
        "def scaled(data):\n",
        "  # Convert categorical 'FLAG' to numeric\n",
        "  label_encoder = LabelEncoder()\n",
        "  data['FLAG'] = label_encoder.fit_transform(data['FLAG'])\n",
        "\n",
        "  # Splitting the data into features (X) and labels (y)\n",
        "  X =  data.drop(['FLAG'], axis=1)\n",
        "  y = data['FLAG']\n",
        "\n",
        "  # Standardize features\n",
        "  scaler = StandardScaler()\n",
        "  X_scaled = scaler.fit_transform(X)\n",
        "  #X_scaled['FLAG'] = y\n",
        "\n",
        "\n",
        "  return X_scaled,y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "JTT6oBABCzlX"
      },
      "outputs": [],
      "source": [
        "def undersampling(data, target_column):\n",
        "    # Separate features and target variable\n",
        "    X = data.drop(target_column, axis=1)\n",
        "    y = data[target_column]\n",
        "\n",
        "    # Apply undersampling\n",
        "    undersampler = RandomUnderSampler()\n",
        "    X_resampled, y_resampled = undersampler.fit_resample(X, y)\n",
        "\n",
        "    # Get indices of selected samples\n",
        "    selected_indices = undersampler.sample_indices_\n",
        "\n",
        "    # Get indices of unselected samples\n",
        "    unselected_indices = np.setdiff1d(np.arange(len(X)), selected_indices)\n",
        "\n",
        "    # Extract unselected samples\n",
        "    X_unselected = X.iloc[unselected_indices]\n",
        "    y_unselected = y.iloc[unselected_indices]\n",
        "\n",
        "    # Combine unselected data into a DataFrame\n",
        "    unselected_data = pd.concat([X_unselected, y_unselected], axis=1)\n",
        "    resampled = pd.concat([X_resampled, y_resampled], axis=1)\n",
        "    return resampled, unselected_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "R372OqcfDl1l"
      },
      "outputs": [],
      "source": [
        "def oversampling(data, target_column):\n",
        "    # Separate features and target variable\n",
        "    X = data.drop(target_column, axis=1)\n",
        "    y = data[target_column]\n",
        "\n",
        "    # Apply oversampling\n",
        "    oversampler = RandomOverSampler()\n",
        "    X_resampled, y_resampled = oversampler.fit_resample(X, y)\n",
        "\n",
        "    # Get indices of selected samples\n",
        "    selected_indices = oversampler.sample_indices_\n",
        "\n",
        "    # Get indices of unselected samples\n",
        "    unselected_indices = np.setdiff1d(np.arange(len(X)), selected_indices)\n",
        "\n",
        "    # Extract unselected samples\n",
        "    X_unselected = X.iloc[unselected_indices]\n",
        "    y_unselected = y.iloc[unselected_indices]\n",
        "\n",
        "    # Combine unselected data into a DataFrame\n",
        "    unselected_data = pd.concat([X_unselected, y_unselected], axis=1)\n",
        "    resampled = pd.concat([X_resampled, y_resampled], axis=1)\n",
        "\n",
        "    return resampled, unselected_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "ky7ICuRuDl8f"
      },
      "outputs": [],
      "source": [
        "def smote(data, target_column):\n",
        "    # Separate features and target variable\n",
        "    X = data.drop(target_column, axis=1)\n",
        "    y = data[target_column]\n",
        "\n",
        "    # Apply SMOTE\n",
        "    smote = SMOTE()\n",
        "    X_resampled, y_resampled = smote.fit_resample(X, y)\n",
        "\n",
        "    # Combine resampled data into a DataFrame\n",
        "    resampled_data = pd.concat([pd.DataFrame(X_resampled, columns=X.columns), pd.Series(y_resampled, name=target_column)], axis=1)\n",
        "    return resampled_data,''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "YaS8Ky5CCnsG"
      },
      "outputs": [],
      "source": [
        "def ballanced(data,type=\"O\"):\n",
        "\n",
        "  if type==\"U\":\n",
        "    resampled, unselected_data = undersampling(data, 'FLAG')\n",
        "  elif type==\"S\":\n",
        "    resampled, unselected_data  = smote(data, 'FLAG')\n",
        "  elif type==\"O\":\n",
        "    resampled, unselected_data = oversampling(data, 'FLAG')\n",
        "\n",
        "\n",
        "  return resampled, unselected_data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NDFnMS8EDnPv"
      },
      "source": [
        "#**Preprocessing **"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "bjCS9A6XDoeu"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "PQGlmKgmObAP"
      },
      "outputs": [],
      "source": [
        "df_filtered = preprocessing()\n",
        "df_filtered = df_filtered.drop(['Address'], axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jkpkxkSm8eEl"
      },
      "source": [
        "**Imballanced Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "ioeEnhHe8V_e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "7e7c0431-9ed2-43b1-f1f9-b27e95e39ab0"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "df = df_filtered\n",
        "positive_sample = df[(df[\"FLAG\"]==1)]\n",
        "negative_sample = df[(df[\"FLAG\"]==0)]\n",
        "dist = df[\"FLAG\"].value_counts()\n",
        "\n",
        "_ = plt.pie(dist, labels = [\"Negative ({0})\".format(len(negative_sample)), \"Positive ({0})\".format(len(positive_sample))], colors = [\"r\", \"g\"], explode=[0.2, 0], autopct='%1.1f%%')\n",
        "_ = plt.title(\"Data Distribution\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "r2cgG4FuNaeE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6a031da-c906-4cc5-8272-48f159afdc3e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20302, 18)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "#df_filtered = np.array(df_filtered)\n",
        "df_filtered.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "oSjP7e4MCIqv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5385fbff-f75a-40c3-94d1-f54f625c1fcd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(29254, 18)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "resampledOver, unselected_Over = ballanced(df_filtered,\"O\")\n",
        "resampledOver.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "h6FayFZmyfme",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "572b640f-a82c-4f2c-e9b4-d6245b8c6773"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(29254, 17)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "X_reshapedO,y_reshapedO = scaled(resampledOver)\n",
        "X_reshapedO.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "Cd-b8SsCoqJI"
      },
      "outputs": [],
      "source": [
        "X_trainO, X_testO, y_trainO, y_testO =  train_test_split(X_reshapedO, y_reshapedO, test_size=0.1, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kikiBnEgEjKW"
      },
      "source": [
        "# #**Models**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MmBZDbm2DwsQ"
      },
      "source": [
        "LSTM"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from sklearn.metrics import roc_auc_score"
      ],
      "metadata": {
        "id": "3aWzA330Ynv-"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.optimizers import Adam"
      ],
      "metadata": {
        "id": "c3DPXF3CipAu"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.concatenate([X_trainO, X_testO], axis=0)\n",
        "y = np.concatenate([y_trainO, y_testO], axis=0)\n",
        "X_df = pd.DataFrame(X)\n",
        "y_df = pd.DataFrame(y)"
      ],
      "metadata": {
        "id": "VCgCBpcfY9uN"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Reshape X to 3D for CNN input\n",
        "X_reshaped = X.reshape(X.shape[0],X.shape[1], 1)\n"
      ],
      "metadata": {
        "id": "VXpOhIV8Yt4E"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kf = KFold(n_splits=10, random_state = 42, shuffle=True)\n",
        "fld = 1"
      ],
      "metadata": {
        "id": "M1d7yW-GhgCe"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = Adam(learning_rate=0.0001)"
      ],
      "metadata": {
        "id": "qD1m0LHaheq2"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the LSTM model\n",
        "model = Sequential()\n",
        "model.add(LSTM(46, activation='relu', input_shape=(X_reshaped.shape[1], 1), return_sequences=True))\n",
        "model.add(LSTM(30, activation='relu', return_sequences=False))\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ],
      "metadata": {
        "id": "gLT-FkfXhlkq"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import EarlyStopping\n",
        "from sklearn.metrics import roc_curve, roc_auc_score"
      ],
      "metadata": {
        "id": "yqNhuELO8KMj"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracies = []\n",
        "history = []\n",
        "losses = []\n",
        "val_accuracies = []\n",
        "val_losses = []\n",
        "resultLSTM  = {}\n",
        "\n",
        "for train_index, test_index in kf.split(X):\n",
        "        X_trainV, X_testV = X_df.iloc[train_index], X_df.iloc[test_index]\n",
        "        y_trainV, y_testV = y_df.iloc[train_index], y_df.iloc[test_index]\n",
        "\n",
        "        start_time = time.time()\n",
        "        model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "        early_stopping = EarlyStopping(monitor='val_loss', patience=10, verbose=1, mode='min', restore_best_weights=True)\n",
        "\n",
        "        Training_time = time.time() - start_time\n",
        "\n",
        "        start_time = time.time()\n",
        "        #history = model.fit(X_trainV, y_trainV, epochs=100, batch_size=32, validation_split=0.2)\n",
        "        history = model.fit(X_trainV, y_trainV, validation_data=(X_testV, y_testV), epochs=100, batch_size=32, verbose=1, callbacks=[early_stopping])\n",
        "\n",
        "        Inference_Time = time.time() - start_time\n",
        "\n",
        "        accuracies.append(history.history['accuracy'][-1])\n",
        "        losses.append(history.history['loss'][-1])\n",
        "        val_accuracies.append(history.history['val_accuracy'][-1])\n",
        "        val_losses.append(history.history['val_loss'][-1])\n",
        "\n",
        "        y_predictLSTM = model.predict(X_testV)\n",
        "\n",
        "        y_predictLSTM_binary = np.where(y_predictLSTM > 0.5, 1, 0)\n",
        "\n",
        "        # Now use these binary predictions for calculating metrics\n",
        "        accuracy = accuracy_score(y_testV, y_predictLSTM_binary)\n",
        "        precision = precision_score(y_testV, y_predictLSTM_binary)\n",
        "        recall = recall_score(y_testV, y_predictLSTM_binary)\n",
        "        f1 = f1_score(y_testV, y_predictLSTM_binary)\n",
        "        kappa = cohen_kappa_score(y_testV, y_predictLSTM_binary)\n",
        "        conf_mat = confusion_matrix(y_testV, y_predictLSTM_binary)\n",
        "        roc_auc = roc_auc_score(y_testV, y_predictLSTM_binary)\n",
        "        fpr, tpr, thresholds = roc_curve(y_testV, y_predictLSTM_binary)\n",
        "\n",
        "\n",
        "\n",
        "        resultLSTM[f'Model_{fld}'] = {'Matrix': conf_mat, 'accuracy': accuracy, 'precision': precision,\n",
        "                                  'recall': recall, 'f1': f1, 'kappa': kappa, 'roc_auc': roc_auc,'fpr':fpr\n",
        "                                     ,'tpr':tpr,'thresholds':thresholds,'Inference_Time':Inference_Time,'Training_time':Training_time}\n",
        "\n",
        "\n",
        "        # Print metrics for the LR model\n",
        "        print(f'Metrics for LR Model Fold {fld}:')\n",
        "        print(f\"Inference Time: {Inference_Time:.4f} seconds\")\n",
        "        print(f\"training Time: {Training_time:.4f} seconds\")\n",
        "        print(f\"Accuracy: {accuracy:.2f}\")\n",
        "        print(f\"Precision: {precision:.2f}\")\n",
        "        print(f\"Recall: {recall:.2f}\")\n",
        "        print(f\"F1-score: {f1:.2f}\")\n",
        "        print(f\"kappa: {kappa:.2f}\")\n",
        "        print(f\"ROC AUC: {roc_auc:.2f}\")\n",
        "        print(f\"fpr: {fpr}\")\n",
        "        print(f\"tpr: {tpr}\")\n",
        "        print(f\"thresholds: {thresholds}\")\n",
        "        print(conf_mat)\n",
        "        print(\"********************************************************************\")\n",
        "\n",
        "        fld = fld + 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PeEnpWyBhcUv",
        "outputId": "804d22b3-b0d8-4b7a-e059-3b7b9ac0d6b6"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "823/823 [==============================] - 22s 19ms/step - loss: 0.3666 - accuracy: 0.8222 - val_loss: 0.3743 - val_accuracy: 0.8216\n",
            "Epoch 2/100\n",
            "823/823 [==============================] - 16s 19ms/step - loss: 0.3672 - accuracy: 0.8203 - val_loss: 0.3787 - val_accuracy: 0.8230\n",
            "Epoch 3/100\n",
            "823/823 [==============================] - 16s 19ms/step - loss: 0.3672 - accuracy: 0.8210 - val_loss: 0.4414 - val_accuracy: 0.7779\n",
            "Epoch 4/100\n",
            "823/823 [==============================] - 16s 19ms/step - loss: 0.3676 - accuracy: 0.8218 - val_loss: 0.4063 - val_accuracy: 0.8206\n",
            "Epoch 5/100\n",
            "823/823 [==============================] - 17s 21ms/step - loss: 0.3615 - accuracy: 0.8253 - val_loss: 0.3882 - val_accuracy: 0.8124\n",
            "Epoch 6/100\n",
            "823/823 [==============================] - 16s 19ms/step - loss: 0.3611 - accuracy: 0.8257 - val_loss: 0.3671 - val_accuracy: 0.8278\n",
            "Epoch 7/100\n",
            "823/823 [==============================] - 16s 19ms/step - loss: 0.3602 - accuracy: 0.8268 - val_loss: 0.3822 - val_accuracy: 0.8151\n",
            "Epoch 8/100\n",
            "823/823 [==============================] - 15s 19ms/step - loss: 0.3547 - accuracy: 0.8270 - val_loss: 0.3789 - val_accuracy: 0.8195\n",
            "Epoch 9/100\n",
            "823/823 [==============================] - 15s 19ms/step - loss: 0.3602 - accuracy: 0.8286 - val_loss: 0.3981 - val_accuracy: 0.7714\n",
            "Epoch 10/100\n",
            "823/823 [==============================] - 16s 20ms/step - loss: 0.3530 - accuracy: 0.8295 - val_loss: 0.3864 - val_accuracy: 0.8370\n",
            "Epoch 11/100\n",
            "823/823 [==============================] - 15s 19ms/step - loss: 0.3555 - accuracy: 0.8283 - val_loss: 0.3712 - val_accuracy: 0.8363\n",
            "Epoch 12/100\n",
            "823/823 [==============================] - 16s 20ms/step - loss: 0.3552 - accuracy: 0.8273 - val_loss: 0.3682 - val_accuracy: 0.8366\n",
            "Epoch 13/100\n",
            "823/823 [==============================] - 16s 19ms/step - loss: 0.3520 - accuracy: 0.8317 - val_loss: 0.3863 - val_accuracy: 0.8213\n",
            "Epoch 14/100\n",
            "823/823 [==============================] - 15s 19ms/step - loss: 0.3530 - accuracy: 0.8297 - val_loss: 0.4183 - val_accuracy: 0.7932\n",
            "Epoch 15/100\n",
            "823/823 [==============================] - 15s 19ms/step - loss: 0.3521 - accuracy: 0.8296 - val_loss: 0.3751 - val_accuracy: 0.8383\n",
            "Epoch 16/100\n",
            "820/823 [============================>.] - ETA: 0s - loss: 0.3536 - accuracy: 0.8301Restoring model weights from the end of the best epoch: 6.\n",
            "823/823 [==============================] - 15s 19ms/step - loss: 0.3536 - accuracy: 0.8301 - val_loss: 0.3863 - val_accuracy: 0.8202\n",
            "Epoch 16: early stopping\n",
            "92/92 [==============================] - 1s 6ms/step\n",
            "Metrics for LR Model Fold 1:\n",
            "Inference Time: 266.6368 seconds\n",
            "training Time: 0.0077 seconds\n",
            "Accuracy: 0.83\n",
            "Precision: 0.78\n",
            "Recall: 0.92\n",
            "F1-score: 0.84\n",
            "kappa: 0.65\n",
            "ROC AUC: 0.83\n",
            "fpr: [0.         0.26984127 1.        ]\n",
            "tpr: [0.         0.92349357 1.        ]\n",
            "thresholds: [2 1 0]\n",
            "[[1058  391]\n",
            " [ 113 1364]]\n",
            "********************************************************************\n",
            "Epoch 1/100\n",
            "823/823 [==============================] - 20s 20ms/step - loss: 0.3636 - accuracy: 0.8248 - val_loss: 0.3491 - val_accuracy: 0.8308\n",
            "Epoch 2/100\n",
            "823/823 [==============================] - 16s 20ms/step - loss: 0.3612 - accuracy: 0.8267 - val_loss: 0.3514 - val_accuracy: 0.8274\n",
            "Epoch 3/100\n",
            "823/823 [==============================] - 16s 19ms/step - loss: 0.3598 - accuracy: 0.8254 - val_loss: 0.3657 - val_accuracy: 0.8144\n",
            "Epoch 4/100\n",
            "823/823 [==============================] - 16s 19ms/step - loss: 0.3620 - accuracy: 0.8252 - val_loss: 0.3728 - val_accuracy: 0.8103\n",
            "Epoch 5/100\n",
            "823/823 [==============================] - 16s 19ms/step - loss: 0.3576 - accuracy: 0.8298 - val_loss: 0.3545 - val_accuracy: 0.8226\n",
            "Epoch 6/100\n",
            "823/823 [==============================] - 16s 19ms/step - loss: 0.3575 - accuracy: 0.8271 - val_loss: 0.3524 - val_accuracy: 0.8332\n",
            "Epoch 7/100\n",
            "823/823 [==============================] - 16s 19ms/step - loss: 0.3563 - accuracy: 0.8285 - val_loss: 0.3478 - val_accuracy: 0.8315\n",
            "Epoch 8/100\n",
            "823/823 [==============================] - 15s 19ms/step - loss: 0.3580 - accuracy: 0.8293 - val_loss: 0.3920 - val_accuracy: 0.8195\n",
            "Epoch 9/100\n",
            "823/823 [==============================] - 15s 18ms/step - loss: 0.3547 - accuracy: 0.8306 - val_loss: 0.3536 - val_accuracy: 0.8342\n",
            "Epoch 10/100\n",
            "823/823 [==============================] - 15s 19ms/step - loss: 0.3509 - accuracy: 0.8320 - val_loss: 0.3471 - val_accuracy: 0.8380\n",
            "Epoch 11/100\n",
            "823/823 [==============================] - 15s 18ms/step - loss: 0.3518 - accuracy: 0.8325 - val_loss: 0.3462 - val_accuracy: 0.8342\n",
            "Epoch 12/100\n",
            "823/823 [==============================] - 15s 19ms/step - loss: 0.3477 - accuracy: 0.8345 - val_loss: 0.3499 - val_accuracy: 0.8342\n",
            "Epoch 13/100\n",
            "823/823 [==============================] - 15s 19ms/step - loss: 0.3561 - accuracy: 0.8280 - val_loss: 0.3580 - val_accuracy: 0.8349\n",
            "Epoch 14/100\n",
            "823/823 [==============================] - 15s 18ms/step - loss: 0.3491 - accuracy: 0.8344 - val_loss: 0.3699 - val_accuracy: 0.8257\n",
            "Epoch 15/100\n",
            "823/823 [==============================] - 15s 19ms/step - loss: 0.3462 - accuracy: 0.8354 - val_loss: 0.3524 - val_accuracy: 0.8370\n",
            "Epoch 16/100\n",
            "823/823 [==============================] - 16s 19ms/step - loss: 0.3502 - accuracy: 0.8316 - val_loss: 0.3532 - val_accuracy: 0.8185\n",
            "Epoch 17/100\n",
            "823/823 [==============================] - 16s 19ms/step - loss: 0.3501 - accuracy: 0.8328 - val_loss: 0.3311 - val_accuracy: 0.8397\n",
            "Epoch 18/100\n",
            "823/823 [==============================] - 16s 19ms/step - loss: 0.3456 - accuracy: 0.8325 - val_loss: 0.3667 - val_accuracy: 0.8175\n",
            "Epoch 19/100\n",
            "823/823 [==============================] - 15s 18ms/step - loss: 0.3479 - accuracy: 0.8350 - val_loss: 0.3377 - val_accuracy: 0.8414\n",
            "Epoch 20/100\n",
            "823/823 [==============================] - 15s 18ms/step - loss: 0.3433 - accuracy: 0.8357 - val_loss: 0.3384 - val_accuracy: 0.8356\n",
            "Epoch 21/100\n",
            "823/823 [==============================] - 16s 19ms/step - loss: 0.3494 - accuracy: 0.8344 - val_loss: 0.3479 - val_accuracy: 0.8339\n",
            "Epoch 22/100\n",
            "823/823 [==============================] - 16s 19ms/step - loss: 0.3436 - accuracy: 0.8375 - val_loss: 0.3469 - val_accuracy: 0.8295\n",
            "Epoch 23/100\n",
            "823/823 [==============================] - 16s 19ms/step - loss: 0.3398 - accuracy: 0.8374 - val_loss: 0.3484 - val_accuracy: 0.8264\n",
            "Epoch 24/100\n",
            "823/823 [==============================] - 17s 21ms/step - loss: 0.3407 - accuracy: 0.8359 - val_loss: 0.3630 - val_accuracy: 0.8250\n",
            "Epoch 25/100\n",
            "823/823 [==============================] - 16s 20ms/step - loss: 0.3423 - accuracy: 0.8366 - val_loss: 0.3354 - val_accuracy: 0.8349\n",
            "Epoch 26/100\n",
            "823/823 [==============================] - 16s 19ms/step - loss: 0.3381 - accuracy: 0.8380 - val_loss: 0.3429 - val_accuracy: 0.8472\n",
            "Epoch 27/100\n",
            "822/823 [============================>.] - ETA: 0s - loss: 0.3397 - accuracy: 0.8396Restoring model weights from the end of the best epoch: 17.\n",
            "823/823 [==============================] - 16s 19ms/step - loss: 0.3396 - accuracy: 0.8396 - val_loss: 0.3929 - val_accuracy: 0.8260\n",
            "Epoch 27: early stopping\n",
            "92/92 [==============================] - 1s 6ms/step\n",
            "Metrics for LR Model Fold 2:\n",
            "Inference Time: 432.0391 seconds\n",
            "training Time: 0.0071 seconds\n",
            "Accuracy: 0.84\n",
            "Precision: 0.80\n",
            "Recall: 0.90\n",
            "F1-score: 0.85\n",
            "kappa: 0.68\n",
            "ROC AUC: 0.84\n",
            "fpr: [0.         0.22425474 1.        ]\n",
            "tpr: [0.         0.90482759 1.        ]\n",
            "thresholds: [2 1 0]\n",
            "[[1145  331]\n",
            " [ 138 1312]]\n",
            "********************************************************************\n",
            "Epoch 1/100\n",
            "823/823 [==============================] - 19s 20ms/step - loss: 0.3501 - accuracy: 0.8322 - val_loss: 0.3762 - val_accuracy: 0.8414\n",
            "Epoch 2/100\n",
            "823/823 [==============================] - 16s 20ms/step - loss: 0.3442 - accuracy: 0.8334 - val_loss: 0.3911 - val_accuracy: 0.8360\n",
            "Epoch 3/100\n",
            "823/823 [==============================] - 18s 22ms/step - loss: 0.3430 - accuracy: 0.8335 - val_loss: 0.3788 - val_accuracy: 0.8353\n",
            "Epoch 4/100\n",
            "823/823 [==============================] - 15s 19ms/step - loss: 0.3444 - accuracy: 0.8343 - val_loss: 0.3442 - val_accuracy: 0.8472\n",
            "Epoch 5/100\n",
            "823/823 [==============================] - 15s 19ms/step - loss: 0.3482 - accuracy: 0.8368 - val_loss: 0.3360 - val_accuracy: 0.8486\n",
            "Epoch 6/100\n",
            "823/823 [==============================] - 15s 19ms/step - loss: 0.3413 - accuracy: 0.8342 - val_loss: 0.3542 - val_accuracy: 0.8370\n",
            "Epoch 7/100\n",
            "823/823 [==============================] - 16s 19ms/step - loss: 0.3392 - accuracy: 0.8379 - val_loss: 0.3414 - val_accuracy: 0.8520\n",
            "Epoch 8/100\n",
            "823/823 [==============================] - 15s 19ms/step - loss: 0.3385 - accuracy: 0.8366 - val_loss: 0.3721 - val_accuracy: 0.8424\n",
            "Epoch 9/100\n",
            "823/823 [==============================] - 15s 19ms/step - loss: 0.3405 - accuracy: 0.8351 - val_loss: 0.3381 - val_accuracy: 0.8554\n",
            "Epoch 10/100\n",
            "823/823 [==============================] - 15s 19ms/step - loss: 0.3435 - accuracy: 0.8343 - val_loss: 0.3790 - val_accuracy: 0.8254\n",
            "Epoch 11/100\n",
            "823/823 [==============================] - 17s 20ms/step - loss: 0.3397 - accuracy: 0.8366 - val_loss: 0.3374 - val_accuracy: 0.8459\n",
            "Epoch 12/100\n",
            "823/823 [==============================] - 16s 19ms/step - loss: 0.3368 - accuracy: 0.8380 - val_loss: 0.3451 - val_accuracy: 0.8469\n",
            "Epoch 13/100\n",
            "823/823 [==============================] - 16s 19ms/step - loss: 0.3427 - accuracy: 0.8364 - val_loss: 0.3496 - val_accuracy: 0.8435\n",
            "Epoch 14/100\n",
            "823/823 [==============================] - 16s 19ms/step - loss: 0.3425 - accuracy: 0.8359 - val_loss: 0.4198 - val_accuracy: 0.8551\n",
            "Epoch 15/100\n",
            "821/823 [============================>.] - ETA: 0s - loss: 0.3383 - accuracy: 0.8361Restoring model weights from the end of the best epoch: 5.\n",
            "823/823 [==============================] - 16s 19ms/step - loss: 0.3383 - accuracy: 0.8361 - val_loss: 0.3678 - val_accuracy: 0.8192\n",
            "Epoch 15: early stopping\n",
            "92/92 [==============================] - 1s 6ms/step\n",
            "Metrics for LR Model Fold 3:\n",
            "Inference Time: 244.7618 seconds\n",
            "training Time: 0.0072 seconds\n",
            "Accuracy: 0.85\n",
            "Precision: 0.81\n",
            "Recall: 0.91\n",
            "F1-score: 0.86\n",
            "kappa: 0.70\n",
            "ROC AUC: 0.85\n",
            "fpr: [0.         0.21920668 1.        ]\n",
            "tpr: [0.         0.91403627 1.        ]\n",
            "thresholds: [2 1 0]\n",
            "[[1122  315]\n",
            " [ 128 1361]]\n",
            "********************************************************************\n",
            "Epoch 1/100\n",
            "823/823 [==============================] - 19s 20ms/step - loss: 0.3426 - accuracy: 0.8381 - val_loss: 0.3546 - val_accuracy: 0.8247\n",
            "Epoch 2/100\n",
            "823/823 [==============================] - 17s 21ms/step - loss: 0.3445 - accuracy: 0.8336 - val_loss: 0.3449 - val_accuracy: 0.8278\n",
            "Epoch 3/100\n",
            "823/823 [==============================] - 16s 19ms/step - loss: 0.3448 - accuracy: 0.8364 - val_loss: 0.3341 - val_accuracy: 0.8431\n",
            "Epoch 4/100\n",
            "823/823 [==============================] - 16s 19ms/step - loss: 0.3426 - accuracy: 0.8371 - val_loss: 0.3586 - val_accuracy: 0.8325\n",
            "Epoch 5/100\n",
            "823/823 [==============================] - 16s 19ms/step - loss: 0.3412 - accuracy: 0.8381 - val_loss: 0.3723 - val_accuracy: 0.7874\n",
            "Epoch 6/100\n",
            "823/823 [==============================] - 16s 20ms/step - loss: 0.3398 - accuracy: 0.8382 - val_loss: 0.3617 - val_accuracy: 0.8199\n",
            "Epoch 7/100\n",
            "823/823 [==============================] - 15s 19ms/step - loss: 0.3385 - accuracy: 0.8381 - val_loss: 0.3644 - val_accuracy: 0.8178\n",
            "Epoch 8/100\n",
            "823/823 [==============================] - 15s 19ms/step - loss: 0.3362 - accuracy: 0.8375 - val_loss: 0.3740 - val_accuracy: 0.8165\n",
            "Epoch 9/100\n",
            "823/823 [==============================] - 15s 19ms/step - loss: 0.3400 - accuracy: 0.8365 - val_loss: 0.3577 - val_accuracy: 0.8230\n",
            "Epoch 10/100\n",
            "823/823 [==============================] - 15s 18ms/step - loss: 0.3350 - accuracy: 0.8400 - val_loss: 0.4055 - val_accuracy: 0.7632\n",
            "Epoch 11/100\n",
            "823/823 [==============================] - 15s 18ms/step - loss: 0.3370 - accuracy: 0.8378 - val_loss: 0.3540 - val_accuracy: 0.8319\n",
            "Epoch 12/100\n",
            "823/823 [==============================] - 15s 18ms/step - loss: 0.3382 - accuracy: 0.8366 - val_loss: 0.3767 - val_accuracy: 0.8161\n",
            "Epoch 13/100\n",
            "821/823 [============================>.] - ETA: 0s - loss: 0.3448 - accuracy: 0.8380Restoring model weights from the end of the best epoch: 3.\n",
            "823/823 [==============================] - 15s 19ms/step - loss: 0.3446 - accuracy: 0.8380 - val_loss: 0.3365 - val_accuracy: 0.8428\n",
            "Epoch 13: early stopping\n",
            "92/92 [==============================] - 1s 6ms/step\n",
            "Metrics for LR Model Fold 4:\n",
            "Inference Time: 212.3947 seconds\n",
            "training Time: 0.0076 seconds\n",
            "Accuracy: 0.84\n",
            "Precision: 0.79\n",
            "Recall: 0.92\n",
            "F1-score: 0.85\n",
            "kappa: 0.69\n",
            "ROC AUC: 0.84\n",
            "fpr: [0.         0.22727273 1.        ]\n",
            "tpr: [0.         0.91678322 1.        ]\n",
            "thresholds: [2 1 0]\n",
            "[[1156  340]\n",
            " [ 119 1311]]\n",
            "********************************************************************\n",
            "Epoch 1/100\n",
            "823/823 [==============================] - 19s 20ms/step - loss: 0.3446 - accuracy: 0.8360 - val_loss: 0.3313 - val_accuracy: 0.8434\n",
            "Epoch 2/100\n",
            "823/823 [==============================] - 15s 19ms/step - loss: 0.3424 - accuracy: 0.8372 - val_loss: 0.3257 - val_accuracy: 0.8417\n",
            "Epoch 3/100\n",
            "823/823 [==============================] - 15s 19ms/step - loss: 0.3391 - accuracy: 0.8375 - val_loss: 0.3180 - val_accuracy: 0.8506\n",
            "Epoch 4/100\n",
            "823/823 [==============================] - 15s 18ms/step - loss: 0.3436 - accuracy: 0.8340 - val_loss: 0.3110 - val_accuracy: 0.8561\n",
            "Epoch 5/100\n",
            "823/823 [==============================] - 15s 19ms/step - loss: 0.3394 - accuracy: 0.8374 - val_loss: 0.3272 - val_accuracy: 0.8574\n",
            "Epoch 6/100\n",
            "823/823 [==============================] - 15s 19ms/step - loss: 0.3497 - accuracy: 0.8352 - val_loss: 0.3258 - val_accuracy: 0.8557\n",
            "Epoch 7/100\n",
            "823/823 [==============================] - 16s 20ms/step - loss: 0.3403 - accuracy: 0.8367 - val_loss: 0.3343 - val_accuracy: 0.8544\n",
            "Epoch 8/100\n",
            "823/823 [==============================] - 15s 18ms/step - loss: 0.3423 - accuracy: 0.8409 - val_loss: 0.3573 - val_accuracy: 0.7819\n",
            "Epoch 9/100\n",
            "823/823 [==============================] - 15s 18ms/step - loss: 0.3395 - accuracy: 0.8388 - val_loss: 0.3523 - val_accuracy: 0.8338\n",
            "Epoch 10/100\n",
            "823/823 [==============================] - 15s 18ms/step - loss: 0.3447 - accuracy: 0.8355 - val_loss: 0.3449 - val_accuracy: 0.8393\n",
            "Epoch 11/100\n",
            "823/823 [==============================] - 15s 19ms/step - loss: 0.3396 - accuracy: 0.8379 - val_loss: 0.3405 - val_accuracy: 0.8335\n",
            "Epoch 12/100\n",
            "823/823 [==============================] - 16s 19ms/step - loss: 0.3370 - accuracy: 0.8378 - val_loss: 0.3354 - val_accuracy: 0.8482\n",
            "Epoch 13/100\n",
            "823/823 [==============================] - 15s 19ms/step - loss: 0.3385 - accuracy: 0.8407 - val_loss: 0.3318 - val_accuracy: 0.8376\n",
            "Epoch 14/100\n",
            "822/823 [============================>.] - ETA: 0s - loss: 0.3338 - accuracy: 0.8408Restoring model weights from the end of the best epoch: 4.\n",
            "823/823 [==============================] - 15s 19ms/step - loss: 0.3338 - accuracy: 0.8408 - val_loss: 0.3138 - val_accuracy: 0.8492\n",
            "Epoch 14: early stopping\n",
            "92/92 [==============================] - 1s 6ms/step\n",
            "Metrics for LR Model Fold 5:\n",
            "Inference Time: 224.0036 seconds\n",
            "training Time: 0.0086 seconds\n",
            "Accuracy: 0.86\n",
            "Precision: 0.81\n",
            "Recall: 0.92\n",
            "F1-score: 0.86\n",
            "kappa: 0.71\n",
            "ROC AUC: 0.86\n",
            "fpr: [0.         0.20414993 1.        ]\n",
            "tpr: [0.         0.91893781 1.        ]\n",
            "thresholds: [2 1 0]\n",
            "[[1189  305]\n",
            " [ 116 1315]]\n",
            "********************************************************************\n",
            "Epoch 1/100\n",
            "823/823 [==============================] - 20s 20ms/step - loss: 0.3468 - accuracy: 0.8312 - val_loss: 0.3233 - val_accuracy: 0.8434\n",
            "Epoch 2/100\n",
            "823/823 [==============================] - 16s 19ms/step - loss: 0.3415 - accuracy: 0.8357 - val_loss: 0.3361 - val_accuracy: 0.8325\n",
            "Epoch 3/100\n",
            "823/823 [==============================] - 16s 19ms/step - loss: 0.3404 - accuracy: 0.8376 - val_loss: 0.3216 - val_accuracy: 0.8568\n",
            "Epoch 4/100\n",
            "823/823 [==============================] - 15s 19ms/step - loss: 0.3397 - accuracy: 0.8368 - val_loss: 0.3442 - val_accuracy: 0.8318\n",
            "Epoch 5/100\n",
            "823/823 [==============================] - 17s 20ms/step - loss: 0.3394 - accuracy: 0.8362 - val_loss: 0.3273 - val_accuracy: 0.8438\n",
            "Epoch 6/100\n",
            "823/823 [==============================] - 16s 19ms/step - loss: 0.3382 - accuracy: 0.8369 - val_loss: 0.3122 - val_accuracy: 0.8550\n",
            "Epoch 7/100\n",
            "823/823 [==============================] - 15s 19ms/step - loss: 0.3374 - accuracy: 0.8377 - val_loss: 0.3226 - val_accuracy: 0.8444\n",
            "Epoch 8/100\n",
            "823/823 [==============================] - 15s 19ms/step - loss: 0.3378 - accuracy: 0.8386 - val_loss: 0.3173 - val_accuracy: 0.8523\n",
            "Epoch 9/100\n",
            "823/823 [==============================] - 15s 19ms/step - loss: 0.3383 - accuracy: 0.8406 - val_loss: 0.3281 - val_accuracy: 0.8492\n",
            "Epoch 10/100\n",
            "823/823 [==============================] - 16s 19ms/step - loss: 0.3393 - accuracy: 0.8365 - val_loss: 0.3346 - val_accuracy: 0.8376\n",
            "Epoch 11/100\n",
            "823/823 [==============================] - 15s 19ms/step - loss: 0.3357 - accuracy: 0.8372 - val_loss: 0.3263 - val_accuracy: 0.8540\n",
            "Epoch 12/100\n",
            "823/823 [==============================] - 17s 20ms/step - loss: 0.3305 - accuracy: 0.8406 - val_loss: 0.3230 - val_accuracy: 0.8550\n",
            "Epoch 13/100\n",
            "823/823 [==============================] - 16s 20ms/step - loss: 0.3325 - accuracy: 0.8403 - val_loss: 0.3439 - val_accuracy: 0.8274\n",
            "Epoch 14/100\n",
            "823/823 [==============================] - 16s 19ms/step - loss: 0.3347 - accuracy: 0.8408 - val_loss: 0.3253 - val_accuracy: 0.8434\n",
            "Epoch 15/100\n",
            "823/823 [==============================] - 16s 19ms/step - loss: 0.3359 - accuracy: 0.8382 - val_loss: 0.3225 - val_accuracy: 0.8526\n",
            "Epoch 16/100\n",
            "823/823 [==============================] - ETA: 0s - loss: 0.3304 - accuracy: 0.8409Restoring model weights from the end of the best epoch: 6.\n",
            "823/823 [==============================] - 16s 19ms/step - loss: 0.3304 - accuracy: 0.8409 - val_loss: 0.3655 - val_accuracy: 0.8174\n",
            "Epoch 16: early stopping\n",
            "92/92 [==============================] - 1s 6ms/step\n",
            "Metrics for LR Model Fold 6:\n",
            "Inference Time: 261.2002 seconds\n",
            "training Time: 0.0119 seconds\n",
            "Accuracy: 0.86\n",
            "Precision: 0.82\n",
            "Recall: 0.92\n",
            "F1-score: 0.87\n",
            "kappa: 0.71\n",
            "ROC AUC: 0.85\n",
            "fpr: [0.         0.21661932 1.        ]\n",
            "tpr: [0.        0.9215557 1.       ]\n",
            "thresholds: [2 1 0]\n",
            "[[1103  305]\n",
            " [ 119 1398]]\n",
            "********************************************************************\n",
            "Epoch 1/100\n",
            "823/823 [==============================] - 20s 21ms/step - loss: 0.3379 - accuracy: 0.8387 - val_loss: 0.3619 - val_accuracy: 0.8352\n",
            "Epoch 2/100\n",
            "823/823 [==============================] - 16s 20ms/step - loss: 0.3402 - accuracy: 0.8403 - val_loss: 0.3396 - val_accuracy: 0.8332\n",
            "Epoch 3/100\n",
            "823/823 [==============================] - 16s 19ms/step - loss: 0.3307 - accuracy: 0.8426 - val_loss: 0.3367 - val_accuracy: 0.8434\n",
            "Epoch 4/100\n",
            "823/823 [==============================] - 16s 19ms/step - loss: 0.3384 - accuracy: 0.8376 - val_loss: 0.3396 - val_accuracy: 0.8301\n",
            "Epoch 5/100\n",
            "823/823 [==============================] - 15s 19ms/step - loss: 0.3315 - accuracy: 0.8414 - val_loss: 0.3261 - val_accuracy: 0.8407\n",
            "Epoch 6/100\n",
            "823/823 [==============================] - 15s 19ms/step - loss: 0.3316 - accuracy: 0.8410 - val_loss: 0.3663 - val_accuracy: 0.8147\n",
            "Epoch 7/100\n",
            "823/823 [==============================] - 16s 19ms/step - loss: 0.3309 - accuracy: 0.8428 - val_loss: 0.3378 - val_accuracy: 0.8356\n",
            "Epoch 8/100\n",
            "823/823 [==============================] - 16s 19ms/step - loss: 0.3298 - accuracy: 0.8430 - val_loss: 0.3579 - val_accuracy: 0.8195\n",
            "Epoch 9/100\n",
            "823/823 [==============================] - 16s 20ms/step - loss: 0.3273 - accuracy: 0.8438 - val_loss: 0.3330 - val_accuracy: 0.8345\n",
            "Epoch 10/100\n",
            "823/823 [==============================] - 18s 21ms/step - loss: 0.3340 - accuracy: 0.8426 - val_loss: 0.3380 - val_accuracy: 0.8280\n",
            "Epoch 11/100\n",
            "823/823 [==============================] - 15s 19ms/step - loss: 0.3296 - accuracy: 0.8434 - val_loss: 0.3411 - val_accuracy: 0.8294\n",
            "Epoch 12/100\n",
            "823/823 [==============================] - 15s 19ms/step - loss: 0.3248 - accuracy: 0.8453 - val_loss: 0.3545 - val_accuracy: 0.8297\n",
            "Epoch 13/100\n",
            "823/823 [==============================] - 15s 19ms/step - loss: 0.3304 - accuracy: 0.8414 - val_loss: 0.3457 - val_accuracy: 0.8304\n",
            "Epoch 14/100\n",
            "823/823 [==============================] - 15s 18ms/step - loss: 0.3266 - accuracy: 0.8465 - val_loss: 0.3506 - val_accuracy: 0.8229\n",
            "Epoch 15/100\n",
            "820/823 [============================>.] - ETA: 0s - loss: 0.3263 - accuracy: 0.8441Restoring model weights from the end of the best epoch: 5.\n",
            "823/823 [==============================] - 15s 18ms/step - loss: 0.3262 - accuracy: 0.8442 - val_loss: 0.3315 - val_accuracy: 0.8386\n",
            "Epoch 15: early stopping\n",
            "92/92 [==============================] - 1s 6ms/step\n",
            "Metrics for LR Model Fold 7:\n",
            "Inference Time: 244.2311 seconds\n",
            "training Time: 0.0106 seconds\n",
            "Accuracy: 0.84\n",
            "Precision: 0.80\n",
            "Recall: 0.92\n",
            "F1-score: 0.85\n",
            "kappa: 0.68\n",
            "ROC AUC: 0.84\n",
            "fpr: [0.         0.23626374 1.        ]\n",
            "tpr: [0.         0.91695031 1.        ]\n",
            "thresholds: [2 1 0]\n",
            "[[1112  344]\n",
            " [ 122 1347]]\n",
            "********************************************************************\n",
            "Epoch 1/100\n",
            "823/823 [==============================] - 19s 20ms/step - loss: 0.3339 - accuracy: 0.8369 - val_loss: 0.3210 - val_accuracy: 0.8489\n",
            "Epoch 2/100\n",
            "823/823 [==============================] - 15s 18ms/step - loss: 0.3392 - accuracy: 0.8381 - val_loss: 0.3281 - val_accuracy: 0.8444\n",
            "Epoch 3/100\n",
            "823/823 [==============================] - 15s 19ms/step - loss: 0.3352 - accuracy: 0.8405 - val_loss: 0.3274 - val_accuracy: 0.8475\n",
            "Epoch 4/100\n",
            "823/823 [==============================] - 18s 22ms/step - loss: 0.3371 - accuracy: 0.8392 - val_loss: 0.3843 - val_accuracy: 0.8431\n",
            "Epoch 5/100\n",
            "823/823 [==============================] - 17s 21ms/step - loss: 0.3473 - accuracy: 0.8405 - val_loss: 0.3579 - val_accuracy: 0.8311\n",
            "Epoch 6/100\n",
            "823/823 [==============================] - 16s 19ms/step - loss: 0.3385 - accuracy: 0.8389 - val_loss: 0.3318 - val_accuracy: 0.8444\n",
            "Epoch 7/100\n",
            "823/823 [==============================] - 15s 19ms/step - loss: 0.3300 - accuracy: 0.8427 - val_loss: 0.3281 - val_accuracy: 0.8410\n",
            "Epoch 8/100\n",
            "823/823 [==============================] - 17s 20ms/step - loss: 0.3303 - accuracy: 0.8425 - val_loss: 0.3343 - val_accuracy: 0.8376\n",
            "Epoch 9/100\n",
            "823/823 [==============================] - 15s 19ms/step - loss: 0.3308 - accuracy: 0.8415 - val_loss: 0.3184 - val_accuracy: 0.8520\n",
            "Epoch 10/100\n",
            "823/823 [==============================] - 15s 19ms/step - loss: 0.3271 - accuracy: 0.8429 - val_loss: 0.3238 - val_accuracy: 0.8479\n",
            "Epoch 11/100\n",
            "823/823 [==============================] - 15s 19ms/step - loss: 0.3247 - accuracy: 0.8444 - val_loss: 0.3243 - val_accuracy: 0.8455\n",
            "Epoch 12/100\n",
            "823/823 [==============================] - 16s 19ms/step - loss: 0.3263 - accuracy: 0.8449 - val_loss: 0.3310 - val_accuracy: 0.8335\n",
            "Epoch 13/100\n",
            "823/823 [==============================] - 17s 20ms/step - loss: 0.3317 - accuracy: 0.8394 - val_loss: 0.3200 - val_accuracy: 0.8523\n",
            "Epoch 14/100\n",
            "823/823 [==============================] - 15s 19ms/step - loss: 0.3279 - accuracy: 0.8424 - val_loss: 0.3236 - val_accuracy: 0.8462\n",
            "Epoch 15/100\n",
            "823/823 [==============================] - 15s 19ms/step - loss: 0.3511 - accuracy: 0.8350 - val_loss: 0.3701 - val_accuracy: 0.8270\n",
            "Epoch 16/100\n",
            "823/823 [==============================] - 15s 19ms/step - loss: 0.3535 - accuracy: 0.8334 - val_loss: 0.3254 - val_accuracy: 0.8489\n",
            "Epoch 17/100\n",
            "823/823 [==============================] - 15s 19ms/step - loss: 0.3265 - accuracy: 0.8426 - val_loss: 0.3345 - val_accuracy: 0.8444\n",
            "Epoch 18/100\n",
            "823/823 [==============================] - 15s 19ms/step - loss: 0.3230 - accuracy: 0.8465 - val_loss: 0.3289 - val_accuracy: 0.8376\n",
            "Epoch 19/100\n",
            "822/823 [============================>.] - ETA: 0s - loss: 0.3244 - accuracy: 0.8452Restoring model weights from the end of the best epoch: 9.\n",
            "823/823 [==============================] - 15s 19ms/step - loss: 0.3244 - accuracy: 0.8451 - val_loss: 0.3193 - val_accuracy: 0.8499\n",
            "Epoch 19: early stopping\n",
            "92/92 [==============================] - 1s 6ms/step\n",
            "Metrics for LR Model Fold 8:\n",
            "Inference Time: 308.7772 seconds\n",
            "training Time: 0.0116 seconds\n",
            "Accuracy: 0.85\n",
            "Precision: 0.81\n",
            "Recall: 0.91\n",
            "F1-score: 0.86\n",
            "kappa: 0.70\n",
            "ROC AUC: 0.85\n",
            "fpr: [0.         0.20596206 1.        ]\n",
            "tpr: [0.         0.91097308 1.        ]\n",
            "thresholds: [2 1 0]\n",
            "[[1172  304]\n",
            " [ 129 1320]]\n",
            "********************************************************************\n",
            "Epoch 1/100\n",
            "823/823 [==============================] - 19s 20ms/step - loss: 0.3494 - accuracy: 0.8325 - val_loss: 0.3385 - val_accuracy: 0.8311\n",
            "Epoch 2/100\n",
            "823/823 [==============================] - 16s 19ms/step - loss: 0.3410 - accuracy: 0.8432 - val_loss: 0.3112 - val_accuracy: 0.8544\n",
            "Epoch 3/100\n",
            "823/823 [==============================] - 17s 21ms/step - loss: 0.3231 - accuracy: 0.8471 - val_loss: 0.3234 - val_accuracy: 0.8431\n",
            "Epoch 4/100\n",
            "823/823 [==============================] - 16s 20ms/step - loss: 0.3284 - accuracy: 0.8442 - val_loss: 0.3115 - val_accuracy: 0.8537\n",
            "Epoch 5/100\n",
            "823/823 [==============================] - 16s 19ms/step - loss: 0.3264 - accuracy: 0.8450 - val_loss: 0.3210 - val_accuracy: 0.8516\n",
            "Epoch 6/100\n",
            "823/823 [==============================] - 15s 19ms/step - loss: 0.3300 - accuracy: 0.8420 - val_loss: 0.3124 - val_accuracy: 0.8561\n",
            "Epoch 7/100\n",
            "823/823 [==============================] - 16s 19ms/step - loss: 0.3264 - accuracy: 0.8447 - val_loss: 0.3652 - val_accuracy: 0.8191\n",
            "Epoch 8/100\n",
            "823/823 [==============================] - 16s 19ms/step - loss: 0.3292 - accuracy: 0.8417 - val_loss: 0.3119 - val_accuracy: 0.8646\n",
            "Epoch 9/100\n",
            "823/823 [==============================] - 16s 19ms/step - loss: 0.3313 - accuracy: 0.8422 - val_loss: 0.3135 - val_accuracy: 0.8554\n",
            "Epoch 10/100\n",
            "823/823 [==============================] - 16s 19ms/step - loss: 0.3298 - accuracy: 0.8415 - val_loss: 0.3005 - val_accuracy: 0.8571\n",
            "Epoch 11/100\n",
            "823/823 [==============================] - 16s 19ms/step - loss: 0.3264 - accuracy: 0.8437 - val_loss: 0.3311 - val_accuracy: 0.8431\n",
            "Epoch 12/100\n",
            "823/823 [==============================] - 17s 20ms/step - loss: 0.3533 - accuracy: 0.8371 - val_loss: 0.3249 - val_accuracy: 0.8465\n",
            "Epoch 13/100\n",
            "823/823 [==============================] - 16s 19ms/step - loss: 0.3346 - accuracy: 0.8434 - val_loss: 0.3146 - val_accuracy: 0.8561\n",
            "Epoch 14/100\n",
            "823/823 [==============================] - 16s 19ms/step - loss: 0.3262 - accuracy: 0.8447 - val_loss: 0.3054 - val_accuracy: 0.8650\n",
            "Epoch 15/100\n",
            "823/823 [==============================] - 16s 19ms/step - loss: 0.3231 - accuracy: 0.8435 - val_loss: 0.3013 - val_accuracy: 0.8568\n",
            "Epoch 16/100\n",
            "823/823 [==============================] - 15s 19ms/step - loss: 0.3239 - accuracy: 0.8457 - val_loss: 0.3326 - val_accuracy: 0.8017\n",
            "Epoch 17/100\n",
            "823/823 [==============================] - 16s 19ms/step - loss: 0.3250 - accuracy: 0.8453 - val_loss: 0.3315 - val_accuracy: 0.8414\n",
            "Epoch 18/100\n",
            "823/823 [==============================] - 17s 21ms/step - loss: 0.3220 - accuracy: 0.8445 - val_loss: 0.2936 - val_accuracy: 0.8598\n",
            "Epoch 19/100\n",
            "823/823 [==============================] - 16s 19ms/step - loss: 0.3213 - accuracy: 0.8461 - val_loss: 0.3327 - val_accuracy: 0.8246\n",
            "Epoch 20/100\n",
            "823/823 [==============================] - 16s 19ms/step - loss: 0.3280 - accuracy: 0.8440 - val_loss: 0.3263 - val_accuracy: 0.8509\n",
            "Epoch 21/100\n",
            "823/823 [==============================] - 17s 20ms/step - loss: 0.3211 - accuracy: 0.8456 - val_loss: 0.3038 - val_accuracy: 0.8588\n",
            "Epoch 22/100\n",
            "823/823 [==============================] - 16s 20ms/step - loss: 0.3240 - accuracy: 0.8447 - val_loss: 0.3219 - val_accuracy: 0.8096\n",
            "Epoch 23/100\n",
            "823/823 [==============================] - 16s 19ms/step - loss: 0.3342 - accuracy: 0.8444 - val_loss: 0.3318 - val_accuracy: 0.8499\n",
            "Epoch 24/100\n",
            "823/823 [==============================] - 16s 19ms/step - loss: 0.3849 - accuracy: 0.8175 - val_loss: 0.3298 - val_accuracy: 0.8366\n",
            "Epoch 25/100\n",
            "823/823 [==============================] - 16s 20ms/step - loss: 0.3579 - accuracy: 0.8304 - val_loss: 0.3179 - val_accuracy: 0.8537\n",
            "Epoch 26/100\n",
            "823/823 [==============================] - 16s 20ms/step - loss: 0.3387 - accuracy: 0.8403 - val_loss: 0.3245 - val_accuracy: 0.8448\n",
            "Epoch 27/100\n",
            "823/823 [==============================] - 16s 20ms/step - loss: 0.5433 - accuracy: 0.8139 - val_loss: 0.3665 - val_accuracy: 0.8267\n",
            "Epoch 28/100\n",
            "822/823 [============================>.] - ETA: 0s - loss: 0.4442 - accuracy: 0.8191Restoring model weights from the end of the best epoch: 18.\n",
            "823/823 [==============================] - 18s 21ms/step - loss: 0.4442 - accuracy: 0.8191 - val_loss: 0.4023 - val_accuracy: 0.8185\n",
            "Epoch 28: early stopping\n",
            "92/92 [==============================] - 1s 7ms/step\n",
            "Metrics for LR Model Fold 9:\n",
            "Inference Time: 458.2635 seconds\n",
            "training Time: 0.0086 seconds\n",
            "Accuracy: 0.86\n",
            "Precision: 0.83\n",
            "Recall: 0.90\n",
            "F1-score: 0.87\n",
            "kappa: 0.72\n",
            "ROC AUC: 0.86\n",
            "fpr: [0.         0.18350515 1.        ]\n",
            "tpr: [0.         0.90272109 1.        ]\n",
            "thresholds: [2 1 0]\n",
            "[[1188  267]\n",
            " [ 143 1327]]\n",
            "********************************************************************\n",
            "Epoch 1/100\n",
            "823/823 [==============================] - 23s 24ms/step - loss: 0.3226 - accuracy: 0.8457 - val_loss: 0.3399 - val_accuracy: 0.8369\n",
            "Epoch 2/100\n",
            "823/823 [==============================] - 16s 20ms/step - loss: 0.3254 - accuracy: 0.8443 - val_loss: 0.3147 - val_accuracy: 0.8472\n",
            "Epoch 3/100\n",
            "823/823 [==============================] - 16s 19ms/step - loss: 0.3216 - accuracy: 0.8478 - val_loss: 0.3499 - val_accuracy: 0.8315\n",
            "Epoch 4/100\n",
            "823/823 [==============================] - 16s 20ms/step - loss: 0.3195 - accuracy: 0.8482 - val_loss: 0.3035 - val_accuracy: 0.8561\n",
            "Epoch 5/100\n",
            "823/823 [==============================] - 17s 21ms/step - loss: 0.3204 - accuracy: 0.8446 - val_loss: 0.3457 - val_accuracy: 0.8301\n",
            "Epoch 6/100\n",
            "823/823 [==============================] - 16s 20ms/step - loss: 0.3249 - accuracy: 0.8432 - val_loss: 0.3199 - val_accuracy: 0.8547\n",
            "Epoch 7/100\n",
            "823/823 [==============================] - 16s 20ms/step - loss: 0.3189 - accuracy: 0.8463 - val_loss: 0.3206 - val_accuracy: 0.8421\n",
            "Epoch 8/100\n",
            "823/823 [==============================] - 17s 20ms/step - loss: 0.3189 - accuracy: 0.8466 - val_loss: 0.3366 - val_accuracy: 0.8465\n",
            "Epoch 9/100\n",
            "823/823 [==============================] - 16s 20ms/step - loss: 0.3168 - accuracy: 0.8485 - val_loss: 0.3175 - val_accuracy: 0.8496\n",
            "Epoch 10/100\n",
            "823/823 [==============================] - 17s 20ms/step - loss: 0.3146 - accuracy: 0.8510 - val_loss: 0.3115 - val_accuracy: 0.8465\n",
            "Epoch 11/100\n",
            "823/823 [==============================] - 17s 21ms/step - loss: 0.3155 - accuracy: 0.8473 - val_loss: 0.3191 - val_accuracy: 0.8455\n",
            "Epoch 12/100\n",
            "823/823 [==============================] - 17s 21ms/step - loss: 0.3157 - accuracy: 0.8494 - val_loss: 0.3199 - val_accuracy: 0.8523\n",
            "Epoch 13/100\n",
            "823/823 [==============================] - 17s 20ms/step - loss: 0.3182 - accuracy: 0.8477 - val_loss: 0.3270 - val_accuracy: 0.8424\n",
            "Epoch 14/100\n",
            "823/823 [==============================] - ETA: 0s - loss: 0.3188 - accuracy: 0.8455Restoring model weights from the end of the best epoch: 4.\n",
            "823/823 [==============================] - 17s 20ms/step - loss: 0.3188 - accuracy: 0.8455 - val_loss: 0.3237 - val_accuracy: 0.8431\n",
            "Epoch 14: early stopping\n",
            "92/92 [==============================] - 1s 7ms/step\n",
            "Metrics for LR Model Fold 10:\n",
            "Inference Time: 242.9880 seconds\n",
            "training Time: 0.0095 seconds\n",
            "Accuracy: 0.86\n",
            "Precision: 0.81\n",
            "Recall: 0.92\n",
            "F1-score: 0.86\n",
            "kappa: 0.71\n",
            "ROC AUC: 0.86\n",
            "fpr: [0.         0.20878378 1.        ]\n",
            "tpr: [0.         0.92249135 1.        ]\n",
            "thresholds: [2 1 0]\n",
            "[[1171  309]\n",
            " [ 112 1333]]\n",
            "********************************************************************\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize lists to store metric values\n",
        "accuracies = []\n",
        "precisions = []\n",
        "recalls = []\n",
        "f1_scores = []\n",
        "kappas = []\n",
        "Inference_Time = []\n",
        "Training_time = []\n",
        "roc_auc = []\n",
        "# Loop over the results dictionary\n",
        "for model, metrics in resultLSTM.items():\n",
        "    accuracies.append(metrics['accuracy'])\n",
        "    precisions.append(metrics['precision'])\n",
        "    recalls.append(metrics['recall'])\n",
        "    f1_scores.append(metrics['f1'])\n",
        "    kappas.append(metrics['kappa'])\n",
        "    Inference_Time.append(metrics['Inference_Time'])\n",
        "    Training_time.append(metrics['Training_time'])\n",
        "    roc_auc.append(metrics['roc_auc'])\n",
        "\n",
        "# Calculate the best, worst, and average values for each metric\n",
        "best_accuracy = round(max(accuracies), 2)\n",
        "worst_accuracy = round(min(accuracies), 2)\n",
        "average_accuracy = round(sum(accuracies) / len(accuracies), 2)\n",
        "\n",
        "\n",
        "best_precision = round(max(precisions), 2)\n",
        "worst_precision = round(min(precisions), 2)\n",
        "average_precision = round(sum(precisions) / len(precisions), 3)\n",
        "\n",
        "best_recall = round(max(recalls), 2)\n",
        "worst_recall = round(min(recalls), 2)\n",
        "average_recall = round(sum(recalls) / len(recalls), 2)\n",
        "\n",
        "best_f1_score = round(max(f1_scores), 2)\n",
        "worst_f1_score = round(min(f1_scores), 2)\n",
        "average_f1_score = round(sum(f1_scores) / len(f1_scores), 2)\n",
        "\n",
        "best_kappa = round(max(kappas), 2)\n",
        "worst_kappa = round(min(kappas), 2)\n",
        "average_kappa = round(sum(kappas) / len(kappas), 2)\n",
        "\n",
        "best_Inference_Time = round(max(Inference_Time), 5)\n",
        "worst_Inference_Time = round(min(Inference_Time), 5)\n",
        "average_Inference_Time = round(sum(Inference_Time) / len(Inference_Time), 5)\n",
        "\n",
        "\n",
        "best_Training_time = round(max(Training_time), 5)\n",
        "worst_Training_time = round(min(Training_time), 5)\n",
        "average_Training_time = round(sum(Training_time) / len(Training_time), 5)\n",
        "\n",
        "best_roc_auc = round(max(roc_auc), 2)\n",
        "worst_roc_auc = round(min(roc_auc), 2)\n",
        "average_roc_auc = round(sum(roc_auc) / len(roc_auc), 2)\n",
        "\n",
        "# Print the results\n",
        "print(\"Best Accuracy:\", best_accuracy)\n",
        "print(\"Worst Accuracy:\", worst_accuracy)\n",
        "print(\"Average Accuracy:\", average_accuracy)\n",
        "\n",
        "print(\"************************************************\")\n",
        "\n",
        "\n",
        "print(\"Best Precision:\", best_precision)\n",
        "print(\"Worst Precision:\", worst_precision)\n",
        "print(\"Average Precision:\", average_precision)\n",
        "print(\"************************************************\")\n",
        "\n",
        "print(\"Best Recall:\", best_recall)\n",
        "print(\"Worst Recall:\", worst_recall)\n",
        "print(\"Average Recall:\", average_recall)\n",
        "print(\"************************************************\")\n",
        "\n",
        "print(\"Best F1 Score:\", best_f1_score)\n",
        "print(\"Worst F1 Score:\", worst_f1_score)\n",
        "print(\"Average F1 Score:\", average_f1_score)\n",
        "print(\"************************************************\")\n",
        "\n",
        "print(\"Best Kappa:\", best_kappa)\n",
        "print(\"Worst Kappa:\", worst_kappa)\n",
        "print(\"Average Kappa:\", average_kappa)\n",
        "\n",
        "print(\"************************************************\")\n",
        "\n",
        "print(\"Best Inference_Time:\", best_Inference_Time)\n",
        "print(\"Worst Inference_Time:\", worst_Inference_Time)\n",
        "print(\"Average Inference_Time:\", average_Inference_Time)\n",
        "print(\"************************************************\")\n",
        "\n",
        "print(\"Best Training_time:\", best_Training_time)\n",
        "print(\"Worst Training_time:\", worst_Training_time)\n",
        "print(\"Average Training_time:\", average_Training_time)\n",
        "print(\"************************************************\")\n",
        "\n",
        "print(\"Best roc_auc:\", best_roc_auc)\n",
        "print(\"Worst roc_auc:\", worst_roc_auc)\n",
        "print(\"Average roc_auc:\", average_roc_auc)\n"
      ],
      "metadata": {
        "id": "MXBSDBw0uYik",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2087a3ce-dc56-45a4-e32a-d6baf7cd3984"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Accuracy: 0.86\n",
            "Worst Accuracy: 0.83\n",
            "Average Accuracy: 0.85\n",
            "************************************************\n",
            "Best Precision: 0.83\n",
            "Worst Precision: 0.78\n",
            "Average Precision: 0.807\n",
            "************************************************\n",
            "Best Recall: 0.92\n",
            "Worst Recall: 0.9\n",
            "Average Recall: 0.92\n",
            "************************************************\n",
            "Best F1 Score: 0.87\n",
            "Worst F1 Score: 0.84\n",
            "Average F1 Score: 0.86\n",
            "************************************************\n",
            "Best Kappa: 0.72\n",
            "Worst Kappa: 0.65\n",
            "Average Kappa: 0.7\n",
            "************************************************\n",
            "Best Inference_Time: 458.26352\n",
            "Worst Inference_Time: 212.39472\n",
            "Average Inference_Time: 289.52961\n",
            "************************************************\n",
            "Best Training_time: 0.01188\n",
            "Worst Training_time: 0.0071\n",
            "Average Training_time: 0.00904\n",
            "************************************************\n",
            "Best roc_auc: 0.86\n",
            "Worst roc_auc: 0.83\n",
            "Average roc_auc: 0.85\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.concatenate([X_trainO, X_testO], axis=0)\n",
        "y = np.concatenate([y_trainO, y_testO], axis=0)\n",
        "X_df = pd.DataFrame(X)\n",
        "y_df = pd.DataFrame(y)"
      ],
      "metadata": {
        "id": "dET9JjMpopp_"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Reshape X to 3D for CNN input\n",
        "X_reshaped = X.reshape(X.shape[0],X.shape[1], 1)\n"
      ],
      "metadata": {
        "id": "OJlLU66SopqC"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kf = KFold(n_splits=10, random_state = 42, shuffle=True)\n",
        "fld = 1"
      ],
      "metadata": {
        "id": "vDeyxu2dopqF"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = Adam(learning_rate=0.00001)"
      ],
      "metadata": {
        "id": "8YgJUoEwopqH"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the LSTM model\n",
        "model = Sequential()\n",
        "model.add(LSTM(46, activation='relu', input_shape=(X_reshaped.shape[1], 1), return_sequences=True))\n",
        "model.add(LSTM(30, activation='relu', return_sequences=False))\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ],
      "metadata": {
        "id": "9BnpadylopqJ"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracies = []\n",
        "history = []\n",
        "losses = []\n",
        "val_accuracies = []\n",
        "val_losses = []\n",
        "resultLSTM  = {}\n",
        "\n",
        "for train_index, test_index in kf.split(X):\n",
        "        X_trainV, X_testV = X_df.iloc[train_index], X_df.iloc[test_index]\n",
        "        y_trainV, y_testV = y_df.iloc[train_index], y_df.iloc[test_index]\n",
        "\n",
        "        start_time = time.time()\n",
        "        model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "        early_stopping = EarlyStopping(monitor='val_loss', patience=10, verbose=1, mode='min', restore_best_weights=True)\n",
        "\n",
        "        Training_time = time.time() - start_time\n",
        "\n",
        "        start_time = time.time()\n",
        "        #history = model.fit(X_trainV, y_trainV, epochs=100, batch_size=32, validation_split=0.2)\n",
        "        history = model.fit(X_trainV, y_trainV, validation_data=(X_testV, y_testV), epochs=100, batch_size=32, verbose=1, callbacks=[early_stopping])\n",
        "\n",
        "        Inference_Time = time.time() - start_time\n",
        "\n",
        "        accuracies.append(history.history['accuracy'][-1])\n",
        "        losses.append(history.history['loss'][-1])\n",
        "        val_accuracies.append(history.history['val_accuracy'][-1])\n",
        "        val_losses.append(history.history['val_loss'][-1])\n",
        "\n",
        "        y_predictLSTM = model.predict(X_testV)\n",
        "\n",
        "        y_predictLSTM_binary = np.where(y_predictLSTM > 0.5, 1, 0)\n",
        "\n",
        "        # Now use these binary predictions for calculating metrics\n",
        "        accuracy = accuracy_score(y_testV, y_predictLSTM_binary)\n",
        "        precision = precision_score(y_testV, y_predictLSTM_binary)\n",
        "        recall = recall_score(y_testV, y_predictLSTM_binary)\n",
        "        f1 = f1_score(y_testV, y_predictLSTM_binary)\n",
        "        kappa = cohen_kappa_score(y_testV, y_predictLSTM_binary)\n",
        "        conf_mat = confusion_matrix(y_testV, y_predictLSTM_binary)\n",
        "        roc_auc = roc_auc_score(y_testV, y_predictLSTM_binary)\n",
        "        fpr, tpr, thresholds = roc_curve(y_testV, y_predictLSTM_binary)\n",
        "\n",
        "\n",
        "\n",
        "        resultLSTM[f'Model_{fld}'] = {'Matrix': conf_mat, 'accuracy': accuracy, 'precision': precision,\n",
        "                                  'recall': recall, 'f1': f1, 'kappa': kappa, 'roc_auc': roc_auc,'fpr':fpr\n",
        "                                     ,'tpr':tpr,'thresholds':thresholds,'Inference_Time':Inference_Time,'Training_time':Training_time}\n",
        "\n",
        "\n",
        "        # Print metrics for the LR model\n",
        "        print(f'Metrics for LR Model Fold {fld}:')\n",
        "        print(f\"Inference Time: {Inference_Time:.4f} seconds\")\n",
        "        print(f\"training Time: {Training_time:.4f} seconds\")\n",
        "        print(f\"Accuracy: {accuracy:.2f}\")\n",
        "        print(f\"Precision: {precision:.2f}\")\n",
        "        print(f\"Recall: {recall:.2f}\")\n",
        "        print(f\"F1-score: {f1:.2f}\")\n",
        "        print(f\"kappa: {kappa:.2f}\")\n",
        "        print(f\"ROC AUC: {roc_auc:.2f}\")\n",
        "        print(f\"fpr: {fpr}\")\n",
        "        print(f\"tpr: {tpr}\")\n",
        "        print(f\"thresholds: {thresholds}\")\n",
        "        print(conf_mat)\n",
        "        print(\"********************************************************************\")\n",
        "\n",
        "        fld = fld + 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xVu_JH5gocVJ",
        "outputId": "6324efb4-0824-462a-ff9d-70d0a699a06d"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "823/823 [==============================] - 20s 20ms/step - loss: 0.6553 - accuracy: 0.5912 - val_loss: 0.6425 - val_accuracy: 0.6186\n",
            "Epoch 2/100\n",
            "823/823 [==============================] - 16s 19ms/step - loss: 0.6323 - accuracy: 0.6248 - val_loss: 0.6268 - val_accuracy: 0.6326\n",
            "Epoch 3/100\n",
            "823/823 [==============================] - 17s 21ms/step - loss: 0.6186 - accuracy: 0.6355 - val_loss: 0.6146 - val_accuracy: 0.6449\n",
            "Epoch 4/100\n",
            "823/823 [==============================] - 16s 19ms/step - loss: 0.6044 - accuracy: 0.6528 - val_loss: 0.6000 - val_accuracy: 0.6541\n",
            "Epoch 5/100\n",
            "823/823 [==============================] - 16s 19ms/step - loss: 0.5843 - accuracy: 0.6752 - val_loss: 0.5649 - val_accuracy: 0.7044\n",
            "Epoch 6/100\n",
            "823/823 [==============================] - 16s 19ms/step - loss: 0.5646 - accuracy: 0.6869 - val_loss: 0.5505 - val_accuracy: 0.7088\n",
            "Epoch 7/100\n",
            "823/823 [==============================] - 16s 19ms/step - loss: 0.5431 - accuracy: 0.7048 - val_loss: 0.5299 - val_accuracy: 0.7184\n",
            "Epoch 8/100\n",
            "823/823 [==============================] - 18s 21ms/step - loss: 0.5295 - accuracy: 0.7151 - val_loss: 0.5063 - val_accuracy: 0.7239\n",
            "Epoch 9/100\n",
            "823/823 [==============================] - 16s 19ms/step - loss: 0.5062 - accuracy: 0.7300 - val_loss: 0.4953 - val_accuracy: 0.7430\n",
            "Epoch 10/100\n",
            "823/823 [==============================] - 16s 20ms/step - loss: 0.4803 - accuracy: 0.7501 - val_loss: 0.4624 - val_accuracy: 0.7614\n",
            "Epoch 11/100\n",
            "823/823 [==============================] - 18s 22ms/step - loss: 0.4731 - accuracy: 0.7596 - val_loss: 0.4732 - val_accuracy: 0.7693\n",
            "Epoch 12/100\n",
            "823/823 [==============================] - 16s 19ms/step - loss: 0.4574 - accuracy: 0.7642 - val_loss: 0.4287 - val_accuracy: 0.7925\n",
            "Epoch 13/100\n",
            "823/823 [==============================] - 16s 19ms/step - loss: 0.4473 - accuracy: 0.7693 - val_loss: 0.4349 - val_accuracy: 0.7779\n",
            "Epoch 14/100\n",
            "823/823 [==============================] - 16s 20ms/step - loss: 0.4382 - accuracy: 0.7793 - val_loss: 0.4349 - val_accuracy: 0.7881\n",
            "Epoch 15/100\n",
            "823/823 [==============================] - 17s 20ms/step - loss: 0.4390 - accuracy: 0.7796 - val_loss: 0.4346 - val_accuracy: 0.7792\n",
            "Epoch 16/100\n",
            "823/823 [==============================] - 17s 21ms/step - loss: 0.4319 - accuracy: 0.7800 - val_loss: 0.4328 - val_accuracy: 0.7772\n",
            "Epoch 17/100\n",
            "823/823 [==============================] - 17s 21ms/step - loss: 0.4265 - accuracy: 0.7841 - val_loss: 0.4268 - val_accuracy: 0.7915\n",
            "Epoch 18/100\n",
            "823/823 [==============================] - 17s 21ms/step - loss: 0.4186 - accuracy: 0.7890 - val_loss: 0.4192 - val_accuracy: 0.7905\n",
            "Epoch 19/100\n",
            "823/823 [==============================] - 17s 21ms/step - loss: 0.4175 - accuracy: 0.7901 - val_loss: 0.4153 - val_accuracy: 0.8018\n",
            "Epoch 20/100\n",
            "823/823 [==============================] - 17s 20ms/step - loss: 0.4106 - accuracy: 0.7933 - val_loss: 0.4162 - val_accuracy: 0.8008\n",
            "Epoch 21/100\n",
            "823/823 [==============================] - 17s 21ms/step - loss: 0.4076 - accuracy: 0.7989 - val_loss: 0.4335 - val_accuracy: 0.7765\n",
            "Epoch 22/100\n",
            "823/823 [==============================] - 18s 22ms/step - loss: 0.4098 - accuracy: 0.7956 - val_loss: 0.4000 - val_accuracy: 0.7987\n",
            "Epoch 23/100\n",
            "823/823 [==============================] - 16s 19ms/step - loss: 0.4017 - accuracy: 0.8001 - val_loss: 0.3923 - val_accuracy: 0.8168\n",
            "Epoch 24/100\n",
            "823/823 [==============================] - 16s 19ms/step - loss: 0.3945 - accuracy: 0.8031 - val_loss: 0.4096 - val_accuracy: 0.7915\n",
            "Epoch 25/100\n",
            "823/823 [==============================] - 16s 19ms/step - loss: 0.3950 - accuracy: 0.8048 - val_loss: 0.4030 - val_accuracy: 0.7963\n",
            "Epoch 26/100\n",
            "823/823 [==============================] - 16s 20ms/step - loss: 0.3963 - accuracy: 0.8025 - val_loss: 0.3985 - val_accuracy: 0.8031\n",
            "Epoch 27/100\n",
            "823/823 [==============================] - 16s 20ms/step - loss: 0.3931 - accuracy: 0.8026 - val_loss: 0.3848 - val_accuracy: 0.8182\n",
            "Epoch 28/100\n",
            "823/823 [==============================] - 16s 19ms/step - loss: 0.3935 - accuracy: 0.8024 - val_loss: 0.4061 - val_accuracy: 0.8025\n",
            "Epoch 29/100\n",
            "823/823 [==============================] - 16s 19ms/step - loss: 0.3861 - accuracy: 0.8106 - val_loss: 0.3904 - val_accuracy: 0.8011\n",
            "Epoch 30/100\n",
            "823/823 [==============================] - 16s 19ms/step - loss: 0.3883 - accuracy: 0.8057 - val_loss: 0.4339 - val_accuracy: 0.7796\n",
            "Epoch 31/100\n",
            "823/823 [==============================] - 16s 19ms/step - loss: 0.3860 - accuracy: 0.8095 - val_loss: 0.3813 - val_accuracy: 0.8192\n",
            "Epoch 32/100\n",
            "823/823 [==============================] - 16s 19ms/step - loss: 0.3837 - accuracy: 0.8095 - val_loss: 0.4071 - val_accuracy: 0.8086\n",
            "Epoch 33/100\n",
            "823/823 [==============================] - 16s 19ms/step - loss: 0.3792 - accuracy: 0.8132 - val_loss: 0.3931 - val_accuracy: 0.8035\n",
            "Epoch 34/100\n",
            "823/823 [==============================] - 17s 20ms/step - loss: 0.3793 - accuracy: 0.8131 - val_loss: 0.3885 - val_accuracy: 0.8165\n",
            "Epoch 35/100\n",
            "823/823 [==============================] - 16s 19ms/step - loss: 0.3783 - accuracy: 0.8138 - val_loss: 0.3814 - val_accuracy: 0.8154\n",
            "Epoch 36/100\n",
            "823/823 [==============================] - 16s 19ms/step - loss: 0.3800 - accuracy: 0.8108 - val_loss: 0.4039 - val_accuracy: 0.8011\n",
            "Epoch 37/100\n",
            "823/823 [==============================] - 17s 21ms/step - loss: 0.3772 - accuracy: 0.8140 - val_loss: 0.4168 - val_accuracy: 0.8014\n",
            "Epoch 38/100\n",
            "823/823 [==============================] - 16s 19ms/step - loss: 0.3752 - accuracy: 0.8138 - val_loss: 0.4096 - val_accuracy: 0.7871\n",
            "Epoch 39/100\n",
            "823/823 [==============================] - 16s 19ms/step - loss: 0.3700 - accuracy: 0.8207 - val_loss: 0.3666 - val_accuracy: 0.8305\n",
            "Epoch 40/100\n",
            "823/823 [==============================] - 17s 21ms/step - loss: 0.3717 - accuracy: 0.8186 - val_loss: 0.3668 - val_accuracy: 0.8390\n",
            "Epoch 41/100\n",
            "823/823 [==============================] - 16s 19ms/step - loss: 0.3745 - accuracy: 0.8212 - val_loss: 0.4102 - val_accuracy: 0.7895\n",
            "Epoch 42/100\n",
            "823/823 [==============================] - 16s 19ms/step - loss: 0.3727 - accuracy: 0.8178 - val_loss: 0.3780 - val_accuracy: 0.8100\n",
            "Epoch 43/100\n",
            "823/823 [==============================] - 16s 19ms/step - loss: 0.3678 - accuracy: 0.8229 - val_loss: 0.3750 - val_accuracy: 0.8264\n",
            "Epoch 44/100\n",
            "823/823 [==============================] - 16s 19ms/step - loss: 0.3654 - accuracy: 0.8216 - val_loss: 0.3887 - val_accuracy: 0.8137\n",
            "Epoch 45/100\n",
            "823/823 [==============================] - 16s 19ms/step - loss: 0.3618 - accuracy: 0.8242 - val_loss: 0.3611 - val_accuracy: 0.8298\n",
            "Epoch 46/100\n",
            "823/823 [==============================] - 16s 19ms/step - loss: 0.3599 - accuracy: 0.8273 - val_loss: 0.3987 - val_accuracy: 0.8148\n",
            "Epoch 47/100\n",
            "823/823 [==============================] - 17s 20ms/step - loss: 0.3595 - accuracy: 0.8277 - val_loss: 0.3656 - val_accuracy: 0.8353\n",
            "Epoch 48/100\n",
            "823/823 [==============================] - 17s 21ms/step - loss: 0.3591 - accuracy: 0.8257 - val_loss: 0.3592 - val_accuracy: 0.8349\n",
            "Epoch 49/100\n",
            "823/823 [==============================] - 17s 21ms/step - loss: 0.3554 - accuracy: 0.8273 - val_loss: 0.3610 - val_accuracy: 0.8216\n",
            "Epoch 50/100\n",
            "823/823 [==============================] - 17s 21ms/step - loss: 0.3621 - accuracy: 0.8238 - val_loss: 0.3865 - val_accuracy: 0.8096\n",
            "Epoch 51/100\n",
            "823/823 [==============================] - 21s 25ms/step - loss: 0.3526 - accuracy: 0.8292 - val_loss: 0.3633 - val_accuracy: 0.8312\n",
            "Epoch 52/100\n",
            "823/823 [==============================] - 18s 22ms/step - loss: 0.3518 - accuracy: 0.8292 - val_loss: 0.3626 - val_accuracy: 0.8257\n",
            "Epoch 53/100\n",
            "823/823 [==============================] - 17s 21ms/step - loss: 0.3542 - accuracy: 0.8311 - val_loss: 0.3676 - val_accuracy: 0.8161\n",
            "Epoch 54/100\n",
            "823/823 [==============================] - 19s 23ms/step - loss: 0.3564 - accuracy: 0.8335 - val_loss: 0.3888 - val_accuracy: 0.8093\n",
            "Epoch 55/100\n",
            "823/823 [==============================] - 18s 22ms/step - loss: 0.3614 - accuracy: 0.8315 - val_loss: 0.3676 - val_accuracy: 0.8267\n",
            "Epoch 56/100\n",
            "823/823 [==============================] - 16s 20ms/step - loss: 0.3481 - accuracy: 0.8321 - val_loss: 0.3555 - val_accuracy: 0.8288\n",
            "Epoch 57/100\n",
            "823/823 [==============================] - 16s 20ms/step - loss: 0.3490 - accuracy: 0.8300 - val_loss: 0.3758 - val_accuracy: 0.7772\n",
            "Epoch 58/100\n",
            "823/823 [==============================] - 16s 20ms/step - loss: 0.3567 - accuracy: 0.8320 - val_loss: 0.3705 - val_accuracy: 0.8342\n",
            "Epoch 59/100\n",
            "823/823 [==============================] - 16s 20ms/step - loss: 0.3521 - accuracy: 0.8319 - val_loss: 0.3618 - val_accuracy: 0.8298\n",
            "Epoch 60/100\n",
            "823/823 [==============================] - 17s 21ms/step - loss: 0.3485 - accuracy: 0.8336 - val_loss: 0.3483 - val_accuracy: 0.8353\n",
            "Epoch 61/100\n",
            "823/823 [==============================] - 17s 20ms/step - loss: 0.3465 - accuracy: 0.8313 - val_loss: 0.3771 - val_accuracy: 0.8134\n",
            "Epoch 62/100\n",
            "823/823 [==============================] - 16s 19ms/step - loss: 0.3500 - accuracy: 0.8295 - val_loss: 0.3487 - val_accuracy: 0.8476\n",
            "Epoch 63/100\n",
            "823/823 [==============================] - 16s 20ms/step - loss: 0.3419 - accuracy: 0.8358 - val_loss: 0.3535 - val_accuracy: 0.8301\n",
            "Epoch 64/100\n",
            "823/823 [==============================] - 16s 20ms/step - loss: 0.3408 - accuracy: 0.8348 - val_loss: 0.3688 - val_accuracy: 0.8233\n",
            "Epoch 65/100\n",
            "823/823 [==============================] - 20s 24ms/step - loss: 0.3420 - accuracy: 0.8333 - val_loss: 0.3550 - val_accuracy: 0.8411\n",
            "Epoch 66/100\n",
            "823/823 [==============================] - 17s 21ms/step - loss: 0.3400 - accuracy: 0.8377 - val_loss: 0.3925 - val_accuracy: 0.8325\n",
            "Epoch 67/100\n",
            "823/823 [==============================] - 16s 20ms/step - loss: 0.3389 - accuracy: 0.8375 - val_loss: 0.3600 - val_accuracy: 0.8298\n",
            "Epoch 68/100\n",
            "823/823 [==============================] - 17s 20ms/step - loss: 0.3389 - accuracy: 0.8339 - val_loss: 0.3594 - val_accuracy: 0.8353\n",
            "Epoch 69/100\n",
            "823/823 [==============================] - 17s 20ms/step - loss: 0.3491 - accuracy: 0.8372 - val_loss: 0.3636 - val_accuracy: 0.7850\n",
            "Epoch 70/100\n",
            "822/823 [============================>.] - ETA: 0s - loss: 0.3376 - accuracy: 0.8377Restoring model weights from the end of the best epoch: 60.\n",
            "823/823 [==============================] - 17s 21ms/step - loss: 0.3376 - accuracy: 0.8377 - val_loss: 0.3684 - val_accuracy: 0.8295\n",
            "Epoch 70: early stopping\n",
            "92/92 [==============================] - 1s 6ms/step\n",
            "Metrics for LR Model Fold 1:\n",
            "Inference Time: 1169.1041 seconds\n",
            "training Time: 0.0100 seconds\n",
            "Accuracy: 0.84\n",
            "Precision: 0.80\n",
            "Recall: 0.90\n",
            "F1-score: 0.85\n",
            "kappa: 0.67\n",
            "ROC AUC: 0.83\n",
            "fpr: [0.        0.2284334 1.       ]\n",
            "tpr: [0.         0.89776574 1.        ]\n",
            "thresholds: [2 1 0]\n",
            "[[1118  331]\n",
            " [ 151 1326]]\n",
            "********************************************************************\n",
            "Epoch 1/100\n",
            "823/823 [==============================] - 22s 23ms/step - loss: 0.3654 - accuracy: 0.8298 - val_loss: 0.5449 - val_accuracy: 0.8202\n",
            "Epoch 2/100\n",
            "823/823 [==============================] - 18s 22ms/step - loss: 0.3498 - accuracy: 0.8311 - val_loss: 0.3328 - val_accuracy: 0.8305\n",
            "Epoch 3/100\n",
            "823/823 [==============================] - 17s 20ms/step - loss: 0.3363 - accuracy: 0.8400 - val_loss: 0.3308 - val_accuracy: 0.8476\n",
            "Epoch 4/100\n",
            "823/823 [==============================] - 16s 20ms/step - loss: 0.3405 - accuracy: 0.8355 - val_loss: 0.3272 - val_accuracy: 0.8401\n",
            "Epoch 5/100\n",
            "823/823 [==============================] - 16s 20ms/step - loss: 0.3359 - accuracy: 0.8388 - val_loss: 0.3545 - val_accuracy: 0.8213\n",
            "Epoch 6/100\n",
            "823/823 [==============================] - 17s 21ms/step - loss: 0.3390 - accuracy: 0.8357 - val_loss: 0.3329 - val_accuracy: 0.8459\n",
            "Epoch 7/100\n",
            "823/823 [==============================] - 16s 19ms/step - loss: 0.3386 - accuracy: 0.8364 - val_loss: 0.3433 - val_accuracy: 0.8428\n",
            "Epoch 8/100\n",
            "823/823 [==============================] - 17s 21ms/step - loss: 0.3377 - accuracy: 0.8397 - val_loss: 0.3313 - val_accuracy: 0.8360\n",
            "Epoch 9/100\n",
            "823/823 [==============================] - 16s 19ms/step - loss: 0.3394 - accuracy: 0.8385 - val_loss: 0.3348 - val_accuracy: 0.8377\n",
            "Epoch 10/100\n",
            "823/823 [==============================] - 16s 19ms/step - loss: 0.3410 - accuracy: 0.8387 - val_loss: 0.3674 - val_accuracy: 0.8131\n",
            "Epoch 11/100\n",
            "823/823 [==============================] - 15s 19ms/step - loss: 0.3361 - accuracy: 0.8410 - val_loss: 0.3312 - val_accuracy: 0.8411\n",
            "Epoch 12/100\n",
            "823/823 [==============================] - 17s 20ms/step - loss: 0.3320 - accuracy: 0.8423 - val_loss: 0.3253 - val_accuracy: 0.8397\n",
            "Epoch 13/100\n",
            "823/823 [==============================] - 16s 20ms/step - loss: 0.3352 - accuracy: 0.8391 - val_loss: 0.3292 - val_accuracy: 0.8397\n",
            "Epoch 14/100\n",
            "823/823 [==============================] - 16s 19ms/step - loss: 0.3371 - accuracy: 0.8379 - val_loss: 0.3295 - val_accuracy: 0.8472\n",
            "Epoch 15/100\n",
            "823/823 [==============================] - 15s 19ms/step - loss: 0.3370 - accuracy: 0.8378 - val_loss: 0.3534 - val_accuracy: 0.8250\n",
            "Epoch 16/100\n",
            "823/823 [==============================] - 16s 19ms/step - loss: 0.3331 - accuracy: 0.8399 - val_loss: 0.3239 - val_accuracy: 0.8465\n",
            "Epoch 17/100\n",
            "823/823 [==============================] - 16s 19ms/step - loss: 0.3339 - accuracy: 0.8413 - val_loss: 0.3330 - val_accuracy: 0.8383\n",
            "Epoch 18/100\n",
            "823/823 [==============================] - 16s 19ms/step - loss: 0.3320 - accuracy: 0.8413 - val_loss: 0.3266 - val_accuracy: 0.8483\n",
            "Epoch 19/100\n",
            "823/823 [==============================] - 16s 19ms/step - loss: 0.3378 - accuracy: 0.8365 - val_loss: 0.3448 - val_accuracy: 0.8336\n",
            "Epoch 20/100\n",
            "823/823 [==============================] - 17s 20ms/step - loss: 0.3335 - accuracy: 0.8400 - val_loss: 0.3582 - val_accuracy: 0.8295\n",
            "Epoch 21/100\n",
            "823/823 [==============================] - 16s 20ms/step - loss: 0.3336 - accuracy: 0.8426 - val_loss: 0.3698 - val_accuracy: 0.8035\n",
            "Epoch 22/100\n",
            "823/823 [==============================] - 16s 19ms/step - loss: 0.3330 - accuracy: 0.8381 - val_loss: 0.3395 - val_accuracy: 0.8301\n",
            "Epoch 23/100\n",
            "823/823 [==============================] - 18s 22ms/step - loss: 0.3334 - accuracy: 0.8431 - val_loss: 0.3366 - val_accuracy: 0.8298\n",
            "Epoch 24/100\n",
            "823/823 [==============================] - 16s 20ms/step - loss: 0.3313 - accuracy: 0.8412 - val_loss: 0.3587 - val_accuracy: 0.8284\n",
            "Epoch 25/100\n",
            "823/823 [==============================] - 16s 20ms/step - loss: 0.3281 - accuracy: 0.8436 - val_loss: 0.3349 - val_accuracy: 0.8489\n",
            "Epoch 26/100\n",
            "822/823 [============================>.] - ETA: 0s - loss: 0.3330 - accuracy: 0.8372Restoring model weights from the end of the best epoch: 16.\n",
            "823/823 [==============================] - 16s 20ms/step - loss: 0.3330 - accuracy: 0.8372 - val_loss: 0.3522 - val_accuracy: 0.8363\n",
            "Epoch 26: early stopping\n",
            "92/92 [==============================] - 1s 6ms/step\n",
            "Metrics for LR Model Fold 2:\n",
            "Inference Time: 432.9876 seconds\n",
            "training Time: 0.0073 seconds\n",
            "Accuracy: 0.85\n",
            "Precision: 0.82\n",
            "Recall: 0.89\n",
            "F1-score: 0.85\n",
            "kappa: 0.69\n",
            "ROC AUC: 0.85\n",
            "fpr: [0.         0.19715447 1.        ]\n",
            "tpr: [0.         0.89103448 1.        ]\n",
            "thresholds: [2 1 0]\n",
            "[[1185  291]\n",
            " [ 158 1292]]\n",
            "********************************************************************\n",
            "Epoch 1/100\n",
            "823/823 [==============================] - 20s 20ms/step - loss: 0.3346 - accuracy: 0.8400 - val_loss: 0.3322 - val_accuracy: 0.8455\n",
            "Epoch 2/100\n",
            "823/823 [==============================] - 16s 19ms/step - loss: 0.3379 - accuracy: 0.8374 - val_loss: 0.3504 - val_accuracy: 0.8397\n",
            "Epoch 3/100\n",
            "823/823 [==============================] - 16s 19ms/step - loss: 0.3370 - accuracy: 0.8359 - val_loss: 0.3215 - val_accuracy: 0.8558\n",
            "Epoch 4/100\n",
            "823/823 [==============================] - 16s 19ms/step - loss: 0.3393 - accuracy: 0.8371 - val_loss: 0.3241 - val_accuracy: 0.8565\n",
            "Epoch 5/100\n",
            "823/823 [==============================] - 16s 19ms/step - loss: 0.3331 - accuracy: 0.8398 - val_loss: 0.3371 - val_accuracy: 0.8455\n",
            "Epoch 6/100\n",
            "823/823 [==============================] - 16s 19ms/step - loss: 0.3355 - accuracy: 0.8392 - val_loss: 0.3245 - val_accuracy: 0.8554\n",
            "Epoch 7/100\n",
            "823/823 [==============================] - 18s 22ms/step - loss: 0.3276 - accuracy: 0.8407 - val_loss: 0.3321 - val_accuracy: 0.8513\n",
            "Epoch 8/100\n",
            "823/823 [==============================] - 16s 20ms/step - loss: 0.3277 - accuracy: 0.8409 - val_loss: 0.3297 - val_accuracy: 0.8565\n",
            "Epoch 9/100\n",
            "823/823 [==============================] - 17s 20ms/step - loss: 0.3295 - accuracy: 0.8394 - val_loss: 0.3469 - val_accuracy: 0.7943\n",
            "Epoch 10/100\n",
            "823/823 [==============================] - 19s 23ms/step - loss: 0.3299 - accuracy: 0.8395 - val_loss: 0.3407 - val_accuracy: 0.8394\n",
            "Epoch 11/100\n",
            "823/823 [==============================] - 16s 20ms/step - loss: 0.3285 - accuracy: 0.8417 - val_loss: 0.3266 - val_accuracy: 0.8510\n",
            "Epoch 12/100\n",
            "823/823 [==============================] - 16s 20ms/step - loss: 0.3288 - accuracy: 0.8423 - val_loss: 0.3263 - val_accuracy: 0.8503\n",
            "Epoch 13/100\n",
            "821/823 [============================>.] - ETA: 0s - loss: 0.3255 - accuracy: 0.8439Restoring model weights from the end of the best epoch: 3.\n",
            "823/823 [==============================] - 17s 21ms/step - loss: 0.3254 - accuracy: 0.8440 - val_loss: 0.3347 - val_accuracy: 0.8397\n",
            "Epoch 13: early stopping\n",
            "92/92 [==============================] - 1s 8ms/step\n",
            "Metrics for LR Model Fold 3:\n",
            "Inference Time: 223.0796 seconds\n",
            "training Time: 0.0070 seconds\n",
            "Accuracy: 0.86\n",
            "Precision: 0.83\n",
            "Recall: 0.91\n",
            "F1-score: 0.87\n",
            "kappa: 0.71\n",
            "ROC AUC: 0.85\n",
            "fpr: [0.         0.19832985 1.        ]\n",
            "tpr: [0.         0.90799194 1.        ]\n",
            "thresholds: [2 1 0]\n",
            "[[1152  285]\n",
            " [ 137 1352]]\n",
            "********************************************************************\n",
            "Epoch 1/100\n",
            "823/823 [==============================] - 20s 21ms/step - loss: 0.3586 - accuracy: 0.8372 - val_loss: 0.3416 - val_accuracy: 0.8322\n",
            "Epoch 2/100\n",
            "823/823 [==============================] - 16s 19ms/step - loss: 0.3356 - accuracy: 0.8400 - val_loss: 0.3457 - val_accuracy: 0.8332\n",
            "Epoch 3/100\n",
            "823/823 [==============================] - 17s 21ms/step - loss: 0.3357 - accuracy: 0.8374 - val_loss: 0.3225 - val_accuracy: 0.8479\n",
            "Epoch 4/100\n",
            "823/823 [==============================] - 16s 20ms/step - loss: 0.3282 - accuracy: 0.8435 - val_loss: 0.3523 - val_accuracy: 0.8288\n",
            "Epoch 5/100\n",
            "823/823 [==============================] - 16s 20ms/step - loss: 0.3287 - accuracy: 0.8426 - val_loss: 0.3382 - val_accuracy: 0.8366\n",
            "Epoch 6/100\n",
            "823/823 [==============================] - 16s 20ms/step - loss: 0.3334 - accuracy: 0.8398 - val_loss: 0.3517 - val_accuracy: 0.8291\n",
            "Epoch 7/100\n",
            "823/823 [==============================] - 17s 20ms/step - loss: 0.3292 - accuracy: 0.8413 - val_loss: 0.3430 - val_accuracy: 0.8349\n",
            "Epoch 8/100\n",
            "823/823 [==============================] - 18s 22ms/step - loss: 0.3288 - accuracy: 0.8430 - val_loss: 0.3356 - val_accuracy: 0.8322\n",
            "Epoch 9/100\n",
            "823/823 [==============================] - 17s 21ms/step - loss: 0.3252 - accuracy: 0.8439 - val_loss: 0.3288 - val_accuracy: 0.8486\n",
            "Epoch 10/100\n",
            "823/823 [==============================] - 16s 20ms/step - loss: 0.3252 - accuracy: 0.8446 - val_loss: 0.3544 - val_accuracy: 0.8195\n",
            "Epoch 11/100\n",
            "823/823 [==============================] - 16s 20ms/step - loss: 0.3276 - accuracy: 0.8429 - val_loss: 0.3525 - val_accuracy: 0.8315\n",
            "Epoch 12/100\n",
            "823/823 [==============================] - 16s 20ms/step - loss: 0.3285 - accuracy: 0.8439 - val_loss: 0.3267 - val_accuracy: 0.8455\n",
            "Epoch 13/100\n",
            "821/823 [============================>.] - ETA: 0s - loss: 0.3247 - accuracy: 0.8453Restoring model weights from the end of the best epoch: 3.\n",
            "823/823 [==============================] - 16s 20ms/step - loss: 0.3248 - accuracy: 0.8451 - val_loss: 0.3370 - val_accuracy: 0.8421\n",
            "Epoch 13: early stopping\n",
            "92/92 [==============================] - 1s 7ms/step\n",
            "Metrics for LR Model Fold 4:\n",
            "Inference Time: 223.8866 seconds\n",
            "training Time: 0.0131 seconds\n",
            "Accuracy: 0.85\n",
            "Precision: 0.81\n",
            "Recall: 0.90\n",
            "F1-score: 0.85\n",
            "kappa: 0.70\n",
            "ROC AUC: 0.85\n",
            "fpr: [0.         0.19786096 1.        ]\n",
            "tpr: [0.        0.8958042 1.       ]\n",
            "thresholds: [2 1 0]\n",
            "[[1200  296]\n",
            " [ 149 1281]]\n",
            "********************************************************************\n",
            "Epoch 1/100\n",
            "823/823 [==============================] - 20s 21ms/step - loss: 0.3299 - accuracy: 0.8429 - val_loss: 0.3270 - val_accuracy: 0.8485\n",
            "Epoch 2/100\n",
            "823/823 [==============================] - 17s 20ms/step - loss: 0.3320 - accuracy: 0.8402 - val_loss: 0.3221 - val_accuracy: 0.8465\n",
            "Epoch 3/100\n",
            "823/823 [==============================] - 18s 21ms/step - loss: 0.3320 - accuracy: 0.8387 - val_loss: 0.3156 - val_accuracy: 0.8547\n",
            "Epoch 4/100\n",
            "823/823 [==============================] - 17s 20ms/step - loss: 0.3264 - accuracy: 0.8440 - val_loss: 0.3274 - val_accuracy: 0.8421\n",
            "Epoch 5/100\n",
            "823/823 [==============================] - 18s 22ms/step - loss: 0.3299 - accuracy: 0.8396 - val_loss: 0.3326 - val_accuracy: 0.8465\n",
            "Epoch 6/100\n",
            "823/823 [==============================] - 16s 20ms/step - loss: 0.3289 - accuracy: 0.8392 - val_loss: 0.3370 - val_accuracy: 0.8373\n",
            "Epoch 7/100\n",
            "823/823 [==============================] - 16s 20ms/step - loss: 0.3311 - accuracy: 0.8405 - val_loss: 0.3364 - val_accuracy: 0.8359\n",
            "Epoch 8/100\n",
            "823/823 [==============================] - 16s 20ms/step - loss: 0.3281 - accuracy: 0.8415 - val_loss: 0.3197 - val_accuracy: 0.8503\n",
            "Epoch 9/100\n",
            "823/823 [==============================] - 17s 21ms/step - loss: 0.3300 - accuracy: 0.8398 - val_loss: 0.3190 - val_accuracy: 0.8458\n",
            "Epoch 10/100\n",
            "823/823 [==============================] - 17s 20ms/step - loss: 0.3394 - accuracy: 0.8411 - val_loss: 0.3143 - val_accuracy: 0.8547\n",
            "Epoch 11/100\n",
            "823/823 [==============================] - 16s 20ms/step - loss: 0.3314 - accuracy: 0.8415 - val_loss: 0.3616 - val_accuracy: 0.8308\n",
            "Epoch 12/100\n",
            "823/823 [==============================] - 16s 20ms/step - loss: 0.3260 - accuracy: 0.8434 - val_loss: 0.3230 - val_accuracy: 0.8482\n",
            "Epoch 13/100\n",
            "823/823 [==============================] - 16s 19ms/step - loss: 0.3289 - accuracy: 0.8434 - val_loss: 0.3351 - val_accuracy: 0.8386\n",
            "Epoch 14/100\n",
            "823/823 [==============================] - 16s 20ms/step - loss: 0.3285 - accuracy: 0.8422 - val_loss: 0.3392 - val_accuracy: 0.8444\n",
            "Epoch 15/100\n",
            "823/823 [==============================] - 17s 21ms/step - loss: 0.3257 - accuracy: 0.8436 - val_loss: 0.3246 - val_accuracy: 0.8516\n",
            "Epoch 16/100\n",
            "823/823 [==============================] - 17s 21ms/step - loss: 0.3231 - accuracy: 0.8444 - val_loss: 0.3228 - val_accuracy: 0.8557\n",
            "Epoch 17/100\n",
            "823/823 [==============================] - 17s 21ms/step - loss: 0.3263 - accuracy: 0.8428 - val_loss: 0.3194 - val_accuracy: 0.8557\n",
            "Epoch 18/100\n",
            "823/823 [==============================] - 17s 20ms/step - loss: 0.3243 - accuracy: 0.8424 - val_loss: 0.3295 - val_accuracy: 0.8516\n",
            "Epoch 19/100\n",
            "823/823 [==============================] - 18s 22ms/step - loss: 0.3276 - accuracy: 0.8436 - val_loss: 0.3257 - val_accuracy: 0.8523\n",
            "Epoch 20/100\n",
            "823/823 [==============================] - ETA: 0s - loss: 0.3230 - accuracy: 0.8433Restoring model weights from the end of the best epoch: 10.\n",
            "823/823 [==============================] - 18s 22ms/step - loss: 0.3230 - accuracy: 0.8433 - val_loss: 0.3232 - val_accuracy: 0.8489\n",
            "Epoch 20: early stopping\n",
            "92/92 [==============================] - 1s 6ms/step\n",
            "Metrics for LR Model Fold 5:\n",
            "Inference Time: 346.4400 seconds\n",
            "training Time: 0.0087 seconds\n",
            "Accuracy: 0.85\n",
            "Precision: 0.81\n",
            "Recall: 0.92\n",
            "F1-score: 0.86\n",
            "kappa: 0.71\n",
            "ROC AUC: 0.86\n",
            "fpr: [0.         0.20682731 1.        ]\n",
            "tpr: [0.         0.91893781 1.        ]\n",
            "thresholds: [2 1 0]\n",
            "[[1185  309]\n",
            " [ 116 1315]]\n",
            "********************************************************************\n",
            "Epoch 1/100\n",
            "823/823 [==============================] - 22s 24ms/step - loss: 0.3342 - accuracy: 0.8396 - val_loss: 0.3213 - val_accuracy: 0.8544\n",
            "Epoch 2/100\n",
            "823/823 [==============================] - 17s 21ms/step - loss: 0.3314 - accuracy: 0.8400 - val_loss: 0.3202 - val_accuracy: 0.8465\n",
            "Epoch 3/100\n",
            "823/823 [==============================] - 16s 20ms/step - loss: 0.3282 - accuracy: 0.8404 - val_loss: 0.3178 - val_accuracy: 0.8499\n",
            "Epoch 4/100\n",
            "823/823 [==============================] - 16s 20ms/step - loss: 0.3297 - accuracy: 0.8432 - val_loss: 0.3489 - val_accuracy: 0.8304\n",
            "Epoch 5/100\n",
            "823/823 [==============================] - 17s 20ms/step - loss: 1.9444 - accuracy: 0.8194 - val_loss: 0.8294 - val_accuracy: 0.8496\n",
            "Epoch 6/100\n",
            "823/823 [==============================] - 18s 21ms/step - loss: 1.7438 - accuracy: 0.8257 - val_loss: 1.8772 - val_accuracy: 0.8455\n",
            "Epoch 7/100\n",
            "823/823 [==============================] - 16s 20ms/step - loss: 0.7987 - accuracy: 0.8175 - val_loss: 0.8803 - val_accuracy: 0.8243\n",
            "Epoch 8/100\n",
            "823/823 [==============================] - 17s 20ms/step - loss: 0.4062 - accuracy: 0.8229 - val_loss: 0.3609 - val_accuracy: 0.8427\n",
            "Epoch 9/100\n",
            "823/823 [==============================] - 16s 20ms/step - loss: 0.3598 - accuracy: 0.8335 - val_loss: 0.3474 - val_accuracy: 0.8431\n",
            "Epoch 10/100\n",
            "823/823 [==============================] - 17s 20ms/step - loss: 0.3464 - accuracy: 0.8382 - val_loss: 0.3378 - val_accuracy: 0.8564\n",
            "Epoch 11/100\n",
            "823/823 [==============================] - 18s 22ms/step - loss: 0.3419 - accuracy: 0.8406 - val_loss: 0.3525 - val_accuracy: 0.8441\n",
            "Epoch 12/100\n",
            "823/823 [==============================] - 19s 23ms/step - loss: 0.3382 - accuracy: 0.8415 - val_loss: 0.3319 - val_accuracy: 0.8506\n",
            "Epoch 13/100\n",
            "821/823 [============================>.] - ETA: 0s - loss: 0.3372 - accuracy: 0.8406Restoring model weights from the end of the best epoch: 3.\n",
            "823/823 [==============================] - 17s 20ms/step - loss: 0.3371 - accuracy: 0.8406 - val_loss: 0.3229 - val_accuracy: 0.8581\n",
            "Epoch 13: early stopping\n",
            "92/92 [==============================] - 1s 7ms/step\n",
            "Metrics for LR Model Fold 6:\n",
            "Inference Time: 229.6836 seconds\n",
            "training Time: 0.0088 seconds\n",
            "Accuracy: 0.85\n",
            "Precision: 0.81\n",
            "Recall: 0.93\n",
            "F1-score: 0.87\n",
            "kappa: 0.70\n",
            "ROC AUC: 0.85\n",
            "fpr: [0.         0.23650568 1.        ]\n",
            "tpr: [0.         0.93012525 1.        ]\n",
            "thresholds: [2 1 0]\n",
            "[[1075  333]\n",
            " [ 106 1411]]\n",
            "********************************************************************\n",
            "Epoch 1/100\n",
            "823/823 [==============================] - 22s 21ms/step - loss: 0.3275 - accuracy: 0.8433 - val_loss: 0.3200 - val_accuracy: 0.8376\n",
            "Epoch 2/100\n",
            "823/823 [==============================] - 17s 20ms/step - loss: 0.3238 - accuracy: 0.8450 - val_loss: 0.3465 - val_accuracy: 0.8267\n",
            "Epoch 3/100\n",
            "823/823 [==============================] - 18s 21ms/step - loss: 0.3238 - accuracy: 0.8437 - val_loss: 0.3213 - val_accuracy: 0.8356\n",
            "Epoch 4/100\n",
            "823/823 [==============================] - 18s 21ms/step - loss: 0.3377 - accuracy: 0.8445 - val_loss: 0.3335 - val_accuracy: 0.8379\n",
            "Epoch 5/100\n",
            "823/823 [==============================] - 17s 20ms/step - loss: 0.3352 - accuracy: 0.8455 - val_loss: 0.3324 - val_accuracy: 0.8369\n",
            "Epoch 6/100\n",
            "823/823 [==============================] - 17s 20ms/step - loss: 0.3236 - accuracy: 0.8469 - val_loss: 0.3333 - val_accuracy: 0.8291\n",
            "Epoch 7/100\n",
            "823/823 [==============================] - 17s 21ms/step - loss: 0.3219 - accuracy: 0.8471 - val_loss: 0.3175 - val_accuracy: 0.8369\n",
            "Epoch 8/100\n",
            "823/823 [==============================] - 18s 22ms/step - loss: 0.3205 - accuracy: 0.8466 - val_loss: 0.3287 - val_accuracy: 0.8359\n",
            "Epoch 9/100\n",
            "823/823 [==============================] - 17s 21ms/step - loss: 0.3189 - accuracy: 0.8466 - val_loss: 0.3341 - val_accuracy: 0.8400\n",
            "Epoch 10/100\n",
            "823/823 [==============================] - 17s 20ms/step - loss: 0.3259 - accuracy: 0.8462 - val_loss: 0.3605 - val_accuracy: 0.8345\n",
            "Epoch 11/100\n",
            "823/823 [==============================] - 17s 20ms/step - loss: 0.3194 - accuracy: 0.8463 - val_loss: 0.3315 - val_accuracy: 0.8356\n",
            "Epoch 12/100\n",
            "823/823 [==============================] - 19s 23ms/step - loss: 0.3189 - accuracy: 0.8473 - val_loss: 0.3340 - val_accuracy: 0.8383\n",
            "Epoch 13/100\n",
            "823/823 [==============================] - 18s 22ms/step - loss: 0.3292 - accuracy: 0.8462 - val_loss: 0.3289 - val_accuracy: 0.8342\n",
            "Epoch 14/100\n",
            "823/823 [==============================] - 18s 22ms/step - loss: 0.3217 - accuracy: 0.8459 - val_loss: 0.3268 - val_accuracy: 0.8376\n",
            "Epoch 15/100\n",
            "823/823 [==============================] - 18s 21ms/step - loss: 0.3205 - accuracy: 0.8475 - val_loss: 0.3473 - val_accuracy: 0.8328\n",
            "Epoch 16/100\n",
            "823/823 [==============================] - 17s 21ms/step - loss: 0.3211 - accuracy: 0.8463 - val_loss: 0.3179 - val_accuracy: 0.8373\n",
            "Epoch 17/100\n",
            "822/823 [============================>.] - ETA: 0s - loss: 0.3139 - accuracy: 0.8522Restoring model weights from the end of the best epoch: 7.\n",
            "823/823 [==============================] - 17s 21ms/step - loss: 0.3139 - accuracy: 0.8522 - val_loss: 0.3490 - val_accuracy: 0.8345\n",
            "Epoch 17: early stopping\n",
            "92/92 [==============================] - 1s 6ms/step\n",
            "Metrics for LR Model Fold 7:\n",
            "Inference Time: 304.9962 seconds\n",
            "training Time: 0.0087 seconds\n",
            "Accuracy: 0.84\n",
            "Precision: 0.80\n",
            "Recall: 0.90\n",
            "F1-score: 0.85\n",
            "kappa: 0.67\n",
            "ROC AUC: 0.84\n",
            "fpr: [0.         0.23076923 1.        ]\n",
            "tpr: [0.         0.90401634 1.        ]\n",
            "thresholds: [2 1 0]\n",
            "[[1120  336]\n",
            " [ 141 1328]]\n",
            "********************************************************************\n",
            "Epoch 1/100\n",
            "823/823 [==============================] - 22s 23ms/step - loss: 0.3248 - accuracy: 0.8437 - val_loss: 0.3212 - val_accuracy: 0.8485\n",
            "Epoch 2/100\n",
            "823/823 [==============================] - 17s 20ms/step - loss: 0.3248 - accuracy: 0.8438 - val_loss: 0.3085 - val_accuracy: 0.8557\n",
            "Epoch 3/100\n",
            "823/823 [==============================] - 17s 20ms/step - loss: 0.3329 - accuracy: 0.8427 - val_loss: 0.3147 - val_accuracy: 0.8612\n",
            "Epoch 4/100\n",
            "823/823 [==============================] - 17s 20ms/step - loss: 0.3285 - accuracy: 0.8422 - val_loss: 0.3181 - val_accuracy: 0.8455\n",
            "Epoch 5/100\n",
            "823/823 [==============================] - 17s 20ms/step - loss: 0.3290 - accuracy: 0.8420 - val_loss: 0.3216 - val_accuracy: 0.8462\n",
            "Epoch 6/100\n",
            "823/823 [==============================] - 20s 24ms/step - loss: 0.3224 - accuracy: 0.8452 - val_loss: 0.3089 - val_accuracy: 0.8574\n",
            "Epoch 7/100\n",
            "823/823 [==============================] - 16s 20ms/step - loss: 0.3221 - accuracy: 0.8448 - val_loss: 0.3043 - val_accuracy: 0.8574\n",
            "Epoch 8/100\n",
            "823/823 [==============================] - 17s 20ms/step - loss: 0.3208 - accuracy: 0.8462 - val_loss: 0.3094 - val_accuracy: 0.8509\n",
            "Epoch 9/100\n",
            "823/823 [==============================] - 17s 20ms/step - loss: 0.3204 - accuracy: 0.8447 - val_loss: 0.3035 - val_accuracy: 0.8561\n",
            "Epoch 10/100\n",
            "823/823 [==============================] - 17s 20ms/step - loss: 0.3205 - accuracy: 0.8455 - val_loss: 0.3119 - val_accuracy: 0.8520\n",
            "Epoch 11/100\n",
            "823/823 [==============================] - 18s 22ms/step - loss: 0.3213 - accuracy: 0.8441 - val_loss: 0.3013 - val_accuracy: 0.8612\n",
            "Epoch 12/100\n",
            "823/823 [==============================] - 17s 20ms/step - loss: 0.3212 - accuracy: 0.8455 - val_loss: 0.3025 - val_accuracy: 0.8568\n",
            "Epoch 13/100\n",
            "823/823 [==============================] - 17s 20ms/step - loss: 0.3181 - accuracy: 0.8472 - val_loss: 0.3080 - val_accuracy: 0.8503\n",
            "Epoch 14/100\n",
            "823/823 [==============================] - 17s 20ms/step - loss: 0.3181 - accuracy: 0.8472 - val_loss: 0.3129 - val_accuracy: 0.8468\n",
            "Epoch 15/100\n",
            "823/823 [==============================] - 17s 20ms/step - loss: 0.3212 - accuracy: 0.8447 - val_loss: 0.3220 - val_accuracy: 0.8441\n",
            "Epoch 16/100\n",
            "823/823 [==============================] - 18s 22ms/step - loss: 0.3270 - accuracy: 0.8438 - val_loss: 0.3070 - val_accuracy: 0.8523\n",
            "Epoch 17/100\n",
            "823/823 [==============================] - 17s 21ms/step - loss: 0.3254 - accuracy: 0.8476 - val_loss: 0.3040 - val_accuracy: 0.8509\n",
            "Epoch 18/100\n",
            "823/823 [==============================] - 17s 20ms/step - loss: 0.3146 - accuracy: 0.8483 - val_loss: 0.3171 - val_accuracy: 0.8479\n",
            "Epoch 19/100\n",
            "823/823 [==============================] - 16s 20ms/step - loss: 0.3154 - accuracy: 0.8483 - val_loss: 0.3249 - val_accuracy: 0.8362\n",
            "Epoch 20/100\n",
            "823/823 [==============================] - 18s 22ms/step - loss: 0.3149 - accuracy: 0.8469 - val_loss: 0.3080 - val_accuracy: 0.8499\n",
            "Epoch 21/100\n",
            "822/823 [============================>.] - ETA: 0s - loss: 0.3145 - accuracy: 0.8509Restoring model weights from the end of the best epoch: 11.\n",
            "823/823 [==============================] - 17s 20ms/step - loss: 0.3144 - accuracy: 0.8510 - val_loss: 0.3168 - val_accuracy: 0.8462\n",
            "Epoch 21: early stopping\n",
            "92/92 [==============================] - 1s 6ms/step\n",
            "Metrics for LR Model Fold 8:\n",
            "Inference Time: 366.4057 seconds\n",
            "training Time: 0.0093 seconds\n",
            "Accuracy: 0.86\n",
            "Precision: 0.82\n",
            "Recall: 0.93\n",
            "F1-score: 0.87\n",
            "kappa: 0.72\n",
            "ROC AUC: 0.86\n",
            "fpr: [0.         0.20325203 1.        ]\n",
            "tpr: [0.        0.9268461 1.       ]\n",
            "thresholds: [2 1 0]\n",
            "[[1176  300]\n",
            " [ 106 1343]]\n",
            "********************************************************************\n",
            "Epoch 1/100\n",
            "823/823 [==============================] - 20s 21ms/step - loss: 0.3214 - accuracy: 0.8458 - val_loss: 0.3040 - val_accuracy: 0.8492\n",
            "Epoch 2/100\n",
            "823/823 [==============================] - 16s 20ms/step - loss: 0.3237 - accuracy: 0.8432 - val_loss: 0.3210 - val_accuracy: 0.8550\n",
            "Epoch 3/100\n",
            "823/823 [==============================] - 17s 20ms/step - loss: 0.3215 - accuracy: 0.8458 - val_loss: 0.3082 - val_accuracy: 0.8526\n",
            "Epoch 4/100\n",
            "823/823 [==============================] - 17s 20ms/step - loss: 0.3232 - accuracy: 0.8450 - val_loss: 0.3189 - val_accuracy: 0.8431\n",
            "Epoch 5/100\n",
            "823/823 [==============================] - 16s 20ms/step - loss: 0.3222 - accuracy: 0.8466 - val_loss: 0.3043 - val_accuracy: 0.8530\n",
            "Epoch 6/100\n",
            "823/823 [==============================] - 25s 31ms/step - loss: 0.3259 - accuracy: 0.8453 - val_loss: 0.3394 - val_accuracy: 0.8379\n",
            "Epoch 7/100\n",
            "823/823 [==============================] - 33s 40ms/step - loss: 0.3247 - accuracy: 0.8458 - val_loss: 0.3008 - val_accuracy: 0.8516\n",
            "Epoch 8/100\n",
            "823/823 [==============================] - 17s 21ms/step - loss: 0.3173 - accuracy: 0.8459 - val_loss: 0.3053 - val_accuracy: 0.8571\n",
            "Epoch 9/100\n",
            "823/823 [==============================] - 19s 23ms/step - loss: 0.3173 - accuracy: 0.8473 - val_loss: 0.3056 - val_accuracy: 0.8564\n",
            "Epoch 10/100\n",
            "823/823 [==============================] - 17s 21ms/step - loss: 0.3253 - accuracy: 0.8489 - val_loss: 0.3058 - val_accuracy: 0.8571\n",
            "Epoch 11/100\n",
            "823/823 [==============================] - 18s 22ms/step - loss: 0.3183 - accuracy: 0.8475 - val_loss: 0.3411 - val_accuracy: 0.8403\n",
            "Epoch 12/100\n",
            "823/823 [==============================] - 18s 22ms/step - loss: 0.3198 - accuracy: 0.8458 - val_loss: 0.2995 - val_accuracy: 0.8561\n",
            "Epoch 13/100\n",
            "823/823 [==============================] - 18s 22ms/step - loss: 0.3159 - accuracy: 0.8494 - val_loss: 0.3254 - val_accuracy: 0.8390\n",
            "Epoch 14/100\n",
            "823/823 [==============================] - 18s 21ms/step - loss: 0.3161 - accuracy: 0.8482 - val_loss: 0.3040 - val_accuracy: 0.8554\n",
            "Epoch 15/100\n",
            "823/823 [==============================] - 18s 22ms/step - loss: 0.3172 - accuracy: 0.8478 - val_loss: 0.2953 - val_accuracy: 0.8581\n",
            "Epoch 16/100\n",
            "823/823 [==============================] - 19s 23ms/step - loss: 0.3287 - accuracy: 0.8444 - val_loss: 0.3597 - val_accuracy: 0.7952\n",
            "Epoch 17/100\n",
            "823/823 [==============================] - 19s 23ms/step - loss: 0.3381 - accuracy: 0.8424 - val_loss: 0.3101 - val_accuracy: 0.8557\n",
            "Epoch 18/100\n",
            "823/823 [==============================] - 18s 22ms/step - loss: 0.3431 - accuracy: 0.8488 - val_loss: 0.3001 - val_accuracy: 0.8622\n",
            "Epoch 19/100\n",
            "823/823 [==============================] - 19s 23ms/step - loss: 0.3285 - accuracy: 0.8448 - val_loss: 0.3117 - val_accuracy: 0.8499\n",
            "Epoch 20/100\n",
            "823/823 [==============================] - 17s 21ms/step - loss: 0.3158 - accuracy: 0.8494 - val_loss: 0.3346 - val_accuracy: 0.8482\n",
            "Epoch 21/100\n",
            "823/823 [==============================] - 17s 21ms/step - loss: 0.3154 - accuracy: 0.8474 - val_loss: 0.2978 - val_accuracy: 0.8571\n",
            "Epoch 22/100\n",
            "823/823 [==============================] - 19s 23ms/step - loss: 0.3162 - accuracy: 0.8477 - val_loss: 0.3060 - val_accuracy: 0.8578\n",
            "Epoch 23/100\n",
            "823/823 [==============================] - 17s 21ms/step - loss: 0.3145 - accuracy: 0.8502 - val_loss: 0.3017 - val_accuracy: 0.8564\n",
            "Epoch 24/100\n",
            "823/823 [==============================] - 18s 22ms/step - loss: 0.3110 - accuracy: 0.8504 - val_loss: 0.3101 - val_accuracy: 0.8506\n",
            "Epoch 25/100\n",
            "822/823 [============================>.] - ETA: 0s - loss: 0.3116 - accuracy: 0.8498Restoring model weights from the end of the best epoch: 15.\n",
            "823/823 [==============================] - 17s 21ms/step - loss: 0.3115 - accuracy: 0.8498 - val_loss: 0.3333 - val_accuracy: 0.8400\n",
            "Epoch 25: early stopping\n",
            "92/92 [==============================] - 1s 7ms/step\n",
            "Metrics for LR Model Fold 9:\n",
            "Inference Time: 473.3696 seconds\n",
            "training Time: 0.0075 seconds\n",
            "Accuracy: 0.86\n",
            "Precision: 0.83\n",
            "Recall: 0.90\n",
            "F1-score: 0.86\n",
            "kappa: 0.72\n",
            "ROC AUC: 0.86\n",
            "fpr: [0.         0.18075601 1.        ]\n",
            "tpr: [0.         0.89659864 1.        ]\n",
            "thresholds: [2 1 0]\n",
            "[[1192  263]\n",
            " [ 152 1318]]\n",
            "********************************************************************\n",
            "Epoch 1/100\n",
            "823/823 [==============================] - 22s 23ms/step - loss: 0.3180 - accuracy: 0.8493 - val_loss: 0.3462 - val_accuracy: 0.8376\n",
            "Epoch 2/100\n",
            "823/823 [==============================] - 17s 21ms/step - loss: 0.3290 - accuracy: 0.8485 - val_loss: 0.3218 - val_accuracy: 0.8434\n",
            "Epoch 3/100\n",
            "823/823 [==============================] - 17s 21ms/step - loss: 0.3152 - accuracy: 0.8472 - val_loss: 0.3147 - val_accuracy: 0.8451\n",
            "Epoch 4/100\n",
            "823/823 [==============================] - 17s 21ms/step - loss: 0.3130 - accuracy: 0.8494 - val_loss: 0.3090 - val_accuracy: 0.8506\n",
            "Epoch 5/100\n",
            "823/823 [==============================] - 17s 21ms/step - loss: 0.3125 - accuracy: 0.8494 - val_loss: 0.3643 - val_accuracy: 0.8397\n",
            "Epoch 6/100\n",
            "823/823 [==============================] - 18s 22ms/step - loss: 0.3181 - accuracy: 0.8469 - val_loss: 0.3171 - val_accuracy: 0.8557\n",
            "Epoch 7/100\n",
            "823/823 [==============================] - 17s 20ms/step - loss: 0.3152 - accuracy: 0.8482 - val_loss: 0.3282 - val_accuracy: 0.8410\n",
            "Epoch 8/100\n",
            "823/823 [==============================] - 17s 21ms/step - loss: 0.3120 - accuracy: 0.8504 - val_loss: 0.4118 - val_accuracy: 0.8215\n",
            "Epoch 9/100\n",
            "823/823 [==============================] - 17s 20ms/step - loss: 0.3125 - accuracy: 0.8495 - val_loss: 0.3181 - val_accuracy: 0.8530\n",
            "Epoch 10/100\n",
            "823/823 [==============================] - 19s 24ms/step - loss: 0.3189 - accuracy: 0.8507 - val_loss: 0.3073 - val_accuracy: 0.8585\n",
            "Epoch 11/100\n",
            "823/823 [==============================] - 18s 21ms/step - loss: 0.3138 - accuracy: 0.8513 - val_loss: 0.3186 - val_accuracy: 0.8503\n",
            "Epoch 12/100\n",
            "823/823 [==============================] - 17s 21ms/step - loss: 0.3106 - accuracy: 0.8504 - val_loss: 0.3225 - val_accuracy: 0.8489\n",
            "Epoch 13/100\n",
            "823/823 [==============================] - 17s 21ms/step - loss: 0.3270 - accuracy: 0.8469 - val_loss: 0.3253 - val_accuracy: 0.8472\n",
            "Epoch 14/100\n",
            "823/823 [==============================] - 17s 21ms/step - loss: 0.3122 - accuracy: 0.8502 - val_loss: 0.3358 - val_accuracy: 0.8328\n",
            "Epoch 15/100\n",
            "823/823 [==============================] - 17s 21ms/step - loss: 0.3150 - accuracy: 0.8464 - val_loss: 0.3721 - val_accuracy: 0.8311\n",
            "Epoch 16/100\n",
            "823/823 [==============================] - 18s 22ms/step - loss: 0.3133 - accuracy: 0.8494 - val_loss: 0.3254 - val_accuracy: 0.8400\n",
            "Epoch 17/100\n",
            "823/823 [==============================] - 17s 20ms/step - loss: 0.3082 - accuracy: 0.8523 - val_loss: 0.3032 - val_accuracy: 0.8554\n",
            "Epoch 18/100\n",
            "823/823 [==============================] - 17s 21ms/step - loss: 0.3125 - accuracy: 0.8504 - val_loss: 0.3165 - val_accuracy: 0.8513\n",
            "Epoch 19/100\n",
            "823/823 [==============================] - 17s 21ms/step - loss: 0.3098 - accuracy: 0.8507 - val_loss: 0.3052 - val_accuracy: 0.8499\n",
            "Epoch 20/100\n",
            "823/823 [==============================] - 18s 22ms/step - loss: 0.3076 - accuracy: 0.8518 - val_loss: 0.3321 - val_accuracy: 0.8369\n",
            "Epoch 21/100\n",
            "823/823 [==============================] - 18s 22ms/step - loss: 0.3074 - accuracy: 0.8504 - val_loss: 0.3155 - val_accuracy: 0.8509\n",
            "Epoch 22/100\n",
            "823/823 [==============================] - 17s 21ms/step - loss: 0.3155 - accuracy: 0.8538 - val_loss: 0.3072 - val_accuracy: 0.8557\n",
            "Epoch 23/100\n",
            "823/823 [==============================] - 19s 23ms/step - loss: 0.3094 - accuracy: 0.8534 - val_loss: 0.3258 - val_accuracy: 0.8359\n",
            "Epoch 24/100\n",
            "823/823 [==============================] - 17s 20ms/step - loss: 0.3072 - accuracy: 0.8534 - val_loss: 0.3445 - val_accuracy: 0.8496\n",
            "Epoch 25/100\n",
            "823/823 [==============================] - 18s 22ms/step - loss: 0.3080 - accuracy: 0.8508 - val_loss: 0.3130 - val_accuracy: 0.8475\n",
            "Epoch 26/100\n",
            "823/823 [==============================] - 17s 20ms/step - loss: 0.3092 - accuracy: 0.8507 - val_loss: 0.3006 - val_accuracy: 0.8550\n",
            "Epoch 27/100\n",
            "823/823 [==============================] - 17s 21ms/step - loss: 0.3071 - accuracy: 0.8532 - val_loss: 0.3137 - val_accuracy: 0.8547\n",
            "Epoch 28/100\n",
            "823/823 [==============================] - 17s 20ms/step - loss: 0.3123 - accuracy: 0.8530 - val_loss: 0.3061 - val_accuracy: 0.8574\n",
            "Epoch 29/100\n",
            "823/823 [==============================] - 17s 20ms/step - loss: 0.3131 - accuracy: 0.8497 - val_loss: 0.3052 - val_accuracy: 0.8547\n",
            "Epoch 30/100\n",
            "823/823 [==============================] - 18s 21ms/step - loss: 0.3079 - accuracy: 0.8545 - val_loss: 0.3170 - val_accuracy: 0.8472\n",
            "Epoch 31/100\n",
            "823/823 [==============================] - 18s 21ms/step - loss: 0.3102 - accuracy: 0.8512 - val_loss: 0.3186 - val_accuracy: 0.8499\n",
            "Epoch 32/100\n",
            "823/823 [==============================] - 17s 21ms/step - loss: 0.3098 - accuracy: 0.8507 - val_loss: 0.3143 - val_accuracy: 0.8561\n",
            "Epoch 33/100\n",
            "823/823 [==============================] - 17s 21ms/step - loss: 0.3051 - accuracy: 0.8530 - val_loss: 0.3094 - val_accuracy: 0.8485\n",
            "Epoch 34/100\n",
            "823/823 [==============================] - 17s 21ms/step - loss: 0.3159 - accuracy: 0.8487 - val_loss: 0.3468 - val_accuracy: 0.8421\n",
            "Epoch 35/100\n",
            "823/823 [==============================] - 18s 22ms/step - loss: 0.3125 - accuracy: 0.8513 - val_loss: 0.3208 - val_accuracy: 0.8513\n",
            "Epoch 36/100\n",
            "823/823 [==============================] - ETA: 0s - loss: 0.3058 - accuracy: 0.8555Restoring model weights from the end of the best epoch: 26.\n",
            "823/823 [==============================] - 18s 21ms/step - loss: 0.3058 - accuracy: 0.8555 - val_loss: 0.3172 - val_accuracy: 0.8561\n",
            "Epoch 36: early stopping\n",
            "92/92 [==============================] - 1s 7ms/step\n",
            "Metrics for LR Model Fold 10:\n",
            "Inference Time: 634.0512 seconds\n",
            "training Time: 0.0073 seconds\n",
            "Accuracy: 0.86\n",
            "Precision: 0.81\n",
            "Recall: 0.92\n",
            "F1-score: 0.86\n",
            "kappa: 0.71\n",
            "ROC AUC: 0.86\n",
            "fpr: [0.         0.20472973 1.        ]\n",
            "tpr: [0.         0.91626298 1.        ]\n",
            "thresholds: [2 1 0]\n",
            "[[1177  303]\n",
            " [ 121 1324]]\n",
            "********************************************************************\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize lists to store metric values\n",
        "accuracies = []\n",
        "precisions = []\n",
        "recalls = []\n",
        "f1_scores = []\n",
        "kappas = []\n",
        "Inference_Time = []\n",
        "Training_time = []\n",
        "roc_auc = []\n",
        "# Loop over the results dictionary\n",
        "for model, metrics in resultLSTM.items():\n",
        "    accuracies.append(metrics['accuracy'])\n",
        "    precisions.append(metrics['precision'])\n",
        "    recalls.append(metrics['recall'])\n",
        "    f1_scores.append(metrics['f1'])\n",
        "    kappas.append(metrics['kappa'])\n",
        "    Inference_Time.append(metrics['Inference_Time'])\n",
        "    Training_time.append(metrics['Training_time'])\n",
        "    roc_auc.append(metrics['roc_auc'])\n",
        "\n",
        "# Calculate the best, worst, and average values for each metric\n",
        "best_accuracy = round(max(accuracies), 2)\n",
        "worst_accuracy = round(min(accuracies), 2)\n",
        "average_accuracy = round(sum(accuracies) / len(accuracies), 2)\n",
        "\n",
        "\n",
        "best_precision = round(max(precisions), 2)\n",
        "worst_precision = round(min(precisions), 2)\n",
        "average_precision = round(sum(precisions) / len(precisions), 3)\n",
        "\n",
        "best_recall = round(max(recalls), 2)\n",
        "worst_recall = round(min(recalls), 2)\n",
        "average_recall = round(sum(recalls) / len(recalls), 2)\n",
        "\n",
        "best_f1_score = round(max(f1_scores), 2)\n",
        "worst_f1_score = round(min(f1_scores), 2)\n",
        "average_f1_score = round(sum(f1_scores) / len(f1_scores), 2)\n",
        "\n",
        "best_kappa = round(max(kappas), 2)\n",
        "worst_kappa = round(min(kappas), 2)\n",
        "average_kappa = round(sum(kappas) / len(kappas), 2)\n",
        "\n",
        "best_Inference_Time = round(max(Inference_Time), 5)\n",
        "worst_Inference_Time = round(min(Inference_Time), 5)\n",
        "average_Inference_Time = round(sum(Inference_Time) / len(Inference_Time), 5)\n",
        "\n",
        "\n",
        "best_Training_time = round(max(Training_time), 5)\n",
        "worst_Training_time = round(min(Training_time), 5)\n",
        "average_Training_time = round(sum(Training_time) / len(Training_time), 5)\n",
        "\n",
        "best_roc_auc = round(max(roc_auc), 2)\n",
        "worst_roc_auc = round(min(roc_auc), 2)\n",
        "average_roc_auc = round(sum(roc_auc) / len(roc_auc), 2)\n",
        "\n",
        "# Print the results\n",
        "print(\"Best Accuracy:\", best_accuracy)\n",
        "print(\"Worst Accuracy:\", worst_accuracy)\n",
        "print(\"Average Accuracy:\", average_accuracy)\n",
        "\n",
        "print(\"************************************************\")\n",
        "\n",
        "\n",
        "print(\"Best Precision:\", best_precision)\n",
        "print(\"Worst Precision:\", worst_precision)\n",
        "print(\"Average Precision:\", average_precision)\n",
        "print(\"************************************************\")\n",
        "\n",
        "print(\"Best Recall:\", best_recall)\n",
        "print(\"Worst Recall:\", worst_recall)\n",
        "print(\"Average Recall:\", average_recall)\n",
        "print(\"************************************************\")\n",
        "\n",
        "print(\"Best F1 Score:\", best_f1_score)\n",
        "print(\"Worst F1 Score:\", worst_f1_score)\n",
        "print(\"Average F1 Score:\", average_f1_score)\n",
        "print(\"************************************************\")\n",
        "\n",
        "print(\"Best Kappa:\", best_kappa)\n",
        "print(\"Worst Kappa:\", worst_kappa)\n",
        "print(\"Average Kappa:\", average_kappa)\n",
        "\n",
        "print(\"************************************************\")\n",
        "\n",
        "print(\"Best Inference_Time:\", best_Inference_Time)\n",
        "print(\"Worst Inference_Time:\", worst_Inference_Time)\n",
        "print(\"Average Inference_Time:\", average_Inference_Time)\n",
        "print(\"************************************************\")\n",
        "\n",
        "print(\"Best Training_time:\", best_Training_time)\n",
        "print(\"Worst Training_time:\", worst_Training_time)\n",
        "print(\"Average Training_time:\", average_Training_time)\n",
        "print(\"************************************************\")\n",
        "\n",
        "print(\"Best roc_auc:\", best_roc_auc)\n",
        "print(\"Worst roc_auc:\", worst_roc_auc)\n",
        "print(\"Average roc_auc:\", average_roc_auc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7uAB1uZH20n8",
        "outputId": "56f1be19-12fa-4a9f-90f9-785234728ba3"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Accuracy: 0.86\n",
            "Worst Accuracy: 0.84\n",
            "Average Accuracy: 0.85\n",
            "************************************************\n",
            "Best Precision: 0.83\n",
            "Worst Precision: 0.8\n",
            "Average Precision: 0.814\n",
            "************************************************\n",
            "Best Recall: 0.93\n",
            "Worst Recall: 0.89\n",
            "Average Recall: 0.91\n",
            "************************************************\n",
            "Best F1 Score: 0.87\n",
            "Worst F1 Score: 0.85\n",
            "Average F1 Score: 0.86\n",
            "************************************************\n",
            "Best Kappa: 0.72\n",
            "Worst Kappa: 0.67\n",
            "Average Kappa: 0.7\n",
            "************************************************\n",
            "Best Inference_Time: 1169.1041\n",
            "Worst Inference_Time: 223.07959\n",
            "Average Inference_Time: 440.40041\n",
            "************************************************\n",
            "Best Training_time: 0.01313\n",
            "Worst Training_time: 0.00702\n",
            "Average Training_time: 0.00877\n",
            "************************************************\n",
            "Best roc_auc: 0.86\n",
            "Worst roc_auc: 0.83\n",
            "Average roc_auc: 0.85\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "8C0gi-ouCuyy",
        "U_LiaLFyCz2Y",
        "4f8O4rioDCxX",
        "NDFnMS8EDnPv"
      ],
      "provenance": [],
      "authorship_tag": "ABX9TyPNKNrQJIxz86Lq5/HqcT1N",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}