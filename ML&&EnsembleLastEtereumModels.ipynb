{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/samanehPahlavani/MscFraudDetection/blob/main/ML%26%26EnsembleLastEtereumModels.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8C0gi-ouCuyy"
      },
      "source": [
        "# Connect Google Drive For Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "TnT44zOYCvsY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8870c4a5-6d70-46a5-f7b3-554530292478"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U_LiaLFyCz2Y"
      },
      "source": [
        "#Libraries\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "g38JUFNsNffx"
      },
      "outputs": [],
      "source": [
        "####Libraries Import\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import os\n",
        "\n",
        "%matplotlib inline\n",
        "import sklearn\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.over_sampling import RandomOverSampler\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "EebzlEOoPIQn"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "from sklearn.model_selection import StratifiedKFold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "7cvVXdoHMgCq"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression # for Logistic Regression Algorithm\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "GY3_rgI6YLiJ"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.svm import SVR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "JBCJ9U8eMjtp"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "k2wy9jCTOLbb"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import cross_val_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "g56ZnvPVUER-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "e298a4a1-d193-40fd-94cd-75d96d3bc2c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pandas_ml\n",
            "  Downloading pandas_ml-0.6.1-py3-none-any.whl (100 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.3/100.3 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas>=0.19.0 in /usr/local/lib/python3.10/dist-packages (from pandas_ml) (1.5.3)\n",
            "Collecting enum34 (from pandas_ml)\n",
            "  Downloading enum34-1.1.10-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.19.0->pandas_ml) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.19.0->pandas_ml) (2023.4)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.19.0->pandas_ml) (1.23.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas>=0.19.0->pandas_ml) (1.16.0)\n",
            "Installing collected packages: enum34, pandas_ml\n",
            "Successfully installed enum34-1.1.10 pandas_ml-0.6.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "enum"
                ]
              },
              "id": "39c738c5932f4f4faec331db31cde410"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install pandas_ml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "jWDU5PrOZQaG"
      },
      "outputs": [],
      "source": [
        "# Import the necessary libraries\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "jPgfSJ2bJ0OW"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, cohen_kappa_score\n",
        "from sklearn.model_selection import train_test_split, KFold"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time"
      ],
      "metadata": {
        "id": "MKgdfRpW0y_Z"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4f8O4rioDCxX"
      },
      "source": [
        "# Functions Def"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Yc0vpXMON1HI"
      },
      "outputs": [],
      "source": [
        "def LoadData(data):\n",
        "  warnings.filterwarnings('ignore')\n",
        "  pd.options.display.max_columns = None\n",
        "  pd.options.display.max_rows = None\n",
        "  df = pd.read_csv(os.path.join(\"/content/drive/MyDrive/EtherFirstDataSet/\", data+\".csv\"))\n",
        "  return df\n",
        "#Load datas\n",
        "def preprocessing():\n",
        "\n",
        "  df1 = LoadData(str(1))\n",
        "  df2 = LoadData(str(2))\n",
        "\n",
        "  df1_fillna = df1.copy()\n",
        "  df2_fillna = df2.copy()\n",
        "\n",
        "  #Drop Most None Related Value Features\n",
        "  df1_fillna.drop([\"ERC20_uniq_rec_token_name\",\"ERC20_uniq_sent_token_name\",\"ERC20_avg_val_sent\",\"ERC20_max_val_sent\",\"ERC20_min_val_sent\",\"ERC20_avg_val_rec\",\"ERC20_max_val_rec\",\"ERC20_min_val_rec\",\"ERC20_uniq_rec_contract_addr\",\"ERC20_uniq_sent_addr_1\",\"ERC20_uniq_sent_addr\",\"ERC20_total_Ether_sent_contract\",\"ERC20_total_ether_sent\",\"ERC20_total_Ether_received\",\"ERC20_most_rec_token_type\",\"ERC20_most_sent_token_type\"], axis=1, inplace=True)\n",
        "  df1_fillna.drop([\"ERC20_uniq_rec_addr\",\"Total_ERC20_tnxs\",\"Time_Diff_between_first_and_last_Mins\",\"total_ether_sent_contracts\"], axis=1, inplace=True)\n",
        "  df2_fillna.drop([\"minTimeBetweenSentTnx\",\"maxTimeBetweenSentTnx\",\"minTimeBetweenRecTnx\",\"maxTimeBetweenRecTnx\",\"lifetime\",\"activityDays\",\"dailyMax\",\"ratioRecSent\",\"ratioSentTotal\",\"ratioRecTotal\",\"giniSent\",\"giniRec\",\"txFreq\",\"stdBalanceEth\"], axis=1, inplace=True)\n",
        "\n",
        "  #Rename Columns\n",
        "  selected_columns = [\"address\",\"flag\",\"avgTimeBetweenRecTnx\",\"avgTimeBetweenSentTnx\",\"sentTransactions\" ,\"receivedTransactions\", \"createdContracts\" ,\"Average_of_numUniqRecAddress\" ,\"Average_of_numUniqSentAddress\"\n",
        "  ,\"minValReceived\"\n",
        "  ,\"maxValReceived\"\n",
        "  ,\"avgValReceived\"\n",
        "  , \"minValSent\"\n",
        "  , \"maxValSent\"\n",
        "  ,\"avgValSent\"\n",
        "  ,\"totalTransactions\"\n",
        "  ,\"totalEtherSent\"\n",
        "  ,\"totalEtherReceived\"\n",
        "  ,\"totalEtherBalance\"    ]\n",
        "\n",
        "  df2_fillna = df2[selected_columns].copy()\n",
        "\n",
        "  df2_fillna.columns = [\"Address\"\n",
        "  ,\"FLAG\"\n",
        "  ,\"Avg_min_between_received_tnx\"\n",
        "  ,\"Avg_min_between_sent_tnx\"\n",
        "  ,\"Sent_tnx\"\n",
        "  ,\"Received_Tnx\"\n",
        "  ,\"Number_of_Created_Contracts\"\n",
        "  ,\"Average_of_Unique_Received_From_Addresses\"\n",
        "  ,\"Average_of_Unique_Sent_To_Addresses\"\n",
        "  ,\"min_value_received\"\n",
        "  ,\"max_value_received \"\n",
        "  ,\"avg_val_received\"\n",
        "  ,\"min_val_sent\"\n",
        "  ,\"max_val_sent\"\n",
        "  ,\"avg_val_sent\"\n",
        "  ,\"total_transactions_including_tnx_to_create_contract\"\n",
        "  ,\"total_Ether_sent\"\n",
        "  ,\"total_ether_received\"\n",
        "  ,\"total_ether_balance\"\n",
        "  ]\n",
        "\n",
        "  merged_df = pd.merge(df1_fillna, df2_fillna, how='outer')\n",
        "  df_filtered = merged_df.drop_duplicates(subset='Address', keep='first')\n",
        "  return df_filtered\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "qAZ3JtKZO8RO"
      },
      "outputs": [],
      "source": [
        "def scaled(data):\n",
        "  # Convert categorical 'FLAG' to numeric\n",
        "  label_encoder = LabelEncoder()\n",
        "  data['FLAG'] = label_encoder.fit_transform(data['FLAG'])\n",
        "\n",
        "  # Splitting the data into features (X) and labels (y)\n",
        "  X =  data.drop(['FLAG'], axis=1)\n",
        "  y = data['FLAG']\n",
        "\n",
        "  # Standardize features\n",
        "  scaler = StandardScaler()\n",
        "  X_scaled = scaler.fit_transform(X)\n",
        "  #X_scaled['FLAG'] = y\n",
        "\n",
        "\n",
        "  return X_scaled,y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "JTT6oBABCzlX"
      },
      "outputs": [],
      "source": [
        "def undersampling(data, target_column):\n",
        "    # Separate features and target variable\n",
        "    X = data.drop(target_column, axis=1)\n",
        "    y = data[target_column]\n",
        "\n",
        "    # Apply undersampling\n",
        "    undersampler = RandomUnderSampler()\n",
        "    X_resampled, y_resampled = undersampler.fit_resample(X, y)\n",
        "\n",
        "    # Get indices of selected samples\n",
        "    selected_indices = undersampler.sample_indices_\n",
        "\n",
        "    # Get indices of unselected samples\n",
        "    unselected_indices = np.setdiff1d(np.arange(len(X)), selected_indices)\n",
        "\n",
        "    # Extract unselected samples\n",
        "    X_unselected = X.iloc[unselected_indices]\n",
        "    y_unselected = y.iloc[unselected_indices]\n",
        "\n",
        "    # Combine unselected data into a DataFrame\n",
        "    unselected_data = pd.concat([X_unselected, y_unselected], axis=1)\n",
        "    resampled = pd.concat([X_resampled, y_resampled], axis=1)\n",
        "    return resampled, unselected_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "R372OqcfDl1l"
      },
      "outputs": [],
      "source": [
        "def oversampling(data, target_column):\n",
        "    # Separate features and target variable\n",
        "    X = data.drop(target_column, axis=1)\n",
        "    y = data[target_column]\n",
        "\n",
        "    # Apply oversampling\n",
        "    oversampler = RandomOverSampler()\n",
        "    X_resampled, y_resampled = oversampler.fit_resample(X, y)\n",
        "\n",
        "    # Get indices of selected samples\n",
        "    selected_indices = oversampler.sample_indices_\n",
        "\n",
        "    # Get indices of unselected samples\n",
        "    unselected_indices = np.setdiff1d(np.arange(len(X)), selected_indices)\n",
        "\n",
        "    # Extract unselected samples\n",
        "    X_unselected = X.iloc[unselected_indices]\n",
        "    y_unselected = y.iloc[unselected_indices]\n",
        "\n",
        "    # Combine unselected data into a DataFrame\n",
        "    unselected_data = pd.concat([X_unselected, y_unselected], axis=1)\n",
        "    resampled = pd.concat([X_resampled, y_resampled], axis=1)\n",
        "\n",
        "    return resampled, unselected_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "ky7ICuRuDl8f"
      },
      "outputs": [],
      "source": [
        "def smote(data, target_column):\n",
        "    # Separate features and target variable\n",
        "    X = data.drop(target_column, axis=1)\n",
        "    y = data[target_column]\n",
        "\n",
        "    # Apply SMOTE\n",
        "    smote = SMOTE()\n",
        "    X_resampled, y_resampled = smote.fit_resample(X, y)\n",
        "\n",
        "    # Combine resampled data into a DataFrame\n",
        "    resampled_data = pd.concat([pd.DataFrame(X_resampled, columns=X.columns), pd.Series(y_resampled, name=target_column)], axis=1)\n",
        "    return resampled_data,''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "YaS8Ky5CCnsG"
      },
      "outputs": [],
      "source": [
        "def ballanced(data,type=\"O\"):\n",
        "\n",
        "  if type==\"U\":\n",
        "    resampled, unselected_data = undersampling(data, 'FLAG')\n",
        "  elif type==\"S\":\n",
        "    resampled, unselected_data  = smote(data, 'FLAG')\n",
        "  elif type==\"O\":\n",
        "    resampled, unselected_data = oversampling(data, 'FLAG')\n",
        "\n",
        "\n",
        "  return resampled, unselected_data\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "US6mp1RHMB2L"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NDFnMS8EDnPv"
      },
      "source": [
        "#**Preprocessing **"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "bjCS9A6XDoeu"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "PQGlmKgmObAP"
      },
      "outputs": [],
      "source": [
        "df_filtered = preprocessing()\n",
        "df_filtered = df_filtered.drop(['Address'], axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jkpkxkSm8eEl"
      },
      "source": [
        "**Imballanced Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "ioeEnhHe8V_e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "88f30d61-1bf1-4063-a375-70b11cac7d79"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "df = df_filtered\n",
        "positive_sample = df[(df[\"FLAG\"]==1)]\n",
        "negative_sample = df[(df[\"FLAG\"]==0)]\n",
        "dist = df[\"FLAG\"].value_counts()\n",
        "\n",
        "_ = plt.pie(dist, labels = [\"Negative ({0})\".format(len(negative_sample)), \"Positive ({0})\".format(len(positive_sample))], colors = [\"r\", \"g\"], explode=[0.2, 0], autopct='%1.1f%%')\n",
        "_ = plt.title(\"Data Distribution\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "r2cgG4FuNaeE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a7e4205-7b2b-4a01-d917-650fec3d41a8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20302, 18)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "#df_filtered = np.array(df_filtered)\n",
        "df_filtered.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "oSjP7e4MCIqv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "671390cd-a9a5-4d22-ef03-b121a5f54248"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(29254, 18)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "resampledOver, unselected_Over = ballanced(df_filtered,\"O\")\n",
        "resampledOver.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "h6FayFZmyfme",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf500be6-14b2-42c3-a5b6-34619895ce9d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(29254, 17)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "X_reshapedO,y_reshapedO = scaled(resampledOver)\n",
        "X_reshapedO.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "Cd-b8SsCoqJI"
      },
      "outputs": [],
      "source": [
        "X_trainO, X_testO, y_trainO, y_testO =  train_test_split(X_reshapedO, y_reshapedO, test_size=0.1, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_testO.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L-5GNKCXeIP3",
        "outputId": "c6fe1d36-03b6-4305-a947-063f2040baa5"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2926, 17)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_trainO.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OpUwEMU-eRft",
        "outputId": "a62d164a-8418-451d-eccb-a2865baa91d1"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(26328, 17)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kikiBnEgEjKW"
      },
      "source": [
        "# #**Models**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MmBZDbm2DwsQ"
      },
      "source": [
        "Rescaling\n",
        "\n",
        "1-LogisticRegression(LR)\n",
        "\n",
        "2-SVM (Support Vector Machine)\n",
        "\n",
        "3-RandomForest(RF)\n",
        "\n",
        "4-DT\n",
        "\n",
        "5-XGBOOST\n",
        "\n",
        "6-MLP\n",
        "\n",
        "7-Naive Bayes\n",
        "\n",
        "8-KNN\n",
        "\n",
        "9- Extra Trees\n",
        "10-AdaBoost\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_curve, roc_auc_score\n"
      ],
      "metadata": {
        "id": "x5YukE3B9YcW"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nh6d23_pMt15"
      },
      "source": [
        "# **1-LogisticRegression(LR)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "IUrHyQUPMyrx"
      },
      "outputs": [],
      "source": [
        "LR = LogisticRegression()\n",
        "# Dictionary to store confusion matrices, accuracies, and cross-validation scores\n",
        "resultsLR = {}\n",
        "\n",
        "# Loop over the training/testing sets\n",
        "kf = KFold(n_splits=10, random_state = 42, shuffle=True)\n",
        "i = 1\n",
        "X = np.concatenate([X_trainO, X_testO], axis=0)\n",
        "y = np.concatenate([y_trainO, y_testO], axis=0)\n",
        "X_df = pd.DataFrame(X)\n",
        "y_df = pd.DataFrame(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w9CukUpgNU_8",
        "outputId": "a4c9bb22-8882-4501-a93e-83642befd578"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Metrics for LR Model Fold 1:\n",
            "Inference Time: 0.0099 seconds\n",
            "training Time: 1.0210 seconds\n",
            "Accuracy: 0.66\n",
            "Precision: 0.61\n",
            "Recall: 0.94\n",
            "F1-score: 0.74\n",
            "kappa: 0.32\n",
            "ROC AUC: 0.66\n",
            "fpr: [0.         0.62318841 1.        ]\n",
            "tpr: [0.         0.93771158 1.        ]\n",
            "thresholds: [2 1 0]\n",
            "[[ 546  903]\n",
            " [  92 1385]]\n",
            "********************************************************************\n",
            "Metrics for LR Model Fold 2:\n",
            "Inference Time: 0.0164 seconds\n",
            "training Time: 0.8449 seconds\n",
            "Accuracy: 0.68\n",
            "Precision: 0.62\n",
            "Recall: 0.94\n",
            "F1-score: 0.74\n",
            "kappa: 0.36\n",
            "ROC AUC: 0.68\n",
            "fpr: [0.         0.57520325 1.        ]\n",
            "tpr: [0.         0.93862069 1.        ]\n",
            "thresholds: [2 1 0]\n",
            "[[ 627  849]\n",
            " [  89 1361]]\n",
            "********************************************************************\n",
            "Metrics for LR Model Fold 3:\n",
            "Inference Time: 0.0055 seconds\n",
            "training Time: 0.9204 seconds\n",
            "Accuracy: 0.69\n",
            "Precision: 0.63\n",
            "Recall: 0.95\n",
            "F1-score: 0.76\n",
            "kappa: 0.38\n",
            "ROC AUC: 0.69\n",
            "fpr: [0.         0.56924148 1.        ]\n",
            "tpr: [0.         0.94627267 1.        ]\n",
            "thresholds: [2 1 0]\n",
            "[[ 619  818]\n",
            " [  80 1409]]\n",
            "********************************************************************\n",
            "Metrics for LR Model Fold 4:\n",
            "Inference Time: 0.0026 seconds\n",
            "training Time: 0.8031 seconds\n",
            "Accuracy: 0.65\n",
            "Precision: 0.59\n",
            "Recall: 0.93\n",
            "F1-score: 0.72\n",
            "kappa: 0.31\n",
            "ROC AUC: 0.66\n",
            "fpr: [0.         0.60695187 1.        ]\n",
            "tpr: [0.         0.92517483 1.        ]\n",
            "thresholds: [2 1 0]\n",
            "[[ 588  908]\n",
            " [ 107 1323]]\n",
            "********************************************************************\n",
            "Metrics for LR Model Fold 5:\n",
            "Inference Time: 0.0153 seconds\n",
            "training Time: 1.4023 seconds\n",
            "Accuracy: 0.68\n",
            "Precision: 0.61\n",
            "Recall: 0.94\n",
            "F1-score: 0.74\n",
            "kappa: 0.36\n",
            "ROC AUC: 0.68\n",
            "fpr: [0.         0.57362784 1.        ]\n",
            "tpr: [0.         0.93640811 1.        ]\n",
            "thresholds: [2 1 0]\n",
            "[[ 637  857]\n",
            " [  91 1340]]\n",
            "********************************************************************\n",
            "Metrics for LR Model Fold 6:\n",
            "Inference Time: 0.0073 seconds\n",
            "training Time: 1.1204 seconds\n",
            "Accuracy: 0.69\n",
            "Precision: 0.64\n",
            "Recall: 0.94\n",
            "F1-score: 0.76\n",
            "kappa: 0.37\n",
            "ROC AUC: 0.68\n",
            "fpr: [0.         0.57741477 1.        ]\n",
            "tpr: [0.         0.94264997 1.        ]\n",
            "thresholds: [2 1 0]\n",
            "[[ 595  813]\n",
            " [  87 1430]]\n",
            "********************************************************************\n",
            "Metrics for LR Model Fold 7:\n",
            "Inference Time: 0.0170 seconds\n",
            "training Time: 1.2864 seconds\n",
            "Accuracy: 0.67\n",
            "Precision: 0.61\n",
            "Recall: 0.95\n",
            "F1-score: 0.74\n",
            "kappa: 0.33\n",
            "ROC AUC: 0.66\n",
            "fpr: [0.         0.61675824 1.        ]\n",
            "tpr: [0.         0.94622192 1.        ]\n",
            "thresholds: [2 1 0]\n",
            "[[ 558  898]\n",
            " [  79 1390]]\n",
            "********************************************************************\n",
            "Metrics for LR Model Fold 8:\n",
            "Inference Time: 0.0128 seconds\n",
            "training Time: 0.9651 seconds\n",
            "Accuracy: 0.66\n",
            "Precision: 0.60\n",
            "Recall: 0.94\n",
            "F1-score: 0.73\n",
            "kappa: 0.33\n",
            "ROC AUC: 0.67\n",
            "fpr: [0.         0.60569106 1.        ]\n",
            "tpr: [0.         0.93857833 1.        ]\n",
            "thresholds: [2 1 0]\n",
            "[[ 582  894]\n",
            " [  89 1360]]\n",
            "********************************************************************\n",
            "Metrics for LR Model Fold 9:\n",
            "Inference Time: 0.0089 seconds\n",
            "training Time: 0.8019 seconds\n",
            "Accuracy: 0.68\n",
            "Precision: 0.62\n",
            "Recall: 0.94\n",
            "F1-score: 0.75\n",
            "kappa: 0.36\n",
            "ROC AUC: 0.68\n",
            "fpr: [0.         0.58419244 1.        ]\n",
            "tpr: [0.         0.94489796 1.        ]\n",
            "thresholds: [2 1 0]\n",
            "[[ 605  850]\n",
            " [  81 1389]]\n",
            "********************************************************************\n",
            "Metrics for LR Model Fold 10:\n",
            "Inference Time: 0.0061 seconds\n",
            "training Time: 0.8446 seconds\n",
            "Accuracy: 0.66\n",
            "Precision: 0.60\n",
            "Recall: 0.94\n",
            "F1-score: 0.73\n",
            "kappa: 0.33\n",
            "ROC AUC: 0.67\n",
            "fpr: [0.         0.60405405 1.        ]\n",
            "tpr: [0.         0.93910035 1.        ]\n",
            "thresholds: [2 1 0]\n",
            "[[ 586  894]\n",
            " [  88 1357]]\n",
            "********************************************************************\n"
          ]
        }
      ],
      "source": [
        "fld = 1\n",
        "for train_index, test_index in kf.split(X):\n",
        "\n",
        "        X_trainV, X_testV = X_df.iloc[train_index], X_df.iloc[test_index]\n",
        "        y_trainV, y_testV = y_df.iloc[train_index], y_df.iloc[test_index]\n",
        "\n",
        "        start_time = time.time()\n",
        "        LR.fit(X_trainV, y_trainV)\n",
        "        Training_time = time.time() - start_time\n",
        "\n",
        "        start_time = time.time()\n",
        "        y_predictLR = LR.predict(X_testV)\n",
        "        Inference_Time = time.time() - start_time\n",
        "\n",
        "\n",
        "        y_predictLR = LR.predict(X_testV)\n",
        "        accuracy = accuracy_score(y_testV, y_predictLR)\n",
        "        precision = precision_score(y_testV, y_predictLR)\n",
        "        recall = recall_score(y_testV, y_predictLR)\n",
        "        f1= f1_score(y_testV, y_predictLR)\n",
        "        kappa = cohen_kappa_score(y_testV, y_predictLR)\n",
        "\n",
        "        roc_auc = roc_auc_score(y_testV, y_predictLR)\n",
        "        fpr, tpr, thresholds = roc_curve(y_testV, y_predictLR)\n",
        "        conf_mat = confusion_matrix(y_testV, y_predictLR)\n",
        "        resultsLR[f'Model_{fld}'] = {'Matrix': conf_mat, 'accuracy': accuracy, 'precision': precision,\n",
        "                                  'recall': recall, 'f1': f1, 'kappa': kappa, 'roc_auc': roc_auc,'fpr':fpr\n",
        "                                     ,'tpr':tpr,'thresholds':thresholds,'Inference_Time':Inference_Time,'Training_time':Training_time}\n",
        "\n",
        "\n",
        "\n",
        "        # Print metrics for the LR model\n",
        "        print(f'Metrics for LR Model Fold {fld}:')\n",
        "        print(f\"Inference Time: {Inference_Time:.4f} seconds\")\n",
        "        print(f\"training Time: {Training_time:.4f} seconds\")\n",
        "        print(f\"Accuracy: {accuracy:.2f}\")\n",
        "        print(f\"Precision: {precision:.2f}\")\n",
        "        print(f\"Recall: {recall:.2f}\")\n",
        "        print(f\"F1-score: {f1:.2f}\")\n",
        "        print(f\"kappa: {kappa:.2f}\")\n",
        "        print(f\"ROC AUC: {roc_auc:.2f}\")\n",
        "        print(f\"fpr: {fpr}\")\n",
        "        print(f\"tpr: {tpr}\")\n",
        "        print(f\"thresholds: {thresholds}\")\n",
        "        print(conf_mat)\n",
        "        print(\"********************************************************************\")\n",
        "        fld = fld + 1\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize lists to store metric values\n",
        "accuracies = []\n",
        "precisions = []\n",
        "recalls = []\n",
        "f1_scores = []\n",
        "kappas = []\n",
        "Inference_Time = []\n",
        "Training_time = []\n",
        "roc_auc = []\n",
        "# Loop over the results dictionary\n",
        "for model, metrics in resultsLR.items():\n",
        "    accuracies.append(metrics['accuracy'])\n",
        "    precisions.append(metrics['precision'])\n",
        "    recalls.append(metrics['recall'])\n",
        "    f1_scores.append(metrics['f1'])\n",
        "    kappas.append(metrics['kappa'])\n",
        "    Inference_Time.append(metrics['Inference_Time'])\n",
        "    Training_time.append(metrics['Training_time'])\n",
        "    roc_auc.append(metrics['roc_auc'])\n",
        "\n",
        "# Calculate the best, worst, and average values for each metric\n",
        "best_accuracy = round(max(accuracies), 2)\n",
        "worst_accuracy = round(min(accuracies), 2)\n",
        "average_accuracy = round(sum(accuracies) / len(accuracies), 2)\n",
        "\n",
        "\n",
        "best_precision = round(max(precisions), 2)\n",
        "worst_precision = round(min(precisions), 2)\n",
        "average_precision = round(sum(precisions) / len(precisions), 3)\n",
        "\n",
        "best_recall = round(max(recalls), 2)\n",
        "worst_recall = round(min(recalls), 2)\n",
        "average_recall = round(sum(recalls) / len(recalls), 2)\n",
        "\n",
        "best_f1_score = round(max(f1_scores), 2)\n",
        "worst_f1_score = round(min(f1_scores), 2)\n",
        "average_f1_score = round(sum(f1_scores) / len(f1_scores), 2)\n",
        "\n",
        "best_kappa = round(max(kappas), 2)\n",
        "worst_kappa = round(min(kappas), 2)\n",
        "average_kappa = round(sum(kappas) / len(kappas), 2)\n",
        "\n",
        "best_Inference_Time = round(max(Inference_Time), 5)\n",
        "worst_Inference_Time = round(min(Inference_Time), 5)\n",
        "average_Inference_Time = round(sum(Inference_Time) / len(Inference_Time), 5)\n",
        "\n",
        "\n",
        "best_Training_time = round(max(Training_time), 5)\n",
        "worst_Training_time = round(min(Training_time), 5)\n",
        "average_Training_time = round(sum(Training_time) / len(Training_time), 5)\n",
        "\n",
        "best_roc_auc = round(max(roc_auc), 2)\n",
        "worst_roc_auc = round(min(roc_auc), 2)\n",
        "average_roc_auc = round(sum(roc_auc) / len(roc_auc), 2)\n",
        "\n",
        "# Print the results\n",
        "print(\"Best Accuracy:\", best_accuracy)\n",
        "print(\"Worst Accuracy:\", worst_accuracy)\n",
        "print(\"Average Accuracy:\", average_accuracy)\n",
        "\n",
        "print(\"************************************************\")\n",
        "\n",
        "\n",
        "print(\"Best Precision:\", best_precision)\n",
        "print(\"Worst Precision:\", worst_precision)\n",
        "print(\"Average Precision:\", average_precision)\n",
        "print(\"************************************************\")\n",
        "\n",
        "print(\"Best Recall:\", best_recall)\n",
        "print(\"Worst Recall:\", worst_recall)\n",
        "print(\"Average Recall:\", average_recall)\n",
        "print(\"************************************************\")\n",
        "\n",
        "print(\"Best F1 Score:\", best_f1_score)\n",
        "print(\"Worst F1 Score:\", worst_f1_score)\n",
        "print(\"Average F1 Score:\", average_f1_score)\n",
        "print(\"************************************************\")\n",
        "\n",
        "print(\"Best Kappa:\", best_kappa)\n",
        "print(\"Worst Kappa:\", worst_kappa)\n",
        "print(\"Average Kappa:\", average_kappa)\n",
        "\n",
        "print(\"************************************************\")\n",
        "\n",
        "print(\"Best Inference_Time:\", best_Inference_Time)\n",
        "print(\"Worst Inference_Time:\", worst_Inference_Time)\n",
        "print(\"Average Inference_Time:\", average_Inference_Time)\n",
        "print(\"************************************************\")\n",
        "\n",
        "print(\"Best Training_time:\", best_Training_time)\n",
        "print(\"Worst Training_time:\", worst_Training_time)\n",
        "print(\"Average Training_time:\", average_Training_time)\n",
        "print(\"************************************************\")\n",
        "\n",
        "print(\"Best roc_auc:\", best_roc_auc)\n",
        "print(\"Worst roc_auc:\", worst_roc_auc)\n",
        "print(\"Average roc_auc:\", average_roc_auc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fwDPBCoE5PEZ",
        "outputId": "82e63853-3233-4721-d5e7-659faab741ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Accuracy: 0.69\n",
            "Worst Accuracy: 0.65\n",
            "Average Accuracy: 0.67\n",
            "************************************************\n",
            "Best Precision: 0.64\n",
            "Worst Precision: 0.59\n",
            "Average Precision: 0.613\n",
            "************************************************\n",
            "Best Recall: 0.95\n",
            "Worst Recall: 0.93\n",
            "Average Recall: 0.94\n",
            "************************************************\n",
            "Best F1 Score: 0.76\n",
            "Worst F1 Score: 0.72\n",
            "Average F1 Score: 0.74\n",
            "************************************************\n",
            "Best Kappa: 0.38\n",
            "Worst Kappa: 0.31\n",
            "Average Kappa: 0.35\n",
            "************************************************\n",
            "Best Inference_Time: 0.01695\n",
            "Worst Inference_Time: 0.00261\n",
            "Average Inference_Time: 0.01018\n",
            "************************************************\n",
            "Best Training_time: 1.40234\n",
            "Worst Training_time: 0.80189\n",
            "Average Training_time: 1.00101\n",
            "************************************************\n",
            "Best roc_auc: 0.69\n",
            "Worst roc_auc: 0.66\n",
            "Average roc_auc: 0.67\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "drD5yBy_dqDN"
      },
      "source": [
        "# 2-SVM (Support Vector Machine)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SamrKhB5osjE"
      },
      "outputs": [],
      "source": [
        "SVM = SVC(kernel='linear', random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ms7GMMhj7MNY",
        "outputId": "c155f69e-a1e3-4466-a1fd-c880266269dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Metrics for SVM Model Fold 1:\n",
            "Inference Time: 1.4238 seconds\n",
            "training Time: 41.1783 seconds\n",
            "Accuracy: 0.63\n",
            "Precision: 0.58\n",
            "Recall: 0.96\n",
            "F1-score: 0.73\n",
            "kappa: 0.26\n",
            "ROC AUC: 0.63\n",
            "fpr: [0.         0.70117322 1.        ]\n",
            "tpr: [0.        0.9634394 1.       ]\n",
            "thresholds: [2 1 0]\n",
            "[[ 433 1016]\n",
            " [  54 1423]]\n",
            "********************************************************************\n",
            "Metrics for SVM Model Fold 2:\n",
            "Inference Time: 1.4339 seconds\n",
            "training Time: 40.4709 seconds\n",
            "Accuracy: 0.64\n",
            "Precision: 0.59\n",
            "Recall: 0.96\n",
            "F1-score: 0.73\n",
            "kappa: 0.29\n",
            "ROC AUC: 0.65\n",
            "fpr: [0.         0.66666667 1.        ]\n",
            "tpr: [0.         0.96206897 1.        ]\n",
            "thresholds: [2 1 0]\n",
            "[[ 492  984]\n",
            " [  55 1395]]\n",
            "********************************************************************\n",
            "Metrics for SVM Model Fold 3:\n",
            "Inference Time: 2.7054 seconds\n",
            "training Time: 47.3386 seconds\n",
            "Accuracy: 0.66\n",
            "Precision: 0.60\n",
            "Recall: 0.97\n",
            "F1-score: 0.74\n",
            "kappa: 0.31\n",
            "ROC AUC: 0.65\n",
            "fpr: [0.         0.66388309 1.        ]\n",
            "tpr: [0.         0.96843519 1.        ]\n",
            "thresholds: [2 1 0]\n",
            "[[ 483  954]\n",
            " [  47 1442]]\n",
            "********************************************************************\n",
            "Metrics for SVM Model Fold 4:\n",
            "Inference Time: 1.4105 seconds\n",
            "training Time: 42.8625 seconds\n",
            "Accuracy: 0.63\n",
            "Precision: 0.57\n",
            "Recall: 0.96\n",
            "F1-score: 0.72\n",
            "kappa: 0.27\n",
            "ROC AUC: 0.64\n",
            "fpr: [0.         0.68248663 1.        ]\n",
            "tpr: [0.         0.96083916 1.        ]\n",
            "thresholds: [2 1 0]\n",
            "[[ 475 1021]\n",
            " [  56 1374]]\n",
            "********************************************************************\n",
            "Metrics for SVM Model Fold 5:\n",
            "Inference Time: 1.4079 seconds\n",
            "training Time: 44.3506 seconds\n",
            "Accuracy: 0.64\n",
            "Precision: 0.58\n",
            "Recall: 0.95\n",
            "F1-score: 0.72\n",
            "kappa: 0.29\n",
            "ROC AUC: 0.65\n",
            "fpr: [0.         0.65863454 1.        ]\n",
            "tpr: [0.         0.95108316 1.        ]\n",
            "thresholds: [2 1 0]\n",
            "[[ 510  984]\n",
            " [  70 1361]]\n",
            "********************************************************************\n",
            "Metrics for SVM Model Fold 6:\n",
            "Inference Time: 1.4221 seconds\n",
            "training Time: 38.6784 seconds\n",
            "Accuracy: 0.66\n",
            "Precision: 0.61\n",
            "Recall: 0.96\n",
            "F1-score: 0.75\n",
            "kappa: 0.31\n",
            "ROC AUC: 0.65\n",
            "fpr: [0.         0.66335227 1.        ]\n",
            "tpr: [0.         0.96440343 1.        ]\n",
            "thresholds: [2 1 0]\n",
            "[[ 474  934]\n",
            " [  54 1463]]\n",
            "********************************************************************\n",
            "Metrics for SVM Model Fold 7:\n",
            "Inference Time: 1.4193 seconds\n",
            "training Time: 38.1403 seconds\n",
            "Accuracy: 0.63\n",
            "Precision: 0.58\n",
            "Recall: 0.96\n",
            "F1-score: 0.72\n",
            "kappa: 0.26\n",
            "ROC AUC: 0.63\n",
            "fpr: [0.         0.69917582 1.        ]\n",
            "tpr: [0.         0.95983662 1.        ]\n",
            "thresholds: [2 1 0]\n",
            "[[ 438 1018]\n",
            " [  59 1410]]\n",
            "********************************************************************\n",
            "Metrics for SVM Model Fold 8:\n",
            "Inference Time: 1.4134 seconds\n",
            "training Time: 43.0551 seconds\n",
            "Accuracy: 0.63\n",
            "Precision: 0.58\n",
            "Recall: 0.96\n",
            "F1-score: 0.72\n",
            "kappa: 0.27\n",
            "ROC AUC: 0.64\n",
            "fpr: [0.         0.68699187 1.        ]\n",
            "tpr: [0.         0.96273292 1.        ]\n",
            "thresholds: [2 1 0]\n",
            "[[ 462 1014]\n",
            " [  54 1395]]\n",
            "********************************************************************\n",
            "Metrics for SVM Model Fold 9:\n",
            "Inference Time: 1.4284 seconds\n",
            "training Time: 40.8982 seconds\n",
            "Accuracy: 0.65\n",
            "Precision: 0.59\n",
            "Recall: 0.98\n",
            "F1-score: 0.74\n",
            "kappa: 0.30\n",
            "ROC AUC: 0.65\n",
            "fpr: [0.         0.68316151 1.        ]\n",
            "tpr: [0.         0.97755102 1.        ]\n",
            "thresholds: [2 1 0]\n",
            "[[ 461  994]\n",
            " [  33 1437]]\n",
            "********************************************************************\n",
            "Metrics for SVM Model Fold 10:\n",
            "Inference Time: 1.4299 seconds\n",
            "training Time: 40.9651 seconds\n",
            "Accuracy: 0.64\n",
            "Precision: 0.58\n",
            "Recall: 0.97\n",
            "F1-score: 0.73\n",
            "kappa: 0.28\n",
            "ROC AUC: 0.64\n",
            "fpr: [0.         0.68648649 1.        ]\n",
            "tpr: [0.         0.97093426 1.        ]\n",
            "thresholds: [2 1 0]\n",
            "[[ 464 1016]\n",
            " [  42 1403]]\n",
            "********************************************************************\n"
          ]
        }
      ],
      "source": [
        "resultsSVM = {}\n",
        "\n",
        "kf = KFold(n_splits=10, random_state = 42, shuffle=True)\n",
        "fld = 1\n",
        "i = 1\n",
        "X = np.concatenate([X_trainO, X_testO], axis=0)\n",
        "y = np.concatenate([y_trainO, y_testO], axis=0)\n",
        "X_df = pd.DataFrame(X)\n",
        "y_df = pd.DataFrame(y)\n",
        "for train_index, test_index in kf.split(X):\n",
        "\n",
        "        X_trainV, X_testV = X_df.iloc[train_index], X_df.iloc[test_index]\n",
        "        y_trainV, y_testV = y_df.iloc[train_index], y_df.iloc[test_index]\n",
        "\n",
        "        start_time = time.time()\n",
        "        SVM.fit(X_trainV, y_trainV)\n",
        "        Training_time = time.time() - start_time\n",
        "\n",
        "        start_time = time.time()\n",
        "        y_predictSVM = SVM.predict(X_testV)\n",
        "        Inference_Time = time.time() - start_time\n",
        "\n",
        "        accuracy = accuracy_score(y_testV, y_predictSVM)\n",
        "        precision = precision_score(y_testV, y_predictSVM)\n",
        "        recall = recall_score(y_testV, y_predictSVM)\n",
        "        f1= f1_score(y_testV, y_predictSVM)\n",
        "        kappa = cohen_kappa_score(y_testV, y_predictSVM)\n",
        "        roc_auc = roc_auc_score(y_testV, y_predictSVM)\n",
        "        fpr, tpr, thresholds = roc_curve(y_testV, y_predictSVM)\n",
        "        conf_mat = confusion_matrix(y_testV, y_predictSVM)\n",
        "        resultsSVM[f'Model_{fld}'] = {'Matrix': conf_mat, 'accuracy': accuracy, 'precision': precision,\n",
        "                                  'recall': recall, 'f1': f1, 'kappa': kappa, 'roc_auc': roc_auc,'fpr':fpr\n",
        "                                     ,'tpr':tpr,'thresholds':thresholds,'Inference_Time':Inference_Time,'Training_time':Training_time}\n",
        "\n",
        "\n",
        "        # Print metrics for the SVM model\n",
        "        print(f'Metrics for SVM Model Fold {fld}:')\n",
        "        print(f\"Inference Time: {Inference_Time:.4f} seconds\")\n",
        "        print(f\"training Time: {Training_time:.4f} seconds\")\n",
        "        print(f\"Accuracy: {accuracy:.2f}\")\n",
        "        print(f\"Precision: {precision:.2f}\")\n",
        "        print(f\"Recall: {recall:.2f}\")\n",
        "        print(f\"F1-score: {f1:.2f}\")\n",
        "        print(f\"kappa: {kappa:.2f}\")\n",
        "        print(f\"ROC AUC: {roc_auc:.2f}\")\n",
        "        print(f\"fpr: {fpr}\")\n",
        "        print(f\"tpr: {tpr}\")\n",
        "        print(f\"thresholds: {thresholds}\")\n",
        "        print(conf_mat)\n",
        "        print(\"********************************************************************\")\n",
        "        fld = fld + 1\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize lists to store metric values\n",
        "accuracies = []\n",
        "precisions = []\n",
        "recalls = []\n",
        "f1_scores = []\n",
        "kappas = []\n",
        "Inference_Time = []\n",
        "Training_time = []\n",
        "roc_auc = []\n",
        "# Loop over the results dictionary\n",
        "for model, metrics in resultsSVM.items():\n",
        "    accuracies.append(metrics['accuracy'])\n",
        "    precisions.append(metrics['precision'])\n",
        "    recalls.append(metrics['recall'])\n",
        "    f1_scores.append(metrics['f1'])\n",
        "    kappas.append(metrics['kappa'])\n",
        "    Inference_Time.append(metrics['Inference_Time'])\n",
        "    Training_time.append(metrics['Training_time'])\n",
        "    roc_auc.append(metrics['roc_auc'])\n",
        "\n",
        "# Calculate the best, worst, and average values for each metric\n",
        "best_accuracy = round(max(accuracies), 2)\n",
        "worst_accuracy = round(min(accuracies), 2)\n",
        "average_accuracy = round(sum(accuracies) / len(accuracies), 2)\n",
        "\n",
        "\n",
        "best_precision = round(max(precisions), 2)\n",
        "worst_precision = round(min(precisions), 2)\n",
        "average_precision = round(sum(precisions) / len(precisions), 3)\n",
        "\n",
        "best_recall = round(max(recalls), 2)\n",
        "worst_recall = round(min(recalls), 2)\n",
        "average_recall = round(sum(recalls) / len(recalls), 2)\n",
        "\n",
        "best_f1_score = round(max(f1_scores), 2)\n",
        "worst_f1_score = round(min(f1_scores), 2)\n",
        "average_f1_score = round(sum(f1_scores) / len(f1_scores), 2)\n",
        "\n",
        "best_kappa = round(max(kappas), 2)\n",
        "worst_kappa = round(min(kappas), 2)\n",
        "average_kappa = round(sum(kappas) / len(kappas), 2)\n",
        "\n",
        "best_Inference_Time = round(max(Inference_Time), 5)\n",
        "worst_Inference_Time = round(min(Inference_Time), 5)\n",
        "average_Inference_Time = round(sum(Inference_Time) / len(Inference_Time), 5)\n",
        "\n",
        "\n",
        "best_Training_time = round(max(Training_time), 5)\n",
        "worst_Training_time = round(min(Training_time), 5)\n",
        "average_Training_time = round(sum(Training_time) / len(Training_time), 5)\n",
        "\n",
        "best_roc_auc = round(max(roc_auc), 2)\n",
        "worst_roc_auc = round(min(roc_auc), 2)\n",
        "average_roc_auc = round(sum(roc_auc) / len(roc_auc), 2)\n",
        "\n",
        "# Print the results\n",
        "print(\"Best Accuracy:\", best_accuracy)\n",
        "print(\"Worst Accuracy:\", worst_accuracy)\n",
        "print(\"Average Accuracy:\", average_accuracy)\n",
        "\n",
        "print(\"************************************************\")\n",
        "\n",
        "\n",
        "print(\"Best Precision:\", best_precision)\n",
        "print(\"Worst Precision:\", worst_precision)\n",
        "print(\"Average Precision:\", average_precision)\n",
        "print(\"************************************************\")\n",
        "\n",
        "print(\"Best Recall:\", best_recall)\n",
        "print(\"Worst Recall:\", worst_recall)\n",
        "print(\"Average Recall:\", average_recall)\n",
        "print(\"************************************************\")\n",
        "\n",
        "print(\"Best F1 Score:\", best_f1_score)\n",
        "print(\"Worst F1 Score:\", worst_f1_score)\n",
        "print(\"Average F1 Score:\", average_f1_score)\n",
        "print(\"************************************************\")\n",
        "\n",
        "print(\"Best Kappa:\", best_kappa)\n",
        "print(\"Worst Kappa:\", worst_kappa)\n",
        "print(\"Average Kappa:\", average_kappa)\n",
        "\n",
        "print(\"************************************************\")\n",
        "\n",
        "print(\"Best Inference_Time:\", best_Inference_Time)\n",
        "print(\"Worst Inference_Time:\", worst_Inference_Time)\n",
        "print(\"Average Inference_Time:\", average_Inference_Time)\n",
        "print(\"************************************************\")\n",
        "\n",
        "print(\"Best Training_time:\", best_Training_time)\n",
        "print(\"Worst Training_time:\", worst_Training_time)\n",
        "print(\"Average Training_time:\", average_Training_time)\n",
        "print(\"************************************************\")\n",
        "\n",
        "print(\"Best roc_auc:\", best_roc_auc)\n",
        "print(\"Worst roc_auc:\", worst_roc_auc)\n",
        "print(\"Average roc_auc:\", average_roc_auc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4D6GJCMMawP5",
        "outputId": "0dcc9e22-96af-450d-a38c-8fb76605ffbf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Accuracy: 0.66\n",
            "Worst Accuracy: 0.63\n",
            "Average Accuracy: 0.64\n",
            "************************************************\n",
            "Best Precision: 0.61\n",
            "Worst Precision: 0.57\n",
            "Average Precision: 0.587\n",
            "************************************************\n",
            "Best Recall: 0.98\n",
            "Worst Recall: 0.95\n",
            "Average Recall: 0.96\n",
            "************************************************\n",
            "Best F1 Score: 0.75\n",
            "Worst F1 Score: 0.72\n",
            "Average F1 Score: 0.73\n",
            "************************************************\n",
            "Best Kappa: 0.31\n",
            "Worst Kappa: 0.26\n",
            "Average Kappa: 0.28\n",
            "************************************************\n",
            "Best Inference_Time: 2.70536\n",
            "Worst Inference_Time: 1.40792\n",
            "Average Inference_Time: 1.54944\n",
            "************************************************\n",
            "Best Training_time: 47.33864\n",
            "Worst Training_time: 38.14033\n",
            "Average Training_time: 41.79381\n",
            "************************************************\n",
            "Best roc_auc: 0.65\n",
            "Worst roc_auc: 0.63\n",
            "Average roc_auc: 0.64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CgFOGBDkqV17"
      },
      "source": [
        "# **3-RF(RandomForest)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FFfd-PAvqoUr"
      },
      "outputs": [],
      "source": [
        "\n",
        "RF = RandomForestClassifier(random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7GT9uwbGriDr",
        "outputId": "1e618c9b-2c5b-48c9-bdfb-dce411ebfac3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Metrics for RF Model Fold 1:\n",
            "Inference Time: 0.0898 seconds\n",
            "training Time: 12.6284 seconds\n",
            "Accuracy: 0.95\n",
            "Precision: 0.93\n",
            "Recall: 0.98\n",
            "F1-score: 0.96\n",
            "kappa: 0.91\n",
            "ROC AUC: 0.95\n",
            "fpr: [0.        0.0731539 1.       ]\n",
            "tpr: [0.        0.9817197 1.       ]\n",
            "thresholds: [2 1 0]\n",
            "[[1343  106]\n",
            " [  27 1450]]\n",
            "********************************************************************\n",
            "Metrics for RF Model Fold 2:\n",
            "Inference Time: 0.0666 seconds\n",
            "training Time: 7.0127 seconds\n",
            "Accuracy: 0.96\n",
            "Precision: 0.93\n",
            "Recall: 0.98\n",
            "F1-score: 0.96\n",
            "kappa: 0.92\n",
            "ROC AUC: 0.96\n",
            "fpr: [0.         0.06842818 1.        ]\n",
            "tpr: [0.         0.98413793 1.        ]\n",
            "thresholds: [2 1 0]\n",
            "[[1375  101]\n",
            " [  23 1427]]\n",
            "********************************************************************\n",
            "Metrics for RF Model Fold 3:\n",
            "Inference Time: 0.0771 seconds\n",
            "training Time: 7.4616 seconds\n",
            "Accuracy: 0.96\n",
            "Precision: 0.94\n",
            "Recall: 0.97\n",
            "F1-score: 0.96\n",
            "kappa: 0.92\n",
            "ROC AUC: 0.96\n",
            "fpr: [0.         0.05915101 1.        ]\n",
            "tpr: [0.         0.97447952 1.        ]\n",
            "thresholds: [2 1 0]\n",
            "[[1352   85]\n",
            " [  38 1451]]\n",
            "********************************************************************\n",
            "Metrics for RF Model Fold 4:\n",
            "Inference Time: 0.0685 seconds\n",
            "training Time: 6.7356 seconds\n",
            "Accuracy: 0.96\n",
            "Precision: 0.94\n",
            "Recall: 0.98\n",
            "F1-score: 0.96\n",
            "kappa: 0.92\n",
            "ROC AUC: 0.96\n",
            "fpr: [0.         0.06483957 1.        ]\n",
            "tpr: [0.         0.98461538 1.        ]\n",
            "thresholds: [2 1 0]\n",
            "[[1399   97]\n",
            " [  22 1408]]\n",
            "********************************************************************\n",
            "Metrics for RF Model Fold 5:\n",
            "Inference Time: 0.0653 seconds\n",
            "training Time: 7.6691 seconds\n",
            "Accuracy: 0.96\n",
            "Precision: 0.94\n",
            "Recall: 0.98\n",
            "F1-score: 0.96\n",
            "kappa: 0.92\n",
            "ROC AUC: 0.96\n",
            "fpr: [0.         0.06091031 1.        ]\n",
            "tpr: [0.         0.98322851 1.        ]\n",
            "thresholds: [2 1 0]\n",
            "[[1403   91]\n",
            " [  24 1407]]\n",
            "********************************************************************\n",
            "Metrics for RF Model Fold 6:\n",
            "Inference Time: 0.0654 seconds\n",
            "training Time: 6.5742 seconds\n",
            "Accuracy: 0.97\n",
            "Precision: 0.95\n",
            "Recall: 0.99\n",
            "F1-score: 0.97\n",
            "kappa: 0.93\n",
            "ROC AUC: 0.96\n",
            "fpr: [0.         0.05752841 1.        ]\n",
            "tpr: [0.         0.98681608 1.        ]\n",
            "thresholds: [2 1 0]\n",
            "[[1327   81]\n",
            " [  20 1497]]\n",
            "********************************************************************\n",
            "Metrics for RF Model Fold 7:\n",
            "Inference Time: 0.0658 seconds\n",
            "training Time: 7.7688 seconds\n",
            "Accuracy: 0.96\n",
            "Precision: 0.94\n",
            "Recall: 0.98\n",
            "F1-score: 0.96\n",
            "kappa: 0.92\n",
            "ROC AUC: 0.96\n",
            "fpr: [0.         0.06524725 1.        ]\n",
            "tpr: [0.         0.98230088 1.        ]\n",
            "thresholds: [2 1 0]\n",
            "[[1361   95]\n",
            " [  26 1443]]\n",
            "********************************************************************\n",
            "Metrics for RF Model Fold 8:\n",
            "Inference Time: 0.0867 seconds\n",
            "training Time: 8.0731 seconds\n",
            "Accuracy: 0.96\n",
            "Precision: 0.94\n",
            "Recall: 0.98\n",
            "F1-score: 0.96\n",
            "kappa: 0.92\n",
            "ROC AUC: 0.96\n",
            "fpr: [0.        0.0596206 1.       ]\n",
            "tpr: [0.         0.98205659 1.        ]\n",
            "thresholds: [2 1 0]\n",
            "[[1388   88]\n",
            " [  26 1423]]\n",
            "********************************************************************\n",
            "Metrics for RF Model Fold 9:\n",
            "Inference Time: 0.0668 seconds\n",
            "training Time: 8.5142 seconds\n",
            "Accuracy: 0.96\n",
            "Precision: 0.94\n",
            "Recall: 0.98\n",
            "F1-score: 0.96\n",
            "kappa: 0.92\n",
            "ROC AUC: 0.96\n",
            "fpr: [0.        0.0604811 1.       ]\n",
            "tpr: [0.         0.98095238 1.        ]\n",
            "thresholds: [2 1 0]\n",
            "[[1367   88]\n",
            " [  28 1442]]\n",
            "********************************************************************\n",
            "Metrics for RF Model Fold 10:\n",
            "Inference Time: 0.0732 seconds\n",
            "training Time: 6.7200 seconds\n",
            "Accuracy: 0.96\n",
            "Precision: 0.94\n",
            "Recall: 0.98\n",
            "F1-score: 0.96\n",
            "kappa: 0.92\n",
            "ROC AUC: 0.96\n",
            "fpr: [0.         0.06216216 1.        ]\n",
            "tpr: [0.         0.98200692 1.        ]\n",
            "thresholds: [2 1 0]\n",
            "[[1388   92]\n",
            " [  26 1419]]\n",
            "********************************************************************\n"
          ]
        }
      ],
      "source": [
        "resultsRF = {}\n",
        "\n",
        "kf = KFold(n_splits=10, random_state = 42, shuffle=True)\n",
        "fld = 1\n",
        "i = 1\n",
        "X = np.concatenate([X_trainO, X_testO], axis=0)\n",
        "y = np.concatenate([y_trainO, y_testO], axis=0)\n",
        "X_df = pd.DataFrame(X)\n",
        "y_df = pd.DataFrame(y)\n",
        "for train_index, test_index in kf.split(X):\n",
        "\n",
        "        X_trainV, X_testV = X_df.iloc[train_index], X_df.iloc[test_index]\n",
        "        y_trainV, y_testV = y_df.iloc[train_index], y_df.iloc[test_index]\n",
        "\n",
        "        start_time = time.time()\n",
        "        RF.fit(X_trainV, y_trainV)\n",
        "        Training_time = time.time() - start_time\n",
        "\n",
        "        start_time = time.time()\n",
        "        y_predictRF = RF.predict(X_testV)\n",
        "        Inference_time = time.time() - start_time\n",
        "\n",
        "        accuracy = accuracy_score(y_testV, y_predictRF)\n",
        "        precision = precision_score(y_testV, y_predictRF)\n",
        "        recall = recall_score(y_testV, y_predictRF)\n",
        "        f1= f1_score(y_testV, y_predictRF)\n",
        "        kappa = cohen_kappa_score(y_testV, y_predictRF)\n",
        "        roc_auc = roc_auc_score(y_testV, y_predictRF)\n",
        "        fpr, tpr, thresholds = roc_curve(y_testV, y_predictRF)\n",
        "\n",
        "        conf_mat = confusion_matrix(y_testV, y_predictRF)\n",
        "        resultsRF[f'Model_{fld}'] = {'Matrix': conf_mat, 'accuracy': accuracy, 'precision': precision, 'recall': recall, 'f1': f1,'kappa':kappa, 'roc_auc': roc_auc,'fpr':fpr\n",
        "                                     ,'tpr':tpr,'thresholds':thresholds,'Inference_Time':Inference_time,'Training_time':Training_time}\n",
        "\n",
        "        print(f'Metrics for RF Model Fold {fld}:')\n",
        "        print(f\"Inference Time: {Inference_time:.4f} seconds\")\n",
        "        print(f\"training Time: {Training_time:.4f} seconds\")\n",
        "        print(f\"Accuracy: {accuracy:.2f}\")\n",
        "        print(f\"Precision: {precision:.2f}\")\n",
        "        print(f\"Recall: {recall:.2f}\")\n",
        "        print(f\"F1-score: {f1:.2f}\")\n",
        "        print(f\"kappa: {kappa:.2f}\")\n",
        "        print(f\"ROC AUC: {roc_auc:.2f}\")\n",
        "        print(f\"fpr: {fpr}\")\n",
        "        print(f\"tpr: {tpr}\")\n",
        "        print(f\"thresholds: {thresholds}\")\n",
        "        print(conf_mat)\n",
        "        print(\"********************************************************************\")\n",
        "        fld = fld + 1\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize lists to store metric values\n",
        "accuracies = []\n",
        "precisions = []\n",
        "recalls = []\n",
        "f1_scores = []\n",
        "kappas = []\n",
        "Inference_Time = []\n",
        "Training_time = []\n",
        "roc_auc = []\n",
        "# Loop over the results dictionary\n",
        "for model, metrics in resultsRF.items():\n",
        "    accuracies.append(metrics['accuracy'])\n",
        "    precisions.append(metrics['precision'])\n",
        "    recalls.append(metrics['recall'])\n",
        "    f1_scores.append(metrics['f1'])\n",
        "    kappas.append(metrics['kappa'])\n",
        "    Inference_Time.append(metrics['Inference_Time'])\n",
        "    Training_time.append(metrics['Training_time'])\n",
        "    roc_auc.append(metrics['roc_auc'])\n",
        "\n",
        "# Calculate the best, worst, and average values for each metric\n",
        "best_accuracy = round(max(accuracies), 2)\n",
        "worst_accuracy = round(min(accuracies), 2)\n",
        "average_accuracy = round(sum(accuracies) / len(accuracies), 2)\n",
        "\n",
        "\n",
        "best_precision = round(max(precisions), 2)\n",
        "worst_precision = round(min(precisions), 2)\n",
        "average_precision = round(sum(precisions) / len(precisions), 3)\n",
        "\n",
        "best_recall = round(max(recalls), 2)\n",
        "worst_recall = round(min(recalls), 2)\n",
        "average_recall = round(sum(recalls) / len(recalls), 2)\n",
        "\n",
        "best_f1_score = round(max(f1_scores), 2)\n",
        "worst_f1_score = round(min(f1_scores), 2)\n",
        "average_f1_score = round(sum(f1_scores) / len(f1_scores), 2)\n",
        "\n",
        "best_kappa = round(max(kappas), 2)\n",
        "worst_kappa = round(min(kappas), 2)\n",
        "average_kappa = round(sum(kappas) / len(kappas), 2)\n",
        "\n",
        "best_Inference_Time = round(max(Inference_Time), 5)\n",
        "worst_Inference_Time = round(min(Inference_Time), 5)\n",
        "average_Inference_Time = round(sum(Inference_Time) / len(Inference_Time), 5)\n",
        "\n",
        "\n",
        "best_Training_time = round(max(Training_time), 5)\n",
        "worst_Training_time = round(min(Training_time), 5)\n",
        "average_Training_time = round(sum(Training_time) / len(Training_time), 5)\n",
        "\n",
        "best_roc_auc = round(max(roc_auc), 2)\n",
        "worst_roc_auc = round(min(roc_auc), 2)\n",
        "average_roc_auc = round(sum(roc_auc) / len(roc_auc), 2)\n",
        "\n",
        "# Print the results\n",
        "print(\"Best Accuracy:\", best_accuracy)\n",
        "print(\"Worst Accuracy:\", worst_accuracy)\n",
        "print(\"Average Accuracy:\", average_accuracy)\n",
        "\n",
        "print(\"************************************************\")\n",
        "\n",
        "\n",
        "print(\"Best Precision:\", best_precision)\n",
        "print(\"Worst Precision:\", worst_precision)\n",
        "print(\"Average Precision:\", average_precision)\n",
        "print(\"************************************************\")\n",
        "\n",
        "print(\"Best Recall:\", best_recall)\n",
        "print(\"Worst Recall:\", worst_recall)\n",
        "print(\"Average Recall:\", average_recall)\n",
        "print(\"************************************************\")\n",
        "\n",
        "print(\"Best F1 Score:\", best_f1_score)\n",
        "print(\"Worst F1 Score:\", worst_f1_score)\n",
        "print(\"Average F1 Score:\", average_f1_score)\n",
        "print(\"************************************************\")\n",
        "\n",
        "print(\"Best Kappa:\", best_kappa)\n",
        "print(\"Worst Kappa:\", worst_kappa)\n",
        "print(\"Average Kappa:\", average_kappa)\n",
        "\n",
        "print(\"************************************************\")\n",
        "\n",
        "print(\"Best Inference_Time:\", best_Inference_Time)\n",
        "print(\"Worst Inference_Time:\", worst_Inference_Time)\n",
        "print(\"Average Inference_Time:\", average_Inference_Time)\n",
        "print(\"************************************************\")\n",
        "\n",
        "print(\"Best Training_time:\", best_Training_time)\n",
        "print(\"Worst Training_time:\", worst_Training_time)\n",
        "print(\"Average Training_time:\", average_Training_time)\n",
        "print(\"************************************************\")\n",
        "\n",
        "print(\"Best roc_auc:\", best_roc_auc)\n",
        "print(\"Worst roc_auc:\", worst_roc_auc)\n",
        "print(\"Average roc_auc:\", average_roc_auc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dc4cltw43Ggs",
        "outputId": "27ec1db0-01b7-4f64-8868-a75a69a8f9e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Accuracy: 0.97\n",
            "Worst Accuracy: 0.95\n",
            "Average Accuracy: 0.96\n",
            "************************************************\n",
            "Best Precision: 0.95\n",
            "Worst Precision: 0.93\n",
            "Average Precision: 0.94\n",
            "************************************************\n",
            "Best Recall: 0.99\n",
            "Worst Recall: 0.97\n",
            "Average Recall: 0.98\n",
            "************************************************\n",
            "Best F1 Score: 0.97\n",
            "Worst F1 Score: 0.96\n",
            "Average F1 Score: 0.96\n",
            "************************************************\n",
            "Best Kappa: 0.93\n",
            "Worst Kappa: 0.91\n",
            "Average Kappa: 0.92\n",
            "************************************************\n",
            "Best Inference_Time: 0.08977\n",
            "Worst Inference_Time: 0.06526\n",
            "Average Inference_Time: 0.07251\n",
            "************************************************\n",
            "Best Training_time: 12.62842\n",
            "Worst Training_time: 6.57416\n",
            "Average Training_time: 7.91576\n",
            "************************************************\n",
            "Best roc_auc: 0.96\n",
            "Worst roc_auc: 0.95\n",
            "Average roc_auc: 0.96\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B4gM0qjjP4uA"
      },
      "source": [
        "# **4-DT(Decision Tree)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "izp-EZ_0P5SF"
      },
      "outputs": [],
      "source": [
        "DT = DecisionTreeClassifier(random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KP_Et0ZuP9F8",
        "outputId": "3637b7e9-6956-4dab-fbdf-6c1a3113c79c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Metrics for DT Model Fold 1:\n",
            "Inference Time: 0.0029 seconds\n",
            "training Time: 0.5255 seconds\n",
            "Accuracy: 0.94\n",
            "Precision: 0.91\n",
            "Recall: 0.98\n",
            "F1-score: 0.94\n",
            "kappa: 0.88\n",
            "ROC AUC: 0.94\n",
            "fpr: [0.         0.09730849 1.        ]\n",
            "tpr: [0.         0.97630332 1.        ]\n",
            "thresholds: [2 1 0]\n",
            "[[1308  141]\n",
            " [  35 1442]]\n",
            "********************************************************************\n",
            "Metrics for DT Model Fold 2:\n",
            "Inference Time: 0.0029 seconds\n",
            "training Time: 0.6108 seconds\n",
            "Accuracy: 0.94\n",
            "Precision: 0.91\n",
            "Recall: 0.98\n",
            "F1-score: 0.95\n",
            "kappa: 0.89\n",
            "ROC AUC: 0.94\n",
            "fpr: [0.         0.09417344 1.        ]\n",
            "tpr: [0.         0.98206897 1.        ]\n",
            "thresholds: [2 1 0]\n",
            "[[1337  139]\n",
            " [  26 1424]]\n",
            "********************************************************************\n",
            "Metrics for DT Model Fold 3:\n",
            "Inference Time: 0.0028 seconds\n",
            "training Time: 0.5296 seconds\n",
            "Accuracy: 0.94\n",
            "Precision: 0.92\n",
            "Recall: 0.97\n",
            "F1-score: 0.94\n",
            "kappa: 0.88\n",
            "ROC AUC: 0.94\n",
            "fpr: [0.         0.09255393 1.        ]\n",
            "tpr: [0.         0.96709201 1.        ]\n",
            "thresholds: [2 1 0]\n",
            "[[1304  133]\n",
            " [  49 1440]]\n",
            "********************************************************************\n",
            "Metrics for DT Model Fold 4:\n",
            "Inference Time: 0.0023 seconds\n",
            "training Time: 0.4811 seconds\n",
            "Accuracy: 0.94\n",
            "Precision: 0.91\n",
            "Recall: 0.98\n",
            "F1-score: 0.95\n",
            "kappa: 0.89\n",
            "ROC AUC: 0.95\n",
            "fpr: [0.         0.08890374 1.        ]\n",
            "tpr: [0.         0.98041958 1.        ]\n",
            "thresholds: [2 1 0]\n",
            "[[1363  133]\n",
            " [  28 1402]]\n",
            "********************************************************************\n",
            "Metrics for DT Model Fold 5:\n",
            "Inference Time: 0.0022 seconds\n",
            "training Time: 0.3704 seconds\n",
            "Accuracy: 0.95\n",
            "Precision: 0.92\n",
            "Recall: 0.97\n",
            "F1-score: 0.95\n",
            "kappa: 0.90\n",
            "ROC AUC: 0.95\n",
            "fpr: [0.         0.07697456 1.        ]\n",
            "tpr: [0.         0.97344514 1.        ]\n",
            "thresholds: [2 1 0]\n",
            "[[1379  115]\n",
            " [  38 1393]]\n",
            "********************************************************************\n",
            "Metrics for DT Model Fold 6:\n",
            "Inference Time: 0.0022 seconds\n",
            "training Time: 0.3851 seconds\n",
            "Accuracy: 0.94\n",
            "Precision: 0.92\n",
            "Recall: 0.98\n",
            "F1-score: 0.95\n",
            "kappa: 0.89\n",
            "ROC AUC: 0.94\n",
            "fpr: [0.         0.09161932 1.        ]\n",
            "tpr: [0.         0.97890574 1.        ]\n",
            "thresholds: [2 1 0]\n",
            "[[1279  129]\n",
            " [  32 1485]]\n",
            "********************************************************************\n",
            "Metrics for DT Model Fold 7:\n",
            "Inference Time: 0.0022 seconds\n",
            "training Time: 0.3683 seconds\n",
            "Accuracy: 0.95\n",
            "Precision: 0.93\n",
            "Recall: 0.98\n",
            "F1-score: 0.95\n",
            "kappa: 0.90\n",
            "ROC AUC: 0.95\n",
            "fpr: [0.         0.07898352 1.        ]\n",
            "tpr: [0.         0.97549353 1.        ]\n",
            "thresholds: [2 1 0]\n",
            "[[1341  115]\n",
            " [  36 1433]]\n",
            "********************************************************************\n",
            "Metrics for DT Model Fold 8:\n",
            "Inference Time: 0.0028 seconds\n",
            "training Time: 0.3820 seconds\n",
            "Accuracy: 0.95\n",
            "Precision: 0.92\n",
            "Recall: 0.97\n",
            "F1-score: 0.95\n",
            "kappa: 0.89\n",
            "ROC AUC: 0.95\n",
            "fpr: [0.         0.08130081 1.        ]\n",
            "tpr: [0.         0.97308489 1.        ]\n",
            "thresholds: [2 1 0]\n",
            "[[1356  120]\n",
            " [  39 1410]]\n",
            "********************************************************************\n",
            "Metrics for DT Model Fold 9:\n",
            "Inference Time: 0.0022 seconds\n",
            "training Time: 0.3783 seconds\n",
            "Accuracy: 0.94\n",
            "Precision: 0.91\n",
            "Recall: 0.98\n",
            "F1-score: 0.94\n",
            "kappa: 0.88\n",
            "ROC AUC: 0.94\n",
            "fpr: [0.         0.09278351 1.        ]\n",
            "tpr: [0.        0.9755102 1.       ]\n",
            "thresholds: [2 1 0]\n",
            "[[1320  135]\n",
            " [  36 1434]]\n",
            "********************************************************************\n",
            "Metrics for DT Model Fold 10:\n",
            "Inference Time: 0.0022 seconds\n",
            "training Time: 0.3713 seconds\n",
            "Accuracy: 0.94\n",
            "Precision: 0.91\n",
            "Recall: 0.97\n",
            "F1-score: 0.94\n",
            "kappa: 0.87\n",
            "ROC AUC: 0.94\n",
            "fpr: [0.         0.09932432 1.        ]\n",
            "tpr: [0.         0.97301038 1.        ]\n",
            "thresholds: [2 1 0]\n",
            "[[1333  147]\n",
            " [  39 1406]]\n",
            "********************************************************************\n"
          ]
        }
      ],
      "source": [
        "resultsDT = {}\n",
        "\n",
        "kf = KFold(n_splits=10, random_state = 42, shuffle=True)\n",
        "fld = 1\n",
        "i = 1\n",
        "X = np.concatenate([X_trainO, X_testO], axis=0)\n",
        "y = np.concatenate([y_trainO, y_testO], axis=0)\n",
        "X_df = pd.DataFrame(X)\n",
        "y_df = pd.DataFrame(y)\n",
        "for train_index, test_index in kf.split(X):\n",
        "\n",
        "        X_trainV, X_testV = X_df.iloc[train_index], X_df.iloc[test_index]\n",
        "        y_trainV, y_testV = y_df.iloc[train_index], y_df.iloc[test_index]\n",
        "\n",
        "        start_time = time.time()\n",
        "        DT.fit(X_trainV, y_trainV)\n",
        "        Training_time = time.time() - start_time\n",
        "\n",
        "        start_time = time.time()\n",
        "        y_predictDT = DT.predict(X_testV)\n",
        "        Inference_Time = time.time() - start_time\n",
        "\n",
        "        accuracy = accuracy_score(y_testV, y_predictDT)\n",
        "        precision = precision_score(y_testV, y_predictDT)\n",
        "        recall = recall_score(y_testV, y_predictDT)\n",
        "        f1= f1_score(y_testV, y_predictDT)\n",
        "        kappa = cohen_kappa_score(y_testV, y_predictDT)\n",
        "\n",
        "        roc_auc = roc_auc_score(y_testV, y_predictDT)\n",
        "        fpr, tpr, thresholds = roc_curve(y_testV, y_predictDT)\n",
        "\n",
        "        conf_mat = confusion_matrix(y_testV, y_predictDT)\n",
        "        resultsDT[f'Model_{fld}'] = {'Matrix': conf_mat, 'accuracy': accuracy, 'precision': precision, 'recall': recall, 'f1': f1,'kappa':kappa, 'roc_auc': roc_auc,'fpr':fpr\n",
        "                                     ,'tpr':tpr,'thresholds':thresholds,'Inference_Time':Inference_Time,'Training_time':Training_time}\n",
        "\n",
        "\n",
        "\n",
        "        # Print metrics for the DT model\n",
        "        print(f'Metrics for DT Model Fold {fld}:')\n",
        "        print(f\"Inference Time: {Inference_Time:.4f} seconds\")\n",
        "        print(f\"training Time: {Training_time:.4f} seconds\")\n",
        "        print(f\"Accuracy: {accuracy:.2f}\")\n",
        "        print(f\"Precision: {precision:.2f}\")\n",
        "        print(f\"Recall: {recall:.2f}\")\n",
        "        print(f\"F1-score: {f1:.2f}\")\n",
        "        print(f\"kappa: {kappa:.2f}\")\n",
        "        print(f\"ROC AUC: {roc_auc:.2f}\")\n",
        "        print(f\"fpr: {fpr}\")\n",
        "        print(f\"tpr: {tpr}\")\n",
        "        print(f\"thresholds: {thresholds}\")\n",
        "        print(conf_mat)\n",
        "        print(\"********************************************************************\")\n",
        "        fld = fld + 1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize lists to store metric values\n",
        "accuracies = []\n",
        "precisions = []\n",
        "recalls = []\n",
        "f1_scores = []\n",
        "kappas = []\n",
        "Inference_Time = []\n",
        "Training_time = []\n",
        "roc_auc = []\n",
        "# Loop over the results dictionary\n",
        "for model, metrics in resultsDT.items():\n",
        "    accuracies.append(metrics['accuracy'])\n",
        "    precisions.append(metrics['precision'])\n",
        "    recalls.append(metrics['recall'])\n",
        "    f1_scores.append(metrics['f1'])\n",
        "    kappas.append(metrics['kappa'])\n",
        "    Inference_Time.append(metrics['Inference_Time'])\n",
        "    Training_time.append(metrics['Training_time'])\n",
        "    roc_auc.append(metrics['roc_auc'])\n",
        "\n",
        "# Calculate the best, worst, and average values for each metric\n",
        "best_accuracy = round(max(accuracies), 2)\n",
        "worst_accuracy = round(min(accuracies), 2)\n",
        "average_accuracy = round(sum(accuracies) / len(accuracies), 2)\n",
        "\n",
        "\n",
        "best_precision = round(max(precisions), 2)\n",
        "worst_precision = round(min(precisions), 2)\n",
        "average_precision = round(sum(precisions) / len(precisions), 3)\n",
        "\n",
        "best_recall = round(max(recalls), 2)\n",
        "worst_recall = round(min(recalls), 2)\n",
        "average_recall = round(sum(recalls) / len(recalls), 2)\n",
        "\n",
        "best_f1_score = round(max(f1_scores), 2)\n",
        "worst_f1_score = round(min(f1_scores), 2)\n",
        "average_f1_score = round(sum(f1_scores) / len(f1_scores), 2)\n",
        "\n",
        "best_kappa = round(max(kappas), 2)\n",
        "worst_kappa = round(min(kappas), 2)\n",
        "average_kappa = round(sum(kappas) / len(kappas), 2)\n",
        "\n",
        "best_Inference_Time = round(max(Inference_Time), 5)\n",
        "worst_Inference_Time = round(min(Inference_Time), 5)\n",
        "average_Inference_Time = round(sum(Inference_Time) / len(Inference_Time), 5)\n",
        "\n",
        "\n",
        "best_Training_time = round(max(Training_time), 5)\n",
        "worst_Training_time = round(min(Training_time), 5)\n",
        "average_Training_time = round(sum(Training_time) / len(Training_time), 5)\n",
        "\n",
        "best_roc_auc = round(max(roc_auc), 2)\n",
        "worst_roc_auc = round(min(roc_auc), 2)\n",
        "average_roc_auc = round(sum(roc_auc) / len(roc_auc), 2)\n",
        "\n",
        "# Print the results\n",
        "print(\"Best Accuracy:\", best_accuracy)\n",
        "print(\"Worst Accuracy:\", worst_accuracy)\n",
        "print(\"Average Accuracy:\", average_accuracy)\n",
        "\n",
        "print(\"************************************************\")\n",
        "\n",
        "\n",
        "print(\"Best Precision:\", best_precision)\n",
        "print(\"Worst Precision:\", worst_precision)\n",
        "print(\"Average Precision:\", average_precision)\n",
        "print(\"************************************************\")\n",
        "\n",
        "print(\"Best Recall:\", best_recall)\n",
        "print(\"Worst Recall:\", worst_recall)\n",
        "print(\"Average Recall:\", average_recall)\n",
        "print(\"************************************************\")\n",
        "\n",
        "print(\"Best F1 Score:\", best_f1_score)\n",
        "print(\"Worst F1 Score:\", worst_f1_score)\n",
        "print(\"Average F1 Score:\", average_f1_score)\n",
        "print(\"************************************************\")\n",
        "\n",
        "print(\"Best Kappa:\", best_kappa)\n",
        "print(\"Worst Kappa:\", worst_kappa)\n",
        "print(\"Average Kappa:\", average_kappa)\n",
        "\n",
        "print(\"************************************************\")\n",
        "\n",
        "print(\"Best Inference_Time:\", best_Inference_Time)\n",
        "print(\"Worst Inference_Time:\", worst_Inference_Time)\n",
        "print(\"Average Inference_Time:\", average_Inference_Time)\n",
        "print(\"************************************************\")\n",
        "\n",
        "print(\"Best Training_time:\", best_Training_time)\n",
        "print(\"Worst Training_time:\", worst_Training_time)\n",
        "print(\"Average Training_time:\", average_Training_time)\n",
        "print(\"************************************************\")\n",
        "\n",
        "print(\"Best roc_auc:\", best_roc_auc)\n",
        "print(\"Worst roc_auc:\", worst_roc_auc)\n",
        "print(\"Average roc_auc:\", average_roc_auc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nQ0oi2_0Dzae",
        "outputId": "4cd36731-5ff9-436d-acb2-72ab4f422cbe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Accuracy: 0.95\n",
            "Worst Accuracy: 0.94\n",
            "Average Accuracy: 0.94\n",
            "************************************************\n",
            "Best Precision: 0.93\n",
            "Worst Precision: 0.91\n",
            "Average Precision: 0.916\n",
            "************************************************\n",
            "Best Recall: 0.98\n",
            "Worst Recall: 0.97\n",
            "Average Recall: 0.98\n",
            "************************************************\n",
            "Best F1 Score: 0.95\n",
            "Worst F1 Score: 0.94\n",
            "Average F1 Score: 0.94\n",
            "************************************************\n",
            "Best Kappa: 0.9\n",
            "Worst Kappa: 0.87\n",
            "Average Kappa: 0.89\n",
            "************************************************\n",
            "Best Inference_Time: 0.0029\n",
            "Worst Inference_Time: 0.00218\n",
            "Average Inference_Time: 0.00247\n",
            "************************************************\n",
            "Best Training_time: 0.61082\n",
            "Worst Training_time: 0.36828\n",
            "Average Training_time: 0.44025\n",
            "************************************************\n",
            "Best roc_auc: 0.95\n",
            "Worst roc_auc: 0.94\n",
            "Average roc_auc: 0.94\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGhYYjDsPtu9"
      },
      "source": [
        "# **5-XGBoost**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OISWY35jPxVk"
      },
      "outputs": [],
      "source": [
        "XGB = XGBClassifier(random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rybmpg5bPwV8",
        "outputId": "6351ce5e-6369-4a0a-998f-c80a0ea3fd03"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Metrics for XGBOOST Model Fold 1:\n",
            "Inference Time: 0.0119 seconds\n",
            "training Time: 0.6497 seconds\n",
            "Accuracy: 0.95\n",
            "Precision: 0.93\n",
            "Recall: 0.97\n",
            "F1-score: 0.95\n",
            "kappa: 0.89\n",
            "ROC AUC: 0.95\n",
            "fpr: [0.         0.07384403 1.        ]\n",
            "tpr: [0.         0.96750169 1.        ]\n",
            "thresholds: [2 1 0]\n",
            "[[1342  107]\n",
            " [  48 1429]]\n",
            "********************************************************************\n",
            "Metrics for XGBOOST Model Fold 2:\n",
            "Inference Time: 0.0120 seconds\n",
            "training Time: 0.6650 seconds\n",
            "Accuracy: 0.96\n",
            "Precision: 0.95\n",
            "Recall: 0.97\n",
            "F1-score: 0.96\n",
            "kappa: 0.91\n",
            "ROC AUC: 0.96\n",
            "fpr: [0.         0.05284553 1.        ]\n",
            "tpr: [0.         0.96551724 1.        ]\n",
            "thresholds: [2 1 0]\n",
            "[[1398   78]\n",
            " [  50 1400]]\n",
            "********************************************************************\n",
            "Metrics for XGBOOST Model Fold 3:\n",
            "Inference Time: 0.0167 seconds\n",
            "training Time: 0.6270 seconds\n",
            "Accuracy: 0.95\n",
            "Precision: 0.94\n",
            "Recall: 0.97\n",
            "F1-score: 0.96\n",
            "kappa: 0.91\n",
            "ROC AUC: 0.95\n",
            "fpr: [0.         0.05915101 1.        ]\n",
            "tpr: [0.         0.96709201 1.        ]\n",
            "thresholds: [2 1 0]\n",
            "[[1352   85]\n",
            " [  49 1440]]\n",
            "********************************************************************\n",
            "Metrics for XGBOOST Model Fold 4:\n",
            "Inference Time: 0.0147 seconds\n",
            "training Time: 4.7113 seconds\n",
            "Accuracy: 0.96\n",
            "Precision: 0.94\n",
            "Recall: 0.98\n",
            "F1-score: 0.96\n",
            "kappa: 0.92\n",
            "ROC AUC: 0.96\n",
            "fpr: [0.         0.05949198 1.        ]\n",
            "tpr: [0.         0.97552448 1.        ]\n",
            "thresholds: [2 1 0]\n",
            "[[1407   89]\n",
            " [  35 1395]]\n",
            "********************************************************************\n",
            "Metrics for XGBOOST Model Fold 5:\n",
            "Inference Time: 0.0492 seconds\n",
            "training Time: 1.7214 seconds\n",
            "Accuracy: 0.95\n",
            "Precision: 0.94\n",
            "Recall: 0.97\n",
            "F1-score: 0.95\n",
            "kappa: 0.90\n",
            "ROC AUC: 0.95\n",
            "fpr: [0.         0.06291834 1.        ]\n",
            "tpr: [0.         0.96785465 1.        ]\n",
            "thresholds: [2 1 0]\n",
            "[[1400   94]\n",
            " [  46 1385]]\n",
            "********************************************************************\n",
            "Metrics for XGBOOST Model Fold 6:\n",
            "Inference Time: 0.0120 seconds\n",
            "training Time: 1.3805 seconds\n",
            "Accuracy: 0.96\n",
            "Precision: 0.95\n",
            "Recall: 0.97\n",
            "F1-score: 0.96\n",
            "kappa: 0.91\n",
            "ROC AUC: 0.96\n",
            "fpr: [0.         0.05894886 1.        ]\n",
            "tpr: [0.         0.97231378 1.        ]\n",
            "thresholds: [2 1 0]\n",
            "[[1325   83]\n",
            " [  42 1475]]\n",
            "********************************************************************\n",
            "Metrics for XGBOOST Model Fold 7:\n",
            "Inference Time: 0.0101 seconds\n",
            "training Time: 1.2804 seconds\n",
            "Accuracy: 0.96\n",
            "Precision: 0.94\n",
            "Recall: 0.98\n",
            "F1-score: 0.96\n",
            "kappa: 0.91\n",
            "ROC AUC: 0.96\n",
            "fpr: [0.         0.06318681 1.        ]\n",
            "tpr: [0.         0.97617427 1.        ]\n",
            "thresholds: [2 1 0]\n",
            "[[1364   92]\n",
            " [  35 1434]]\n",
            "********************************************************************\n",
            "Metrics for XGBOOST Model Fold 8:\n",
            "Inference Time: 0.0102 seconds\n",
            "training Time: 0.5707 seconds\n",
            "Accuracy: 0.96\n",
            "Precision: 0.95\n",
            "Recall: 0.96\n",
            "F1-score: 0.96\n",
            "kappa: 0.91\n",
            "ROC AUC: 0.96\n",
            "fpr: [0.         0.04878049 1.        ]\n",
            "tpr: [0.         0.95997239 1.        ]\n",
            "thresholds: [2 1 0]\n",
            "[[1404   72]\n",
            " [  58 1391]]\n",
            "********************************************************************\n",
            "Metrics for XGBOOST Model Fold 9:\n",
            "Inference Time: 0.0104 seconds\n",
            "training Time: 0.5842 seconds\n",
            "Accuracy: 0.96\n",
            "Precision: 0.94\n",
            "Recall: 0.97\n",
            "F1-score: 0.96\n",
            "kappa: 0.91\n",
            "ROC AUC: 0.96\n",
            "fpr: [0.        0.0604811 1.       ]\n",
            "tpr: [0.         0.97482993 1.        ]\n",
            "thresholds: [2 1 0]\n",
            "[[1367   88]\n",
            " [  37 1433]]\n",
            "********************************************************************\n",
            "Metrics for XGBOOST Model Fold 10:\n",
            "Inference Time: 0.0103 seconds\n",
            "training Time: 0.5671 seconds\n",
            "Accuracy: 0.96\n",
            "Precision: 0.94\n",
            "Recall: 0.97\n",
            "F1-score: 0.96\n",
            "kappa: 0.91\n",
            "ROC AUC: 0.96\n",
            "fpr: [0.         0.05608108 1.        ]\n",
            "tpr: [0.         0.96678201 1.        ]\n",
            "thresholds: [2 1 0]\n",
            "[[1397   83]\n",
            " [  48 1397]]\n",
            "********************************************************************\n"
          ]
        }
      ],
      "source": [
        "resultsXGB = {}\n",
        "kf = KFold(n_splits=10, random_state = 42, shuffle=True)\n",
        "fld = 1\n",
        "i = 1\n",
        "X = np.concatenate([X_trainO, X_testO], axis=0)\n",
        "y = np.concatenate([y_trainO, y_testO], axis=0)\n",
        "X_df = pd.DataFrame(X)\n",
        "y_df = pd.DataFrame(y)\n",
        "for train_index, test_index in kf.split(X):\n",
        "\n",
        "        X_trainV, X_testV = X_df.iloc[train_index], X_df.iloc[test_index]\n",
        "        y_trainV, y_testV = y_df.iloc[train_index], y_df.iloc[test_index]\n",
        "\n",
        "        start_time = time.time()\n",
        "        XGB.fit(X_trainV, y_trainV)\n",
        "        Training_time = time.time() - start_time\n",
        "\n",
        "        start_time = time.time()\n",
        "        y_predictXGB = XGB.predict(X_testV)\n",
        "        Inference_Time = time.time() - start_time\n",
        "\n",
        "        accuracy = accuracy_score(y_testV, y_predictXGB)\n",
        "        precision = precision_score(y_testV, y_predictXGB)\n",
        "        recall = recall_score(y_testV, y_predictXGB)\n",
        "        f1= f1_score(y_testV, y_predictXGB)\n",
        "        kappa = cohen_kappa_score(y_testV, y_predictXGB)\n",
        "        roc_auc = roc_auc_score(y_testV, y_predictXGB)\n",
        "        fpr, tpr, thresholds = roc_curve(y_testV, y_predictXGB)\n",
        "        conf_mat = confusion_matrix(y_testV, y_predictXGB)\n",
        "        resultsXGB[f'Model_{fld}'] = {'Matrix': conf_mat, 'accuracy': accuracy, 'precision': precision, 'recall': recall, 'f1': f1,'kappa':kappa, 'roc_auc': roc_auc,'fpr':fpr\n",
        "                                     ,'tpr':tpr,'thresholds':thresholds,'Inference_Time':Inference_Time,'Training_time':Training_time}\n",
        "\n",
        "        # Print metrics for the XGBOOST model\n",
        "        print(f'Metrics for XGBOOST Model Fold {fld}:')\n",
        "        print(f\"Inference Time: {Inference_Time:.4f} seconds\")\n",
        "        print(f\"training Time: {Training_time:.4f} seconds\")\n",
        "        print(f\"Accuracy: {accuracy:.2f}\")\n",
        "        print(f\"Precision: {precision:.2f}\")\n",
        "        print(f\"Recall: {recall:.2f}\")\n",
        "        print(f\"F1-score: {f1:.2f}\")\n",
        "        print(f\"kappa: {kappa:.2f}\")\n",
        "        print(f\"ROC AUC: {roc_auc:.2f}\")\n",
        "        print(f\"fpr: {fpr}\")\n",
        "        print(f\"tpr: {tpr}\")\n",
        "        print(f\"thresholds: {thresholds}\")\n",
        "        print(conf_mat)\n",
        "        print(\"********************************************************************\")\n",
        "        fld = fld + 1\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize lists to store metric values\n",
        "accuracies = []\n",
        "precisions = []\n",
        "recalls = []\n",
        "f1_scores = []\n",
        "kappas = []\n",
        "Inference_Time = []\n",
        "Training_time = []\n",
        "roc_auc = []\n",
        "# Loop over the results dictionary\n",
        "for model, metrics in resultsXGB.items():\n",
        "    accuracies.append(metrics['accuracy'])\n",
        "    precisions.append(metrics['precision'])\n",
        "    recalls.append(metrics['recall'])\n",
        "    f1_scores.append(metrics['f1'])\n",
        "    kappas.append(metrics['kappa'])\n",
        "    Inference_Time.append(metrics['Inference_Time'])\n",
        "    Training_time.append(metrics['Training_time'])\n",
        "    roc_auc.append(metrics['roc_auc'])\n",
        "\n",
        "# Calculate the best, worst, and average values for each metric\n",
        "best_accuracy = round(max(accuracies), 2)\n",
        "worst_accuracy = round(min(accuracies), 2)\n",
        "average_accuracy = round(sum(accuracies) / len(accuracies), 2)\n",
        "\n",
        "\n",
        "best_precision = round(max(precisions), 2)\n",
        "worst_precision = round(min(precisions), 2)\n",
        "average_precision = round(sum(precisions) / len(precisions), 3)\n",
        "\n",
        "best_recall = round(max(recalls), 2)\n",
        "worst_recall = round(min(recalls), 2)\n",
        "average_recall = round(sum(recalls) / len(recalls), 2)\n",
        "\n",
        "best_f1_score = round(max(f1_scores), 2)\n",
        "worst_f1_score = round(min(f1_scores), 2)\n",
        "average_f1_score = round(sum(f1_scores) / len(f1_scores), 2)\n",
        "\n",
        "best_kappa = round(max(kappas), 2)\n",
        "worst_kappa = round(min(kappas), 2)\n",
        "average_kappa = round(sum(kappas) / len(kappas), 2)\n",
        "\n",
        "best_Inference_Time = round(max(Inference_Time), 2)\n",
        "worst_Inference_Time = round(min(Inference_Time), 2)\n",
        "average_Inference_Time = round(sum(Inference_Time) / len(Inference_Time), 2)\n",
        "\n",
        "\n",
        "best_Training_time = round(max(Training_time), 5)\n",
        "worst_Training_time = round(min(Training_time), 5)\n",
        "average_Training_time = round(sum(Training_time) / len(Training_time), 5)\n",
        "\n",
        "best_roc_auc = round(max(roc_auc), 5)\n",
        "worst_roc_auc = round(min(roc_auc), 5)\n",
        "average_roc_auc = round(sum(roc_auc) / len(roc_auc), 5)\n",
        "\n",
        "# Print the results\n",
        "print(\"Best Accuracy:\", best_accuracy)\n",
        "print(\"Worst Accuracy:\", worst_accuracy)\n",
        "print(\"Average Accuracy:\", average_accuracy)\n",
        "\n",
        "print(\"************************************************\")\n",
        "\n",
        "\n",
        "print(\"Best Precision:\", best_precision)\n",
        "print(\"Worst Precision:\", worst_precision)\n",
        "print(\"Average Precision:\", average_precision)\n",
        "print(\"************************************************\")\n",
        "\n",
        "print(\"Best Recall:\", best_recall)\n",
        "print(\"Worst Recall:\", worst_recall)\n",
        "print(\"Average Recall:\", average_recall)\n",
        "print(\"************************************************\")\n",
        "\n",
        "print(\"Best F1 Score:\", best_f1_score)\n",
        "print(\"Worst F1 Score:\", worst_f1_score)\n",
        "print(\"Average F1 Score:\", average_f1_score)\n",
        "print(\"************************************************\")\n",
        "\n",
        "print(\"Best Kappa:\", best_kappa)\n",
        "print(\"Worst Kappa:\", worst_kappa)\n",
        "print(\"Average Kappa:\", average_kappa)\n",
        "\n",
        "print(\"************************************************\")\n",
        "\n",
        "print(\"Best Inference_Time:\", best_Inference_Time)\n",
        "print(\"Worst Inference_Time:\", worst_Inference_Time)\n",
        "print(\"Average Inference_Time:\", average_Inference_Time)\n",
        "print(\"************************************************\")\n",
        "\n",
        "print(\"Best Training_time:\", best_Training_time)\n",
        "print(\"Worst Training_time:\", worst_Training_time)\n",
        "print(\"Average Training_time:\", average_Training_time)\n",
        "print(\"************************************************\")\n",
        "\n",
        "print(\"Best roc_auc:\", best_roc_auc)\n",
        "print(\"Worst roc_auc:\", worst_roc_auc)\n",
        "print(\"Average roc_auc:\", average_roc_auc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SOjl9mSIFV3D",
        "outputId": "0b9530e1-3aca-4688-bbf1-5f66020c6c14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Accuracy: 0.96\n",
            "Worst Accuracy: 0.95\n",
            "Average Accuracy: 0.95\n",
            "************************************************\n",
            "Best Precision: 0.95\n",
            "Worst Precision: 0.93\n",
            "Average Precision: 0.942\n",
            "************************************************\n",
            "Best Recall: 0.98\n",
            "Worst Recall: 0.96\n",
            "Average Recall: 0.97\n",
            "************************************************\n",
            "Best F1 Score: 0.96\n",
            "Worst F1 Score: 0.95\n",
            "Average F1 Score: 0.96\n",
            "************************************************\n",
            "Best Kappa: 0.92\n",
            "Worst Kappa: 0.89\n",
            "Average Kappa: 0.91\n",
            "************************************************\n",
            "Best Inference_Time: 0.05\n",
            "Worst Inference_Time: 0.01\n",
            "Average Inference_Time: 0.02\n",
            "************************************************\n",
            "Best Training_time: 4.71135\n",
            "Worst Training_time: 0.56713\n",
            "Average Training_time: 1.27574\n",
            "************************************************\n",
            "Best roc_auc: 0.95802\n",
            "Worst roc_auc: 0.94683\n",
            "Average roc_auc: 0.95489\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fat2Y4lHted_"
      },
      "source": [
        "# **6-MLP**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pwMVdtSftp9x"
      },
      "outputs": [],
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "MLP = MLPClassifier(hidden_layer_sizes=(100, ), max_iter=100, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RbXG9yErtg5Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59849405-cb0b-4b3f-d6b3-52da1e4b0e5c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Metrics for MLP Model Fold 1:\n",
            "Inference Time: 0.0048 seconds\n",
            "training Time: 33.5772 seconds\n",
            "Accuracy: 0.82\n",
            "Precision: 0.76\n",
            "Recall: 0.93\n",
            "F1-score: 0.84\n",
            "kappa: 0.63\n",
            "ROC AUC: 0.82\n",
            "fpr: [0.         0.29744651 1.        ]\n",
            "tpr: [0.        0.9309411 1.       ]\n",
            "thresholds: [2 1 0]\n",
            "[[1018  431]\n",
            " [ 102 1375]]\n",
            "********************************************************************\n",
            "Metrics for MLP Model Fold 2:\n",
            "Inference Time: 0.0043 seconds\n",
            "training Time: 24.7672 seconds\n",
            "Accuracy: 0.80\n",
            "Precision: 0.73\n",
            "Recall: 0.93\n",
            "F1-score: 0.82\n",
            "kappa: 0.60\n",
            "ROC AUC: 0.80\n",
            "fpr: [0.         0.32926829 1.        ]\n",
            "tpr: [0.         0.92689655 1.        ]\n",
            "thresholds: [2 1 0]\n",
            "[[ 990  486]\n",
            " [ 106 1344]]\n",
            "********************************************************************\n",
            "Metrics for MLP Model Fold 3:\n",
            "Inference Time: 0.0042 seconds\n",
            "training Time: 17.7241 seconds\n",
            "Accuracy: 0.81\n",
            "Precision: 0.75\n",
            "Recall: 0.95\n",
            "F1-score: 0.84\n",
            "kappa: 0.62\n",
            "ROC AUC: 0.81\n",
            "fpr: [0.         0.33194154 1.        ]\n",
            "tpr: [0.        0.9516454 1.       ]\n",
            "thresholds: [2 1 0]\n",
            "[[ 960  477]\n",
            " [  72 1417]]\n",
            "********************************************************************\n",
            "Metrics for MLP Model Fold 4:\n",
            "Inference Time: 0.0042 seconds\n",
            "training Time: 17.7329 seconds\n",
            "Accuracy: 0.79\n",
            "Precision: 0.74\n",
            "Recall: 0.91\n",
            "F1-score: 0.81\n",
            "kappa: 0.59\n",
            "ROC AUC: 0.80\n",
            "fpr: [0.         0.31149733 1.        ]\n",
            "tpr: [0.         0.90559441 1.        ]\n",
            "thresholds: [2 1 0]\n",
            "[[1030  466]\n",
            " [ 135 1295]]\n",
            "********************************************************************\n",
            "Metrics for MLP Model Fold 5:\n",
            "Inference Time: 0.0059 seconds\n",
            "training Time: 18.6766 seconds\n",
            "Accuracy: 0.80\n",
            "Precision: 0.76\n",
            "Recall: 0.87\n",
            "F1-score: 0.81\n",
            "kappa: 0.61\n",
            "ROC AUC: 0.81\n",
            "fpr: [0.         0.25970549 1.        ]\n",
            "tpr: [0.         0.87071978 1.        ]\n",
            "thresholds: [2 1 0]\n",
            "[[1106  388]\n",
            " [ 185 1246]]\n",
            "********************************************************************\n",
            "Metrics for MLP Model Fold 6:\n",
            "Inference Time: 0.0042 seconds\n",
            "training Time: 20.0172 seconds\n",
            "Accuracy: 0.82\n",
            "Precision: 0.78\n",
            "Recall: 0.92\n",
            "F1-score: 0.84\n",
            "kappa: 0.64\n",
            "ROC AUC: 0.82\n",
            "fpr: [0.         0.28267045 1.        ]\n",
            "tpr: [0.        0.9215557 1.       ]\n",
            "thresholds: [2 1 0]\n",
            "[[1010  398]\n",
            " [ 119 1398]]\n",
            "********************************************************************\n",
            "Metrics for MLP Model Fold 7:\n",
            "Inference Time: 0.0042 seconds\n",
            "training Time: 17.8298 seconds\n",
            "Accuracy: 0.81\n",
            "Precision: 0.76\n",
            "Recall: 0.91\n",
            "F1-score: 0.83\n",
            "kappa: 0.62\n",
            "ROC AUC: 0.81\n",
            "fpr: [0.         0.28983516 1.        ]\n",
            "tpr: [0.         0.90673928 1.        ]\n",
            "thresholds: [2 1 0]\n",
            "[[1034  422]\n",
            " [ 137 1332]]\n",
            "********************************************************************\n",
            "Metrics for MLP Model Fold 8:\n",
            "Inference Time: 0.0042 seconds\n",
            "training Time: 17.6497 seconds\n",
            "Accuracy: 0.80\n",
            "Precision: 0.73\n",
            "Recall: 0.94\n",
            "F1-score: 0.83\n",
            "kappa: 0.61\n",
            "ROC AUC: 0.80\n",
            "fpr: [0.         0.33739837 1.        ]\n",
            "tpr: [0.         0.94478951 1.        ]\n",
            "thresholds: [2 1 0]\n",
            "[[ 978  498]\n",
            " [  80 1369]]\n",
            "********************************************************************\n",
            "Metrics for MLP Model Fold 9:\n",
            "Inference Time: 0.0092 seconds\n",
            "training Time: 18.2430 seconds\n",
            "Accuracy: 0.82\n",
            "Precision: 0.76\n",
            "Recall: 0.94\n",
            "F1-score: 0.84\n",
            "kappa: 0.63\n",
            "ROC AUC: 0.82\n",
            "fpr: [0.         0.30378007 1.        ]\n",
            "tpr: [0.         0.93605442 1.        ]\n",
            "thresholds: [2 1 0]\n",
            "[[1013  442]\n",
            " [  94 1376]]\n",
            "********************************************************************\n",
            "Metrics for MLP Model Fold 10:\n",
            "Inference Time: 0.0043 seconds\n",
            "training Time: 20.0591 seconds\n",
            "Accuracy: 0.81\n",
            "Precision: 0.74\n",
            "Recall: 0.94\n",
            "F1-score: 0.83\n",
            "kappa: 0.63\n",
            "ROC AUC: 0.81\n",
            "fpr: [0.         0.31756757 1.        ]\n",
            "tpr: [0.         0.94463668 1.        ]\n",
            "thresholds: [2 1 0]\n",
            "[[1010  470]\n",
            " [  80 1365]]\n",
            "********************************************************************\n"
          ]
        }
      ],
      "source": [
        "resultsMLP = {}\n",
        "kf = KFold(n_splits=10, random_state = 42, shuffle=True)\n",
        "fld = 1\n",
        "i = 1\n",
        "X = np.concatenate([X_trainO, X_testO], axis=0)\n",
        "y = np.concatenate([y_trainO, y_testO], axis=0)\n",
        "X_df = pd.DataFrame(X)\n",
        "y_df = pd.DataFrame(y)\n",
        "for train_index, test_index in kf.split(X):\n",
        "\n",
        "        X_trainV, X_testV = X_df.iloc[train_index], X_df.iloc[test_index]\n",
        "        y_trainV, y_testV = y_df.iloc[train_index], y_df.iloc[test_index]\n",
        "\n",
        "        start_time = time.time()\n",
        "        MLP.fit(X_trainV, y_trainV)\n",
        "        Training_time = time.time() - start_time\n",
        "\n",
        "        start_time = time.time()\n",
        "        y_predMLP = MLP.predict(X_testV)\n",
        "        Inference_Time = time.time() - start_time\n",
        "\n",
        "        accuracy  = accuracy_score(y_testV, y_predMLP)\n",
        "        precision  = precision_score(y_testV, y_predMLP)\n",
        "        recall  = recall_score(y_testV, y_predMLP)\n",
        "        f1  = f1_score(y_testV, y_predMLP)\n",
        "        roc_auc = roc_auc_score(y_testV, y_predMLP)\n",
        "        fpr, tpr, thresholds = roc_curve(y_testV, y_predMLP)\n",
        "\n",
        "        kappa = cohen_kappa_score(y_testV, y_predMLP)\n",
        "        conf_mat = confusion_matrix(y_testV, y_predMLP)\n",
        "        resultsMLP[f'Model_{fld}'] = {'Matrix': conf_mat, 'accuracy': accuracy, 'precision': precision, 'recall': recall, 'f1': f1,'kappa':kappa, 'roc_auc': roc_auc,'fpr':fpr\n",
        "                                     ,'tpr':tpr,'thresholds':thresholds,'Inference_Time':Inference_Time,'Training_time':Training_time}\n",
        "\n",
        "        # Print metrics for the MLP model\n",
        "        print(f'Metrics for MLP Model Fold {fld}:')\n",
        "        print(f\"Inference Time: {Inference_Time:.4f} seconds\")\n",
        "        print(f\"training Time: {Training_time:.4f} seconds\")\n",
        "        print(f\"Accuracy: {accuracy:.2f}\")\n",
        "        print(f\"Precision: {precision:.2f}\")\n",
        "        print(f\"Recall: {recall:.2f}\")\n",
        "        print(f\"F1-score: {f1:.2f}\")\n",
        "        print(f\"kappa: {kappa:.2f}\")\n",
        "        print(f\"ROC AUC: {roc_auc:.2f}\")\n",
        "        print(f\"fpr: {fpr}\")\n",
        "        print(f\"tpr: {tpr}\")\n",
        "        print(f\"thresholds: {thresholds}\")\n",
        "        print(conf_mat)\n",
        "        print(\"********************************************************************\")\n",
        "        fld = fld + 1\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize lists to store metric values\n",
        "accuracies = []\n",
        "precisions = []\n",
        "recalls = []\n",
        "f1_scores = []\n",
        "kappas = []\n",
        "Inference_Time = []\n",
        "Training_time = []\n",
        "roc_auc = []\n",
        "# Loop over the results dictionary\n",
        "for model, metrics in resultsMLP.items():\n",
        "    accuracies.append(metrics['accuracy'])\n",
        "    precisions.append(metrics['precision'])\n",
        "    recalls.append(metrics['recall'])\n",
        "    f1_scores.append(metrics['f1'])\n",
        "    kappas.append(metrics['kappa'])\n",
        "    Inference_Time.append(metrics['Inference_Time'])\n",
        "    Training_time.append(metrics['Training_time'])\n",
        "    roc_auc.append(metrics['roc_auc'])\n",
        "\n",
        "# Calculate the best, worst, and average values for each metric\n",
        "best_accuracy = round(max(accuracies), 2)\n",
        "worst_accuracy = round(min(accuracies), 2)\n",
        "average_accuracy = round(sum(accuracies) / len(accuracies), 2)\n",
        "\n",
        "\n",
        "best_precision = round(max(precisions), 2)\n",
        "worst_precision = round(min(precisions), 2)\n",
        "average_precision = round(sum(precisions) / len(precisions), 3)\n",
        "\n",
        "best_recall = round(max(recalls), 2)\n",
        "worst_recall = round(min(recalls), 2)\n",
        "average_recall = round(sum(recalls) / len(recalls), 2)\n",
        "\n",
        "best_f1_score = round(max(f1_scores), 2)\n",
        "worst_f1_score = round(min(f1_scores), 2)\n",
        "average_f1_score = round(sum(f1_scores) / len(f1_scores), 2)\n",
        "\n",
        "best_kappa = round(max(kappas), 2)\n",
        "worst_kappa = round(min(kappas), 2)\n",
        "average_kappa = round(sum(kappas) / len(kappas), 2)\n",
        "\n",
        "best_Inference_Time = round(max(Inference_Time), 5)\n",
        "worst_Inference_Time = round(min(Inference_Time), 5)\n",
        "average_Inference_Time = round(sum(Inference_Time) / len(Inference_Time), 5)\n",
        "\n",
        "\n",
        "best_Training_time = round(max(Training_time), 5)\n",
        "worst_Training_time = round(min(Training_time), 5)\n",
        "average_Training_time = round(sum(Training_time) / len(Training_time), 5)\n",
        "\n",
        "best_roc_auc = round(max(roc_auc), 2)\n",
        "worst_roc_auc = round(min(roc_auc), 2)\n",
        "average_roc_auc = round(sum(roc_auc) / len(roc_auc), 2)\n",
        "\n",
        "# Print the results\n",
        "print(\"Best Accuracy:\", best_accuracy)\n",
        "print(\"Worst Accuracy:\", worst_accuracy)\n",
        "print(\"Average Accuracy:\", average_accuracy)\n",
        "\n",
        "print(\"************************************************\")\n",
        "\n",
        "\n",
        "print(\"Best Precision:\", best_precision)\n",
        "print(\"Worst Precision:\", worst_precision)\n",
        "print(\"Average Precision:\", average_precision)\n",
        "print(\"************************************************\")\n",
        "\n",
        "print(\"Best Recall:\", best_recall)\n",
        "print(\"Worst Recall:\", worst_recall)\n",
        "print(\"Average Recall:\", average_recall)\n",
        "print(\"************************************************\")\n",
        "\n",
        "print(\"Best F1 Score:\", best_f1_score)\n",
        "print(\"Worst F1 Score:\", worst_f1_score)\n",
        "print(\"Average F1 Score:\", average_f1_score)\n",
        "print(\"************************************************\")\n",
        "\n",
        "print(\"Best Kappa:\", best_kappa)\n",
        "print(\"Worst Kappa:\", worst_kappa)\n",
        "print(\"Average Kappa:\", average_kappa)\n",
        "\n",
        "print(\"************************************************\")\n",
        "\n",
        "print(\"Best Inference_Time:\", best_Inference_Time)\n",
        "print(\"Worst Inference_Time:\", worst_Inference_Time)\n",
        "print(\"Average Inference_Time:\", average_Inference_Time)\n",
        "print(\"************************************************\")\n",
        "\n",
        "print(\"Best Training_time:\", best_Training_time)\n",
        "print(\"Worst Training_time:\", worst_Training_time)\n",
        "print(\"Average Training_time:\", average_Training_time)\n",
        "print(\"************************************************\")\n",
        "\n",
        "print(\"Best roc_auc:\", best_roc_auc)\n",
        "print(\"Worst roc_auc:\", worst_roc_auc)\n",
        "print(\"Average roc_auc:\", average_roc_auc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EZ2E2f1eFYhM",
        "outputId": "d145face-bdd2-4a34-e356-be18b35d5177"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Accuracy: 0.82\n",
            "Worst Accuracy: 0.79\n",
            "Average Accuracy: 0.81\n",
            "************************************************\n",
            "Best Precision: 0.78\n",
            "Worst Precision: 0.73\n",
            "Average Precision: 0.751\n",
            "************************************************\n",
            "Best Recall: 0.95\n",
            "Worst Recall: 0.87\n",
            "Average Recall: 0.92\n",
            "************************************************\n",
            "Best F1 Score: 0.84\n",
            "Worst F1 Score: 0.81\n",
            "Average F1 Score: 0.83\n",
            "************************************************\n",
            "Best Kappa: 0.64\n",
            "Worst Kappa: 0.59\n",
            "Average Kappa: 0.62\n",
            "************************************************\n",
            "Best Inference_Time: 0.00924\n",
            "Worst Inference_Time: 0.00416\n",
            "Average Inference_Time: 0.00494\n",
            "************************************************\n",
            "Best Training_time: 33.57721\n",
            "Worst Training_time: 17.6497\n",
            "Average Training_time: 20.62768\n",
            "************************************************\n",
            "Best roc_auc: 0.82\n",
            "Worst roc_auc: 0.8\n",
            "Average roc_auc: 0.81\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **7-NaiveBayes**"
      ],
      "metadata": {
        "id": "CO3St7wZTctK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resultsNaiveBayes = {}\n",
        "additional_metrics = {}\n",
        "kf = KFold(n_splits=10, random_state = 42, shuffle=True)\n",
        "fld = 1\n",
        "i = 1\n",
        "X = np.concatenate([X_trainO, X_testO], axis=0)\n",
        "y = np.concatenate([y_trainO, y_testO], axis=0)\n",
        "X_df = pd.DataFrame(X)\n",
        "y_df = pd.DataFrame(y)\n",
        "NaiveBayes = GaussianNB()\n",
        "for train_index, test_index in kf.split(X):\n",
        "\n",
        "        X_trainV, X_testV = X_df.iloc[train_index], X_df.iloc[test_index]\n",
        "        y_trainV, y_testV = y_df.iloc[train_index], y_df.iloc[test_index]\n",
        "\n",
        "        start_time = time.time()\n",
        "        NaiveBayes.fit(X_trainV, y_trainV)\n",
        "        Training_time = time.time() - start_time\n",
        "\n",
        "        start_time = time.time()\n",
        "        y_predNaiveBayes = NaiveBayes.predict(X_testV)\n",
        "        Inference_Time = time.time() - start_time\n",
        "\n",
        "        accuracy = accuracy_score(y_testV, y_predNaiveBayes)\n",
        "        precision = precision_score(y_testV, y_predNaiveBayes)\n",
        "        recall = recall_score(y_testV, y_predNaiveBayes)\n",
        "        f1 = f1_score(y_testV, y_predNaiveBayes)\n",
        "\n",
        "        kappa = cohen_kappa_score(y_testV, y_predNaiveBayes)\n",
        "        roc_auc = roc_auc_score(y_testV, y_predNaiveBayes)\n",
        "        fpr, tpr, thresholds = roc_curve(y_testV, y_predNaiveBayes)\n",
        "\n",
        "        confusion_matrix_ensemble = confusion_matrix(y_testV, y_predNaiveBayes)\n",
        "\n",
        "\n",
        "        resultsNaiveBayes[f'Model_{fld}'] = {'Matrix': confusion_matrix_ensemble, 'accuracy': accuracy, 'precision': precision, 'recall': recall, 'f1': f1,'kappa':kappa,'roc_auc':roc_auc\n",
        "                                             ,'tpr':tpr,'thresholds':thresholds,'Inference_Time':Inference_Time,'Training_time':Training_time}\n",
        "\n",
        "\n",
        "\n",
        "        # Print metrics for the NaiveBayes model\n",
        "        print(f'Metrics for NaiveBayes Model Fold {fld}:')\n",
        "        print(f\"Inference Time: {Inference_Time:.4f} seconds\")\n",
        "        print(f\"training Time: {Training_time:.4f} seconds\")\n",
        "        print(f\"Accuracy: {accuracy:.2f}\")\n",
        "        print(f\"Precision: {precision:.2f}\")\n",
        "        print(f\"Recall: {recall:.2f}\")\n",
        "        print(f\"F1-score: {f1:.2f}\")\n",
        "        print(f\"kappa: {kappa:.2f}\")\n",
        "        print(f\"ROC AUC: {roc_auc:.2f}\")\n",
        "        print(f\"fpr: {fpr}\")\n",
        "        print(f\"tpr: {tpr}\")\n",
        "        print(f\"thresholds: {thresholds}\")\n",
        "        print(conf_mat)\n",
        "        print(\"********************************************************************\")\n",
        "        fld = fld + 1\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-y6VC0xATgVg",
        "outputId": "3348a2a2-c2e2-45ba-c76b-ffd636f16b9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Metrics for NaiveBayes Model Fold 1:\n",
            "Inference Time: 0.0086 seconds\n",
            "training Time: 0.0214 seconds\n",
            "Accuracy: 0.57\n",
            "Precision: 0.54\n",
            "Recall: 0.99\n",
            "F1-score: 0.70\n",
            "kappa: 0.13\n",
            "ROC AUC: 0.57\n",
            "fpr: [0.         0.85507246 1.        ]\n",
            "tpr: [0.         0.98849018 1.        ]\n",
            "thresholds: [2 1 0]\n",
            "[[1010  470]\n",
            " [  80 1365]]\n",
            "********************************************************************\n",
            "Metrics for NaiveBayes Model Fold 2:\n",
            "Inference Time: 0.0034 seconds\n",
            "training Time: 0.0219 seconds\n",
            "Accuracy: 0.57\n",
            "Precision: 0.53\n",
            "Recall: 0.99\n",
            "F1-score: 0.69\n",
            "kappa: 0.14\n",
            "ROC AUC: 0.57\n",
            "fpr: [0.         0.84891599 1.        ]\n",
            "tpr: [0.         0.98758621 1.        ]\n",
            "thresholds: [2 1 0]\n",
            "[[1010  470]\n",
            " [  80 1365]]\n",
            "********************************************************************\n",
            "Metrics for NaiveBayes Model Fold 3:\n",
            "Inference Time: 0.0033 seconds\n",
            "training Time: 0.0189 seconds\n",
            "Accuracy: 0.58\n",
            "Precision: 0.55\n",
            "Recall: 0.99\n",
            "F1-score: 0.71\n",
            "kappa: 0.15\n",
            "ROC AUC: 0.57\n",
            "fpr: [0.         0.84272791 1.        ]\n",
            "tpr: [0.         0.98925453 1.        ]\n",
            "thresholds: [2 1 0]\n",
            "[[1010  470]\n",
            " [  80 1365]]\n",
            "********************************************************************\n",
            "Metrics for NaiveBayes Model Fold 4:\n",
            "Inference Time: 0.0033 seconds\n",
            "training Time: 0.0236 seconds\n",
            "Accuracy: 0.55\n",
            "Precision: 0.52\n",
            "Recall: 0.99\n",
            "F1-score: 0.68\n",
            "kappa: 0.12\n",
            "ROC AUC: 0.56\n",
            "fpr: [0.         0.86163102 1.        ]\n",
            "tpr: [0.         0.98811189 1.        ]\n",
            "thresholds: [2 1 0]\n",
            "[[1010  470]\n",
            " [  80 1365]]\n",
            "********************************************************************\n",
            "Metrics for NaiveBayes Model Fold 5:\n",
            "Inference Time: 0.0033 seconds\n",
            "training Time: 0.0220 seconds\n",
            "Accuracy: 0.57\n",
            "Precision: 0.53\n",
            "Recall: 0.99\n",
            "F1-score: 0.69\n",
            "kappa: 0.15\n",
            "ROC AUC: 0.57\n",
            "fpr: [0.        0.8373494 1.       ]\n",
            "tpr: [0.         0.98602376 1.        ]\n",
            "thresholds: [2 1 0]\n",
            "[[1010  470]\n",
            " [  80 1365]]\n",
            "********************************************************************\n",
            "Metrics for NaiveBayes Model Fold 6:\n",
            "Inference Time: 0.0035 seconds\n",
            "training Time: 0.0263 seconds\n",
            "Accuracy: 0.59\n",
            "Precision: 0.56\n",
            "Recall: 0.99\n",
            "F1-score: 0.72\n",
            "kappa: 0.16\n",
            "ROC AUC: 0.58\n",
            "fpr: [0.         0.83025568 1.        ]\n",
            "tpr: [0.         0.98879367 1.        ]\n",
            "thresholds: [2 1 0]\n",
            "[[1010  470]\n",
            " [  80 1365]]\n",
            "********************************************************************\n",
            "Metrics for NaiveBayes Model Fold 7:\n",
            "Inference Time: 0.0035 seconds\n",
            "training Time: 0.0417 seconds\n",
            "Accuracy: 0.57\n",
            "Precision: 0.54\n",
            "Recall: 0.99\n",
            "F1-score: 0.70\n",
            "kappa: 0.14\n",
            "ROC AUC: 0.57\n",
            "fpr: [0.         0.84684066 1.        ]\n",
            "tpr: [0.         0.98978897 1.        ]\n",
            "thresholds: [2 1 0]\n",
            "[[1010  470]\n",
            " [  80 1365]]\n",
            "********************************************************************\n",
            "Metrics for NaiveBayes Model Fold 8:\n",
            "Inference Time: 0.0035 seconds\n",
            "training Time: 0.0194 seconds\n",
            "Accuracy: 0.56\n",
            "Precision: 0.53\n",
            "Recall: 0.98\n",
            "F1-score: 0.69\n",
            "kappa: 0.12\n",
            "ROC AUC: 0.56\n",
            "fpr: [0.        0.8604336 1.       ]\n",
            "tpr: [0.         0.98481712 1.        ]\n",
            "thresholds: [2 1 0]\n",
            "[[1010  470]\n",
            " [  80 1365]]\n",
            "********************************************************************\n",
            "Metrics for NaiveBayes Model Fold 9:\n",
            "Inference Time: 0.0030 seconds\n",
            "training Time: 0.0274 seconds\n",
            "Accuracy: 0.57\n",
            "Precision: 0.54\n",
            "Recall: 0.99\n",
            "F1-score: 0.70\n",
            "kappa: 0.13\n",
            "ROC AUC: 0.57\n",
            "fpr: [0.        0.8604811 1.       ]\n",
            "tpr: [0.         0.99251701 1.        ]\n",
            "thresholds: [2 1 0]\n",
            "[[1010  470]\n",
            " [  80 1365]]\n",
            "********************************************************************\n",
            "Metrics for NaiveBayes Model Fold 10:\n",
            "Inference Time: 0.0035 seconds\n",
            "training Time: 0.0185 seconds\n",
            "Accuracy: 0.57\n",
            "Precision: 0.54\n",
            "Recall: 0.99\n",
            "F1-score: 0.69\n",
            "kappa: 0.15\n",
            "ROC AUC: 0.57\n",
            "fpr: [0.         0.83851351 1.        ]\n",
            "tpr: [0.         0.98823529 1.        ]\n",
            "thresholds: [2 1 0]\n",
            "[[1010  470]\n",
            " [  80 1365]]\n",
            "********************************************************************\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize lists to store metric values\n",
        "accuracies = []\n",
        "precisions = []\n",
        "recalls = []\n",
        "f1_scores = []\n",
        "kappas = []\n",
        "Inference_Time = []\n",
        "Training_time = []\n",
        "roc_auc = []\n",
        "# Loop over the results dictionary\n",
        "for model, metrics in resultsNaiveBayes.items():\n",
        "    accuracies.append(metrics['accuracy'])\n",
        "    precisions.append(metrics['precision'])\n",
        "    recalls.append(metrics['recall'])\n",
        "    f1_scores.append(metrics['f1'])\n",
        "    kappas.append(metrics['kappa'])\n",
        "    Inference_Time.append(metrics['Inference_Time'])\n",
        "    Training_time.append(metrics['Training_time'])\n",
        "    roc_auc.append(metrics['roc_auc'])\n",
        "\n",
        "# Calculate the best, worst, and average values for each metric\n",
        "best_accuracy = round(max(accuracies), 2)\n",
        "worst_accuracy = round(min(accuracies), 2)\n",
        "average_accuracy = round(sum(accuracies) / len(accuracies), 2)\n",
        "\n",
        "\n",
        "best_precision = round(max(precisions), 2)\n",
        "worst_precision = round(min(precisions), 2)\n",
        "average_precision = round(sum(precisions) / len(precisions), 3)\n",
        "\n",
        "best_recall = round(max(recalls), 2)\n",
        "worst_recall = round(min(recalls), 2)\n",
        "average_recall = round(sum(recalls) / len(recalls), 2)\n",
        "\n",
        "best_f1_score = round(max(f1_scores), 2)\n",
        "worst_f1_score = round(min(f1_scores), 2)\n",
        "average_f1_score = round(sum(f1_scores) / len(f1_scores), 2)\n",
        "\n",
        "best_kappa = round(max(kappas), 2)\n",
        "worst_kappa = round(min(kappas), 2)\n",
        "average_kappa = round(sum(kappas) / len(kappas), 2)\n",
        "\n",
        "best_Inference_Time = round(max(Inference_Time), 5)\n",
        "worst_Inference_Time = round(min(Inference_Time), 5)\n",
        "average_Inference_Time = round(sum(Inference_Time) / len(Inference_Time), 5)\n",
        "\n",
        "\n",
        "best_Training_time = round(max(Training_time), 5)\n",
        "worst_Training_time = round(min(Training_time), 5)\n",
        "average_Training_time = round(sum(Training_time) / len(Training_time), 5)\n",
        "\n",
        "best_roc_auc = round(max(roc_auc), 2)\n",
        "worst_roc_auc = round(min(roc_auc), 2)\n",
        "average_roc_auc = round(sum(roc_auc) / len(roc_auc), 2)\n",
        "\n",
        "# Print the results\n",
        "print(\"Best Accuracy:\", best_accuracy)\n",
        "print(\"Worst Accuracy:\", worst_accuracy)\n",
        "print(\"Average Accuracy:\", average_accuracy)\n",
        "\n",
        "print(\"************************************************\")\n",
        "\n",
        "\n",
        "print(\"Best Precision:\", best_precision)\n",
        "print(\"Worst Precision:\", worst_precision)\n",
        "print(\"Average Precision:\", average_precision)\n",
        "print(\"************************************************\")\n",
        "\n",
        "print(\"Best Recall:\", best_recall)\n",
        "print(\"Worst Recall:\", worst_recall)\n",
        "print(\"Average Recall:\", average_recall)\n",
        "print(\"************************************************\")\n",
        "\n",
        "print(\"Best F1 Score:\", best_f1_score)\n",
        "print(\"Worst F1 Score:\", worst_f1_score)\n",
        "print(\"Average F1 Score:\", average_f1_score)\n",
        "print(\"************************************************\")\n",
        "\n",
        "print(\"Best Kappa:\", best_kappa)\n",
        "print(\"Worst Kappa:\", worst_kappa)\n",
        "print(\"Average Kappa:\", average_kappa)\n",
        "\n",
        "print(\"************************************************\")\n",
        "\n",
        "print(\"Best Inference_Time:\", best_Inference_Time)\n",
        "print(\"Worst Inference_Time:\", worst_Inference_Time)\n",
        "print(\"Average Inference_Time:\", average_Inference_Time)\n",
        "print(\"************************************************\")\n",
        "\n",
        "print(\"Best Training_time:\", best_Training_time)\n",
        "print(\"Worst Training_time:\", worst_Training_time)\n",
        "print(\"Average Training_time:\", average_Training_time)\n",
        "print(\"************************************************\")\n",
        "\n",
        "print(\"Best roc_auc:\", best_roc_auc)\n",
        "print(\"Worst roc_auc:\", worst_roc_auc)\n",
        "print(\"Average roc_auc:\", average_roc_auc)\n"
      ],
      "metadata": {
        "id": "YfWfA28NFZ5M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e414206c-0bda-421a-dec4-c282a7c753ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Accuracy: 0.59\n",
            "Worst Accuracy: 0.55\n",
            "Average Accuracy: 0.57\n",
            "************************************************\n",
            "Best Precision: 0.56\n",
            "Worst Precision: 0.52\n",
            "Average Precision: 0.538\n",
            "************************************************\n",
            "Best Recall: 0.99\n",
            "Worst Recall: 0.98\n",
            "Average Recall: 0.99\n",
            "************************************************\n",
            "Best F1 Score: 0.72\n",
            "Worst F1 Score: 0.68\n",
            "Average F1 Score: 0.7\n",
            "************************************************\n",
            "Best Kappa: 0.16\n",
            "Worst Kappa: 0.12\n",
            "Average Kappa: 0.14\n",
            "************************************************\n",
            "Best Inference_Time: 0.00856\n",
            "Worst Inference_Time: 0.00305\n",
            "Average Inference_Time: 0.00389\n",
            "************************************************\n",
            "Best Training_time: 0.04168\n",
            "Worst Training_time: 0.01851\n",
            "Average Training_time: 0.02412\n",
            "************************************************\n",
            "Best roc_auc: 0.58\n",
            "Worst roc_auc: 0.56\n",
            "Average roc_auc: 0.57\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **8-KNN**"
      ],
      "metadata": {
        "id": "2iafVolEVEH_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "KNN = KNeighborsClassifier()"
      ],
      "metadata": {
        "id": "do0azXZRVGif"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resultsKNN = {}\n",
        "additional_metrics = {}\n",
        "kf = KFold(n_splits=10, random_state = 42, shuffle=True)\n",
        "fld = 1\n",
        "i = 1\n",
        "X = np.concatenate([X_trainO, X_testO], axis=0)\n",
        "y = np.concatenate([y_trainO, y_testO], axis=0)\n",
        "X_df = pd.DataFrame(X)\n",
        "y_df = pd.DataFrame(y)\n",
        "\n",
        "for train_index, test_index in kf.split(X):\n",
        "\n",
        "        X_trainV, X_testV = X_df.iloc[train_index], X_df.iloc[test_index]\n",
        "        y_trainV, y_testV = y_df.iloc[train_index], y_df.iloc[test_index]\n",
        "\n",
        "        start_time = time.time()\n",
        "        KNN.fit(X_trainV, y_trainV)\n",
        "        Training_time = time.time() - start_time\n",
        "\n",
        "        start_time = time.time()\n",
        "        y_predKNN= KNN.predict(X_testV)\n",
        "        Inference_Time = time.time() - start_time\n",
        "\n",
        "        accuracy_KNN = accuracy_score(y_testV, y_predKNN)\n",
        "        precision_KNN = precision_score(y_testV, y_predKNN)\n",
        "        recall_KNN = recall_score(y_testV, y_predKNN)\n",
        "        f1_KNN = f1_score(y_testV, y_predKNN)\n",
        "\n",
        "        kappa = cohen_kappa_score(y_testV, y_predKNN)\n",
        "        confusion_matrix_KNN = confusion_matrix(y_testV, y_predKNN)\n",
        "        roc_auc = roc_auc_score(y_testV, y_predKNN)\n",
        "        fpr, tpr, thresholds = roc_curve(y_testV, y_predKNN)\n",
        "\n",
        "        resultsKNN[f'Model_{fld}'] = {'Matrix': confusion_matrix_KNN, 'accuracy': accuracy_KNN, 'precision': precision_KNN, 'recall': recall_KNN, 'f1': f1_KNN,'kappa':kappa,'roc_auc':roc_auc\n",
        "                                      ,'tpr':tpr,'thresholds':thresholds,'Inference_Time':Inference_Time,'Training_time':Training_time}\n",
        "\n",
        "        # Print metrics for the KNN model\n",
        "        print(f'Metrics for KNN Model Fold {fld}:')\n",
        "        print(f\"Inference Time: {Inference_Time:.4f} seconds\")\n",
        "        print(f\"training Time: {Training_time:.4f} seconds\")\n",
        "        print(f\"Accuracy: {accuracy_KNN:.2f}\")\n",
        "        print(f\"Precision: {precision_KNN:.2f}\")\n",
        "        print(f\"Recall: {recall_KNN:.2f}\")\n",
        "        print(f\"F1-score: {f1_KNN:.2f}\")\n",
        "        print(f\"kappa: {kappa:.2f}\")\n",
        "        print(f\"ROC AUC: {roc_auc:.2f}\")\n",
        "        print(f\"fpr: {fpr}\")\n",
        "        print(f\"tpr: {tpr}\")\n",
        "        print(f\"thresholds: {thresholds}\")\n",
        "        print(confusion_matrix_KNN)\n",
        "        print(\"********************************************************************\")\n",
        "        fld = fld + 1\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3pR1X9a-VHyX",
        "outputId": "82047cc7-8485-415a-e9e8-253046ce7d88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Metrics for KNN Model Fold 1:\n",
            "Inference Time: 1.4859 seconds\n",
            "training Time: 0.0078 seconds\n",
            "Accuracy: 0.90\n",
            "Precision: 0.88\n",
            "Recall: 0.92\n",
            "F1-score: 0.90\n",
            "kappa: 0.80\n",
            "ROC AUC: 0.90\n",
            "fpr: [0.         0.12491373 1.        ]\n",
            "tpr: [0.         0.92010833 1.        ]\n",
            "thresholds: [2 1 0]\n",
            "[[1268  181]\n",
            " [ 118 1359]]\n",
            "********************************************************************\n",
            "Metrics for KNN Model Fold 2:\n",
            "Inference Time: 1.8474 seconds\n",
            "training Time: 0.0161 seconds\n",
            "Accuracy: 0.89\n",
            "Precision: 0.88\n",
            "Recall: 0.90\n",
            "F1-score: 0.89\n",
            "kappa: 0.78\n",
            "ROC AUC: 0.89\n",
            "fpr: [0.         0.12466125 1.        ]\n",
            "tpr: [0.         0.90482759 1.        ]\n",
            "thresholds: [2 1 0]\n",
            "[[1292  184]\n",
            " [ 138 1312]]\n",
            "********************************************************************\n",
            "Metrics for KNN Model Fold 3:\n",
            "Inference Time: 1.9724 seconds\n",
            "training Time: 0.0191 seconds\n",
            "Accuracy: 0.90\n",
            "Precision: 0.89\n",
            "Recall: 0.91\n",
            "F1-score: 0.90\n",
            "kappa: 0.80\n",
            "ROC AUC: 0.90\n",
            "fpr: [0.         0.11969381 1.        ]\n",
            "tpr: [0.         0.91470786 1.        ]\n",
            "thresholds: [2 1 0]\n",
            "[[1265  172]\n",
            " [ 127 1362]]\n",
            "********************************************************************\n",
            "Metrics for KNN Model Fold 4:\n",
            "Inference Time: 1.4174 seconds\n",
            "training Time: 0.0154 seconds\n",
            "Accuracy: 0.90\n",
            "Precision: 0.88\n",
            "Recall: 0.92\n",
            "F1-score: 0.90\n",
            "kappa: 0.80\n",
            "ROC AUC: 0.90\n",
            "fpr: [0.         0.11430481 1.        ]\n",
            "tpr: [0.         0.91958042 1.        ]\n",
            "thresholds: [2 1 0]\n",
            "[[1325  171]\n",
            " [ 115 1315]]\n",
            "********************************************************************\n",
            "Metrics for KNN Model Fold 5:\n",
            "Inference Time: 1.1957 seconds\n",
            "training Time: 0.0078 seconds\n",
            "Accuracy: 0.90\n",
            "Precision: 0.89\n",
            "Recall: 0.91\n",
            "F1-score: 0.90\n",
            "kappa: 0.80\n",
            "ROC AUC: 0.90\n",
            "fpr: [0.         0.11178046 1.        ]\n",
            "tpr: [0.         0.90915444 1.        ]\n",
            "thresholds: [2 1 0]\n",
            "[[1327  167]\n",
            " [ 130 1301]]\n",
            "********************************************************************\n",
            "Metrics for KNN Model Fold 6:\n",
            "Inference Time: 1.1973 seconds\n",
            "training Time: 0.0100 seconds\n",
            "Accuracy: 0.91\n",
            "Precision: 0.90\n",
            "Recall: 0.93\n",
            "F1-score: 0.91\n",
            "kappa: 0.81\n",
            "ROC AUC: 0.91\n",
            "fpr: [0.         0.11505682 1.        ]\n",
            "tpr: [0.         0.92748846 1.        ]\n",
            "thresholds: [2 1 0]\n",
            "[[1246  162]\n",
            " [ 110 1407]]\n",
            "********************************************************************\n",
            "Metrics for KNN Model Fold 7:\n",
            "Inference Time: 1.2558 seconds\n",
            "training Time: 0.0075 seconds\n",
            "Accuracy: 0.90\n",
            "Precision: 0.88\n",
            "Recall: 0.92\n",
            "F1-score: 0.90\n",
            "kappa: 0.79\n",
            "ROC AUC: 0.89\n",
            "fpr: [0.         0.12774725 1.        ]\n",
            "tpr: [0.         0.91763104 1.        ]\n",
            "thresholds: [2 1 0]\n",
            "[[1270  186]\n",
            " [ 121 1348]]\n",
            "********************************************************************\n",
            "Metrics for KNN Model Fold 8:\n",
            "Inference Time: 1.0494 seconds\n",
            "training Time: 0.0145 seconds\n",
            "Accuracy: 0.90\n",
            "Precision: 0.89\n",
            "Recall: 0.92\n",
            "F1-score: 0.90\n",
            "kappa: 0.80\n",
            "ROC AUC: 0.90\n",
            "fpr: [0.        0.1104336 1.       ]\n",
            "tpr: [0.         0.91511387 1.        ]\n",
            "thresholds: [2 1 0]\n",
            "[[1313  163]\n",
            " [ 123 1326]]\n",
            "********************************************************************\n",
            "Metrics for KNN Model Fold 9:\n",
            "Inference Time: 1.5390 seconds\n",
            "training Time: 0.0152 seconds\n",
            "Accuracy: 0.90\n",
            "Precision: 0.88\n",
            "Recall: 0.92\n",
            "F1-score: 0.90\n",
            "kappa: 0.80\n",
            "ROC AUC: 0.90\n",
            "fpr: [0.        0.1209622 1.       ]\n",
            "tpr: [0.         0.92108844 1.        ]\n",
            "thresholds: [2 1 0]\n",
            "[[1279  176]\n",
            " [ 116 1354]]\n",
            "********************************************************************\n",
            "Metrics for KNN Model Fold 10:\n",
            "Inference Time: 0.7572 seconds\n",
            "training Time: 0.0068 seconds\n",
            "Accuracy: 0.89\n",
            "Precision: 0.87\n",
            "Recall: 0.91\n",
            "F1-score: 0.89\n",
            "kappa: 0.79\n",
            "ROC AUC: 0.89\n",
            "fpr: [0.         0.12837838 1.        ]\n",
            "tpr: [0.         0.91487889 1.        ]\n",
            "thresholds: [2 1 0]\n",
            "[[1290  190]\n",
            " [ 123 1322]]\n",
            "********************************************************************\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize lists to store metric values\n",
        "accuracies = []\n",
        "precisions = []\n",
        "recalls = []\n",
        "f1_scores = []\n",
        "kappas = []\n",
        "Inference_Time = []\n",
        "Training_time = []\n",
        "roc_auc = []\n",
        "# Loop over the results dictionary\n",
        "for model, metrics in resultsKNN.items():\n",
        "    accuracies.append(metrics['accuracy'])\n",
        "    precisions.append(metrics['precision'])\n",
        "    recalls.append(metrics['recall'])\n",
        "    f1_scores.append(metrics['f1'])\n",
        "    kappas.append(metrics['kappa'])\n",
        "    Inference_Time.append(metrics['Inference_Time'])\n",
        "    Training_time.append(metrics['Training_time'])\n",
        "    roc_auc.append(metrics['roc_auc'])\n",
        "\n",
        "# Calculate the best, worst, and average values for each metric\n",
        "best_accuracy = round(max(accuracies), 2)\n",
        "worst_accuracy = round(min(accuracies), 2)\n",
        "average_accuracy = round(sum(accuracies) / len(accuracies), 2)\n",
        "\n",
        "\n",
        "best_precision = round(max(precisions), 2)\n",
        "worst_precision = round(min(precisions), 2)\n",
        "average_precision = round(sum(precisions) / len(precisions), 3)\n",
        "\n",
        "best_recall = round(max(recalls), 2)\n",
        "worst_recall = round(min(recalls), 2)\n",
        "average_recall = round(sum(recalls) / len(recalls), 2)\n",
        "\n",
        "best_f1_score = round(max(f1_scores), 2)\n",
        "worst_f1_score = round(min(f1_scores), 2)\n",
        "average_f1_score = round(sum(f1_scores) / len(f1_scores), 2)\n",
        "\n",
        "best_kappa = round(max(kappas), 2)\n",
        "worst_kappa = round(min(kappas), 2)\n",
        "average_kappa = round(sum(kappas) / len(kappas), 2)\n",
        "\n",
        "best_Inference_Time = round(max(Inference_Time), 5)\n",
        "worst_Inference_Time = round(min(Inference_Time), 5)\n",
        "average_Inference_Time = round(sum(Inference_Time) / len(Inference_Time), 5)\n",
        "\n",
        "\n",
        "best_Training_time = round(max(Training_time), 5)\n",
        "worst_Training_time = round(min(Training_time), 5)\n",
        "average_Training_time = round(sum(Training_time) / len(Training_time), 5)\n",
        "\n",
        "best_roc_auc = round(max(roc_auc), 2)\n",
        "worst_roc_auc = round(min(roc_auc), 2)\n",
        "average_roc_auc = round(sum(roc_auc) / len(roc_auc), 2)\n",
        "\n",
        "# Print the results\n",
        "print(\"Best Accuracy:\", best_accuracy)\n",
        "print(\"Worst Accuracy:\", worst_accuracy)\n",
        "print(\"Average Accuracy:\", average_accuracy)\n",
        "\n",
        "print(\"************************************************\")\n",
        "\n",
        "\n",
        "print(\"Best Precision:\", best_precision)\n",
        "print(\"Worst Precision:\", worst_precision)\n",
        "print(\"Average Precision:\", average_precision)\n",
        "print(\"************************************************\")\n",
        "\n",
        "print(\"Best Recall:\", best_recall)\n",
        "print(\"Worst Recall:\", worst_recall)\n",
        "print(\"Average Recall:\", average_recall)\n",
        "print(\"************************************************\")\n",
        "\n",
        "print(\"Best F1 Score:\", best_f1_score)\n",
        "print(\"Worst F1 Score:\", worst_f1_score)\n",
        "print(\"Average F1 Score:\", average_f1_score)\n",
        "print(\"************************************************\")\n",
        "\n",
        "print(\"Best Kappa:\", best_kappa)\n",
        "print(\"Worst Kappa:\", worst_kappa)\n",
        "print(\"Average Kappa:\", average_kappa)\n",
        "\n",
        "print(\"************************************************\")\n",
        "\n",
        "print(\"Best Inference_Time:\", best_Inference_Time)\n",
        "print(\"Worst Inference_Time:\", worst_Inference_Time)\n",
        "print(\"Average Inference_Time:\", average_Inference_Time)\n",
        "print(\"************************************************\")\n",
        "\n",
        "print(\"Best Training_time:\", best_Training_time)\n",
        "print(\"Worst Training_time:\", worst_Training_time)\n",
        "print(\"Average Training_time:\", average_Training_time)\n",
        "print(\"************************************************\")\n",
        "\n",
        "print(\"Best roc_auc:\", best_roc_auc)\n",
        "print(\"Worst roc_auc:\", worst_roc_auc)\n",
        "print(\"Average roc_auc:\", average_roc_auc)\n"
      ],
      "metadata": {
        "id": "nbWUSyVYFa9z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d928d32-127d-4d68-95be-174d75efc8a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Accuracy: 0.91\n",
            "Worst Accuracy: 0.89\n",
            "Average Accuracy: 0.9\n",
            "************************************************\n",
            "Best Precision: 0.9\n",
            "Worst Precision: 0.87\n",
            "Average Precision: 0.884\n",
            "************************************************\n",
            "Best Recall: 0.93\n",
            "Worst Recall: 0.9\n",
            "Average Recall: 0.92\n",
            "************************************************\n",
            "Best F1 Score: 0.91\n",
            "Worst F1 Score: 0.89\n",
            "Average F1 Score: 0.9\n",
            "************************************************\n",
            "Best Kappa: 0.81\n",
            "Worst Kappa: 0.78\n",
            "Average Kappa: 0.8\n",
            "************************************************\n",
            "Best Inference_Time: 1.97239\n",
            "Worst Inference_Time: 0.75719\n",
            "Average Inference_Time: 1.37174\n",
            "************************************************\n",
            "Best Training_time: 0.01913\n",
            "Worst Training_time: 0.00677\n",
            "Average Training_time: 0.01202\n",
            "************************************************\n",
            "Best roc_auc: 0.91\n",
            "Worst roc_auc: 0.89\n",
            "Average roc_auc: 0.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **9-ExtraTrees**"
      ],
      "metadata": {
        "id": "5iE19hDDVhO5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "ExtraTrees = ExtraTreesClassifier()\n",
        "from sklearn.metrics import roc_auc_score,roc_curve\n"
      ],
      "metadata": {
        "id": "aFrRo8rKVi4e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resultsExtraTrees = {}\n",
        "additional_metrics = {}\n",
        "kf = KFold(n_splits=10, random_state = 42, shuffle=True)\n",
        "fld = 1\n",
        "i = 1\n",
        "X = np.concatenate([X_trainO, X_testO], axis=0)\n",
        "y = np.concatenate([y_trainO, y_testO], axis=0)\n",
        "X_df = pd.DataFrame(X)\n",
        "y_df = pd.DataFrame(y)\n",
        "\n",
        "for train_index, test_index in kf.split(X):\n",
        "\n",
        "        X_trainV, X_testV = X_df.iloc[train_index], X_df.iloc[test_index]\n",
        "        y_trainV, y_testV = y_df.iloc[train_index], y_df.iloc[test_index]\n",
        "\n",
        "        start_time = time.time()\n",
        "        ExtraTrees.fit(X_trainV, y_trainV)\n",
        "        Training_time = time.time() - start_time\n",
        "\n",
        "        start_time = time.time()\n",
        "        y_predExtraTrees= ExtraTrees.predict(X_testV)\n",
        "        Inference_Time = time.time() - start_time\n",
        "\n",
        "\n",
        "        accuracy_ExtraTrees = accuracy_score(y_testV, y_predExtraTrees)\n",
        "        precision_ExtraTrees = precision_score(y_testV, y_predExtraTrees)\n",
        "        recall_ExtraTrees = recall_score(y_testV, y_predExtraTrees)\n",
        "        f1_ExtraTrees = f1_score(y_testV, y_predExtraTrees)\n",
        "\n",
        "        kappa = cohen_kappa_score(y_testV, y_predExtraTrees)\n",
        "        confusion_matrix_ExtraTrees = confusion_matrix(y_testV, y_predExtraTrees)\n",
        "        roc_auc = roc_auc_score(y_testV, y_predExtraTrees)\n",
        "        fpr, tpr, thresholds = roc_curve(y_testV, y_predExtraTrees)\n",
        "        resultsExtraTrees[f'Model_{fld}'] = {'Matrix': confusion_matrix_ExtraTrees, 'accuracy': accuracy_ExtraTrees, 'precision': precision_ExtraTrees, 'recall': recall_ExtraTrees, 'f1': f1_ExtraTrees,'kappa':kappa,'roc_auc':roc_auc\n",
        "                                             ,'tpr':tpr,'thresholds':thresholds,'Inference_Time':Inference_Time,'Training_time':Training_time}\n",
        "\n",
        "       # Print metrics for the ExtraTrees model\n",
        "        print(f'Metrics for ExtraTrees Model Fold {fld}:')\n",
        "        print(f\"Inference Time: {Inference_Time:.4f} seconds\")\n",
        "        print(f\"training Time: {Training_time:.4f} seconds\")\n",
        "        print(f\"Accuracy: {accuracy_ExtraTrees:.2f}\")\n",
        "        print(f\"Precision: {precision_ExtraTrees:.2f}\")\n",
        "        print(f\"Recall: {recall_ExtraTrees:.2f}\")\n",
        "        print(f\"F1-score: {f1_ExtraTrees:.2f}\")\n",
        "        print(f\"kappa: {kappa:.2f}\")\n",
        "        print(f\"ROC AUC: {roc_auc:.2f}\")\n",
        "        print(f\"fpr: {fpr}\")\n",
        "        print(f\"tpr: {tpr}\")\n",
        "        print(f\"thresholds: {thresholds}\")\n",
        "        print(confusion_matrix_ExtraTrees)\n",
        "        print(\"********************************************************************\")\n",
        "        fld = fld + 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DOg_UwJSVlYX",
        "outputId": "a8304aac-b35d-4b34-ef15-1db01ebd494b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Metrics for ExtraTrees Model Fold 1:\n",
            "Inference Time: 0.0968 seconds\n",
            "training Time: 4.7579 seconds\n",
            "Accuracy: 0.96\n",
            "Precision: 0.94\n",
            "Recall: 0.98\n",
            "F1-score: 0.96\n",
            "kappa: 0.91\n",
            "ROC AUC: 0.96\n",
            "fpr: [0.         0.06280193 1.        ]\n",
            "tpr: [0.         0.97562627 1.        ]\n",
            "thresholds: [2 1 0]\n",
            "[[1358   91]\n",
            " [  36 1441]]\n",
            "********************************************************************\n",
            "Metrics for ExtraTrees Model Fold 2:\n",
            "Inference Time: 0.1008 seconds\n",
            "training Time: 2.7021 seconds\n",
            "Accuracy: 0.97\n",
            "Precision: 0.95\n",
            "Recall: 0.98\n",
            "F1-score: 0.97\n",
            "kappa: 0.93\n",
            "ROC AUC: 0.97\n",
            "fpr: [0.         0.05149051 1.        ]\n",
            "tpr: [0.         0.98206897 1.        ]\n",
            "thresholds: [2 1 0]\n",
            "[[1400   76]\n",
            " [  26 1424]]\n",
            "********************************************************************\n",
            "Metrics for ExtraTrees Model Fold 3:\n",
            "Inference Time: 0.1056 seconds\n",
            "training Time: 2.7230 seconds\n",
            "Accuracy: 0.96\n",
            "Precision: 0.95\n",
            "Recall: 0.98\n",
            "F1-score: 0.97\n",
            "kappa: 0.93\n",
            "ROC AUC: 0.96\n",
            "fpr: [0.        0.0480167 1.       ]\n",
            "tpr: [0.        0.9758227 1.       ]\n",
            "thresholds: [2 1 0]\n",
            "[[1368   69]\n",
            " [  36 1453]]\n",
            "********************************************************************\n",
            "Metrics for ExtraTrees Model Fold 4:\n",
            "Inference Time: 0.1253 seconds\n",
            "training Time: 3.7733 seconds\n",
            "Accuracy: 0.96\n",
            "Precision: 0.94\n",
            "Recall: 0.98\n",
            "F1-score: 0.96\n",
            "kappa: 0.92\n",
            "ROC AUC: 0.96\n",
            "fpr: [0.         0.05614973 1.        ]\n",
            "tpr: [0.         0.98181818 1.        ]\n",
            "thresholds: [2 1 0]\n",
            "[[1412   84]\n",
            " [  26 1404]]\n",
            "********************************************************************\n",
            "Metrics for ExtraTrees Model Fold 5:\n",
            "Inference Time: 0.0999 seconds\n",
            "training Time: 2.8778 seconds\n",
            "Accuracy: 0.96\n",
            "Precision: 0.95\n",
            "Recall: 0.98\n",
            "F1-score: 0.96\n",
            "kappa: 0.92\n",
            "ROC AUC: 0.96\n",
            "fpr: [0.         0.05287818 1.        ]\n",
            "tpr: [0.         0.97763802 1.        ]\n",
            "thresholds: [2 1 0]\n",
            "[[1415   79]\n",
            " [  32 1399]]\n",
            "********************************************************************\n",
            "Metrics for ExtraTrees Model Fold 6:\n",
            "Inference Time: 0.0983 seconds\n",
            "training Time: 2.7240 seconds\n",
            "Accuracy: 0.97\n",
            "Precision: 0.96\n",
            "Recall: 0.99\n",
            "F1-score: 0.97\n",
            "kappa: 0.94\n",
            "ROC AUC: 0.97\n",
            "fpr: [0.         0.04616477 1.        ]\n",
            "tpr: [0.         0.98549769 1.        ]\n",
            "thresholds: [2 1 0]\n",
            "[[1343   65]\n",
            " [  22 1495]]\n",
            "********************************************************************\n",
            "Metrics for ExtraTrees Model Fold 7:\n",
            "Inference Time: 0.0972 seconds\n",
            "training Time: 2.7289 seconds\n",
            "Accuracy: 0.97\n",
            "Precision: 0.96\n",
            "Recall: 0.98\n",
            "F1-score: 0.97\n",
            "kappa: 0.93\n",
            "ROC AUC: 0.97\n",
            "fpr: [0.         0.04601648 1.        ]\n",
            "tpr: [0.         0.97889721 1.        ]\n",
            "thresholds: [2 1 0]\n",
            "[[1389   67]\n",
            " [  31 1438]]\n",
            "********************************************************************\n",
            "Metrics for ExtraTrees Model Fold 8:\n",
            "Inference Time: 0.1157 seconds\n",
            "training Time: 3.2993 seconds\n",
            "Accuracy: 0.96\n",
            "Precision: 0.95\n",
            "Recall: 0.98\n",
            "F1-score: 0.96\n",
            "kappa: 0.93\n",
            "ROC AUC: 0.96\n",
            "fpr: [0.         0.04945799 1.        ]\n",
            "tpr: [0.         0.97722567 1.        ]\n",
            "thresholds: [2 1 0]\n",
            "[[1403   73]\n",
            " [  33 1416]]\n",
            "********************************************************************\n",
            "Metrics for ExtraTrees Model Fold 9:\n",
            "Inference Time: 0.1300 seconds\n",
            "training Time: 5.2599 seconds\n",
            "Accuracy: 0.96\n",
            "Precision: 0.95\n",
            "Recall: 0.98\n",
            "F1-score: 0.97\n",
            "kappa: 0.93\n",
            "ROC AUC: 0.96\n",
            "fpr: [0.         0.04948454 1.        ]\n",
            "tpr: [0.         0.97891156 1.        ]\n",
            "thresholds: [2 1 0]\n",
            "[[1383   72]\n",
            " [  31 1439]]\n",
            "********************************************************************\n",
            "Metrics for ExtraTrees Model Fold 10:\n",
            "Inference Time: 0.0978 seconds\n",
            "training Time: 2.8256 seconds\n",
            "Accuracy: 0.96\n",
            "Precision: 0.95\n",
            "Recall: 0.98\n",
            "F1-score: 0.96\n",
            "kappa: 0.93\n",
            "ROC AUC: 0.96\n",
            "fpr: [0.         0.04797297 1.        ]\n",
            "tpr: [0.         0.97647059 1.        ]\n",
            "thresholds: [2 1 0]\n",
            "[[1409   71]\n",
            " [  34 1411]]\n",
            "********************************************************************\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize lists to store metric values\n",
        "accuracies = []\n",
        "precisions = []\n",
        "recalls = []\n",
        "f1_scores = []\n",
        "kappas = []\n",
        "Inference_Time = []\n",
        "Training_time = []\n",
        "roc_auc = []\n",
        "# Loop over the results dictionary\n",
        "for model, metrics in resultsExtraTrees.items():\n",
        "    accuracies.append(metrics['accuracy'])\n",
        "    precisions.append(metrics['precision'])\n",
        "    recalls.append(metrics['recall'])\n",
        "    f1_scores.append(metrics['f1'])\n",
        "    kappas.append(metrics['kappa'])\n",
        "    Inference_Time.append(metrics['Inference_Time'])\n",
        "    Training_time.append(metrics['Training_time'])\n",
        "    roc_auc.append(metrics['roc_auc'])\n",
        "\n",
        "# Calculate the best, worst, and average values for each metric\n",
        "best_accuracy = round(max(accuracies), 2)\n",
        "worst_accuracy = round(min(accuracies), 2)\n",
        "average_accuracy = round(sum(accuracies) / len(accuracies), 2)\n",
        "\n",
        "\n",
        "best_precision = round(max(precisions), 2)\n",
        "worst_precision = round(min(precisions), 2)\n",
        "average_precision = round(sum(precisions) / len(precisions), 3)\n",
        "\n",
        "best_recall = round(max(recalls), 2)\n",
        "worst_recall = round(min(recalls), 2)\n",
        "average_recall = round(sum(recalls) / len(recalls), 2)\n",
        "\n",
        "best_f1_score = round(max(f1_scores), 2)\n",
        "worst_f1_score = round(min(f1_scores), 2)\n",
        "average_f1_score = round(sum(f1_scores) / len(f1_scores), 2)\n",
        "\n",
        "best_kappa = round(max(kappas), 2)\n",
        "worst_kappa = round(min(kappas), 2)\n",
        "average_kappa = round(sum(kappas) / len(kappas), 2)\n",
        "\n",
        "best_Inference_Time = round(max(Inference_Time), 5)\n",
        "worst_Inference_Time = round(min(Inference_Time), 5)\n",
        "average_Inference_Time = round(sum(Inference_Time) / len(Inference_Time), 5)\n",
        "\n",
        "\n",
        "best_Training_time = round(max(Training_time), 5)\n",
        "worst_Training_time = round(min(Training_time), 5)\n",
        "average_Training_time = round(sum(Training_time) / len(Training_time), 5)\n",
        "\n",
        "best_roc_auc = round(max(roc_auc), 2)\n",
        "worst_roc_auc = round(min(roc_auc), 2)\n",
        "average_roc_auc = round(sum(roc_auc) / len(roc_auc), 2)\n",
        "\n",
        "# Print the results\n",
        "print(\"Best Accuracy:\", best_accuracy)\n",
        "print(\"Worst Accuracy:\", worst_accuracy)\n",
        "print(\"Average Accuracy:\", average_accuracy)\n",
        "\n",
        "print(\"************************************************\")\n",
        "\n",
        "\n",
        "print(\"Best Precision:\", best_precision)\n",
        "print(\"Worst Precision:\", worst_precision)\n",
        "print(\"Average Precision:\", average_precision)\n",
        "print(\"************************************************\")\n",
        "\n",
        "print(\"Best Recall:\", best_recall)\n",
        "print(\"Worst Recall:\", worst_recall)\n",
        "print(\"Average Recall:\", average_recall)\n",
        "print(\"************************************************\")\n",
        "\n",
        "print(\"Best F1 Score:\", best_f1_score)\n",
        "print(\"Worst F1 Score:\", worst_f1_score)\n",
        "print(\"Average F1 Score:\", average_f1_score)\n",
        "print(\"************************************************\")\n",
        "\n",
        "print(\"Best Kappa:\", best_kappa)\n",
        "print(\"Worst Kappa:\", worst_kappa)\n",
        "print(\"Average Kappa:\", average_kappa)\n",
        "\n",
        "print(\"************************************************\")\n",
        "\n",
        "print(\"Best Inference_Time:\", best_Inference_Time)\n",
        "print(\"Worst Inference_Time:\", worst_Inference_Time)\n",
        "print(\"Average Inference_Time:\", average_Inference_Time)\n",
        "print(\"************************************************\")\n",
        "\n",
        "print(\"Best Training_time:\", best_Training_time)\n",
        "print(\"Worst Training_time:\", worst_Training_time)\n",
        "print(\"Average Training_time:\", average_Training_time)\n",
        "print(\"************************************************\")\n",
        "\n",
        "print(\"Best roc_auc:\", best_roc_auc)\n",
        "print(\"Worst roc_auc:\", worst_roc_auc)\n",
        "print(\"Average roc_auc:\", average_roc_auc)\n"
      ],
      "metadata": {
        "id": "pd6v2fUHFcCU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e35f0d1a-2b1c-41af-a305-6f6b374bd366"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Accuracy: 0.97\n",
            "Worst Accuracy: 0.96\n",
            "Average Accuracy: 0.96\n",
            "************************************************\n",
            "Best Precision: 0.96\n",
            "Worst Precision: 0.94\n",
            "Average Precision: 0.95\n",
            "************************************************\n",
            "Best Recall: 0.99\n",
            "Worst Recall: 0.98\n",
            "Average Recall: 0.98\n",
            "************************************************\n",
            "Best F1 Score: 0.97\n",
            "Worst F1 Score: 0.96\n",
            "Average F1 Score: 0.96\n",
            "************************************************\n",
            "Best Kappa: 0.94\n",
            "Worst Kappa: 0.91\n",
            "Average Kappa: 0.93\n",
            "************************************************\n",
            "Best Inference_Time: 0.12995\n",
            "Worst Inference_Time: 0.09682\n",
            "Average Inference_Time: 0.10673\n",
            "************************************************\n",
            "Best Training_time: 5.25995\n",
            "Worst Training_time: 2.7021\n",
            "Average Training_time: 3.36719\n",
            "************************************************\n",
            "Best roc_auc: 0.97\n",
            "Worst roc_auc: 0.96\n",
            "Average roc_auc: 0.96\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**10-AdaBoost**"
      ],
      "metadata": {
        "id": "F-5HOOddZ-T-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, cohen_kappa_score, confusion_matrix, roc_auc_score, roc_curve\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.model_selection import KFold\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "resultsAdaBoost = {}\n",
        "additional_metrics = {}\n",
        "kf = KFold(n_splits=10, random_state=42, shuffle=True)\n",
        "fld = 1\n",
        "i = 1\n",
        "X = np.concatenate([X_trainO, X_testO], axis=0)\n",
        "y = np.concatenate([y_trainO, y_testO], axis=0)\n",
        "X_df = pd.DataFrame(X)\n",
        "y_df = pd.DataFrame(y)\n",
        "\n",
        "for train_index, test_index in kf.split(X):\n",
        "\n",
        "    X_trainV, X_testV = X_df.iloc[train_index], X_df.iloc[test_index]\n",
        "    y_trainV, y_testV = y_df.iloc[train_index], y_df.iloc[test_index]\n",
        "\n",
        "    # Initialize AdaBoostClassifier\n",
        "    AdaBoost = AdaBoostClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "    start_time = time.time()\n",
        "    AdaBoost.fit(X_trainV, y_trainV)\n",
        "    Training_time = time.time() - start_time\n",
        "\n",
        "    start_time = time.time()\n",
        "    y_predAdaBoost = AdaBoost.predict(X_testV)\n",
        "    Inference_Time = time.time() - start_time\n",
        "\n",
        "    accuracy_AdaBoost = accuracy_score(y_testV, y_predAdaBoost)\n",
        "    precision_AdaBoost = precision_score(y_testV, y_predAdaBoost)\n",
        "    recall_AdaBoost = recall_score(y_testV, y_predAdaBoost)\n",
        "    f1_AdaBoost = f1_score(y_testV, y_predAdaBoost)\n",
        "\n",
        "    kappa = cohen_kappa_score(y_testV, y_predAdaBoost)\n",
        "    confusion_matrix_AdaBoost = confusion_matrix(y_testV, y_predAdaBoost)\n",
        "    roc_auc = roc_auc_score(y_testV, y_predAdaBoost)\n",
        "    fpr, tpr, thresholds = roc_curve(y_testV, y_predAdaBoost)\n",
        "\n",
        "    resultsAdaBoost[f'Model_{fld}'] = {\n",
        "        'Matrix': confusion_matrix_AdaBoost,\n",
        "        'accuracy': accuracy_AdaBoost,\n",
        "        'precision': precision_AdaBoost,\n",
        "        'recall': recall_AdaBoost,\n",
        "        'f1': f1_AdaBoost,\n",
        "        'kappa': kappa,\n",
        "        'roc_auc': roc_auc,\n",
        "        'tpr': tpr,\n",
        "        'thresholds': thresholds,\n",
        "        'Inference_Time': Inference_Time,\n",
        "        'Training_time': Training_time\n",
        "    }\n",
        "\n",
        "    # Print metrics for the AdaBoost model\n",
        "    print(f'Metrics for AdaBoost Model Fold {fld}:')\n",
        "    print(f\"Inference Time: {Inference_Time:.4f} seconds\")\n",
        "    print(f\"Training Time: {Training_time:.4f} seconds\")\n",
        "    print(f\"Accuracy: {accuracy_AdaBoost:.2f}\")\n",
        "    print(f\"Precision: {precision_AdaBoost:.2f}\")\n",
        "    print(f\"Recall: {recall_AdaBoost:.2f}\")\n",
        "    print(f\"F1-score: {f1_AdaBoost:.2f}\")\n",
        "    print(f\"kappa: {kappa:.2f}\")\n",
        "    print(f\"ROC AUC: {roc_auc:.2f}\")\n",
        "    print(f\"fpr: {fpr}\")\n",
        "    print(f\"tpr: {tpr}\")\n",
        "    print(f\"thresholds: {thresholds}\")\n",
        "    print(confusion_matrix_AdaBoost)\n",
        "    print(\"********************************************************************\")\n",
        "\n",
        "    fld = fld + 1\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QDp-wAO6aQUM",
        "outputId": "b3cf5b2a-ee9a-4726-f184-794460d8499e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Metrics for AdaBoost Model Fold 1:\n",
            "Inference Time: 0.0548 seconds\n",
            "Training Time: 6.5959 seconds\n",
            "Accuracy: 0.86\n",
            "Precision: 0.85\n",
            "Recall: 0.88\n",
            "F1-score: 0.86\n",
            "kappa: 0.72\n",
            "ROC AUC: 0.86\n",
            "fpr: [0.         0.16494134 1.        ]\n",
            "tpr: [0.         0.88422478 1.        ]\n",
            "thresholds: [2 1 0]\n",
            "[[1210  239]\n",
            " [ 171 1306]]\n",
            "********************************************************************\n",
            "Metrics for AdaBoost Model Fold 2:\n",
            "Inference Time: 0.0569 seconds\n",
            "Training Time: 4.6348 seconds\n",
            "Accuracy: 0.84\n",
            "Precision: 0.83\n",
            "Recall: 0.86\n",
            "F1-score: 0.84\n",
            "kappa: 0.68\n",
            "ROC AUC: 0.84\n",
            "fpr: [0.         0.17547425 1.        ]\n",
            "tpr: [0.         0.85793103 1.        ]\n",
            "thresholds: [2 1 0]\n",
            "[[1217  259]\n",
            " [ 206 1244]]\n",
            "********************************************************************\n",
            "Metrics for AdaBoost Model Fold 3:\n",
            "Inference Time: 0.0779 seconds\n",
            "Training Time: 4.8857 seconds\n",
            "Accuracy: 0.85\n",
            "Precision: 0.84\n",
            "Recall: 0.88\n",
            "F1-score: 0.86\n",
            "kappa: 0.71\n",
            "ROC AUC: 0.85\n",
            "fpr: [0.         0.17397356 1.        ]\n",
            "tpr: [0.         0.88247146 1.        ]\n",
            "thresholds: [2 1 0]\n",
            "[[1187  250]\n",
            " [ 175 1314]]\n",
            "********************************************************************\n",
            "Metrics for AdaBoost Model Fold 4:\n",
            "Inference Time: 0.1086 seconds\n",
            "Training Time: 6.4587 seconds\n",
            "Accuracy: 0.85\n",
            "Precision: 0.83\n",
            "Recall: 0.88\n",
            "F1-score: 0.85\n",
            "kappa: 0.71\n",
            "ROC AUC: 0.85\n",
            "fpr: [0.         0.17580214 1.        ]\n",
            "tpr: [0.         0.88251748 1.        ]\n",
            "thresholds: [2 1 0]\n",
            "[[1233  263]\n",
            " [ 168 1262]]\n",
            "********************************************************************\n",
            "Metrics for AdaBoost Model Fold 5:\n",
            "Inference Time: 0.0907 seconds\n",
            "Training Time: 6.5529 seconds\n",
            "Accuracy: 0.86\n",
            "Precision: 0.85\n",
            "Recall: 0.87\n",
            "F1-score: 0.86\n",
            "kappa: 0.72\n",
            "ROC AUC: 0.86\n",
            "fpr: [0.         0.14658635 1.        ]\n",
            "tpr: [0.         0.87141859 1.        ]\n",
            "thresholds: [2 1 0]\n",
            "[[1275  219]\n",
            " [ 184 1247]]\n",
            "********************************************************************\n",
            "Metrics for AdaBoost Model Fold 6:\n",
            "Inference Time: 0.1814 seconds\n",
            "Training Time: 9.2801 seconds\n",
            "Accuracy: 0.86\n",
            "Precision: 0.86\n",
            "Recall: 0.87\n",
            "F1-score: 0.87\n",
            "kappa: 0.72\n",
            "ROC AUC: 0.86\n",
            "fpr: [0.         0.15198864 1.        ]\n",
            "tpr: [0.         0.87277521 1.        ]\n",
            "thresholds: [2 1 0]\n",
            "[[1194  214]\n",
            " [ 193 1324]]\n",
            "********************************************************************\n",
            "Metrics for AdaBoost Model Fold 7:\n",
            "Inference Time: 0.0692 seconds\n",
            "Training Time: 7.1943 seconds\n",
            "Accuracy: 0.85\n",
            "Precision: 0.84\n",
            "Recall: 0.87\n",
            "F1-score: 0.85\n",
            "kappa: 0.70\n",
            "ROC AUC: 0.85\n",
            "fpr: [0.         0.16964286 1.        ]\n",
            "tpr: [0.         0.87202178 1.        ]\n",
            "thresholds: [2 1 0]\n",
            "[[1209  247]\n",
            " [ 188 1281]]\n",
            "********************************************************************\n",
            "Metrics for AdaBoost Model Fold 8:\n",
            "Inference Time: 0.0589 seconds\n",
            "Training Time: 4.8779 seconds\n",
            "Accuracy: 0.85\n",
            "Precision: 0.83\n",
            "Recall: 0.89\n",
            "F1-score: 0.86\n",
            "kappa: 0.71\n",
            "ROC AUC: 0.85\n",
            "fpr: [0.        0.1802168 1.       ]\n",
            "tpr: [0.        0.8868185 1.       ]\n",
            "thresholds: [2 1 0]\n",
            "[[1210  266]\n",
            " [ 164 1285]]\n",
            "********************************************************************\n",
            "Metrics for AdaBoost Model Fold 9:\n",
            "Inference Time: 0.0756 seconds\n",
            "Training Time: 5.2906 seconds\n",
            "Accuracy: 0.86\n",
            "Precision: 0.84\n",
            "Recall: 0.88\n",
            "F1-score: 0.86\n",
            "kappa: 0.71\n",
            "ROC AUC: 0.86\n",
            "fpr: [0.         0.16975945 1.        ]\n",
            "tpr: [0.         0.88027211 1.        ]\n",
            "thresholds: [2 1 0]\n",
            "[[1208  247]\n",
            " [ 176 1294]]\n",
            "********************************************************************\n",
            "Metrics for AdaBoost Model Fold 10:\n",
            "Inference Time: 0.0535 seconds\n",
            "Training Time: 6.2246 seconds\n",
            "Accuracy: 0.85\n",
            "Precision: 0.84\n",
            "Recall: 0.87\n",
            "F1-score: 0.85\n",
            "kappa: 0.71\n",
            "ROC AUC: 0.85\n",
            "fpr: [0.         0.16418919 1.        ]\n",
            "tpr: [0.         0.86989619 1.        ]\n",
            "thresholds: [2 1 0]\n",
            "[[1237  243]\n",
            " [ 188 1257]]\n",
            "********************************************************************\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize lists to store metric values\n",
        "accuracies = []\n",
        "precisions = []\n",
        "recalls = []\n",
        "f1_scores = []\n",
        "kappas = []\n",
        "Inference_Time = []\n",
        "Training_time = []\n",
        "roc_auc = []\n",
        "\n",
        "# Loop over the results dictionary\n",
        "for model, metrics in resultsAdaBoost.items():\n",
        "    accuracies.append(metrics['accuracy'])\n",
        "    precisions.append(metrics['precision'])\n",
        "    recalls.append(metrics['recall'])\n",
        "    f1_scores.append(metrics['f1'])\n",
        "    kappas.append(metrics['kappa'])\n",
        "    Inference_Time.append(metrics['Inference_Time'])\n",
        "    Training_time.append(metrics['Training_time'])\n",
        "    roc_auc.append(metrics['roc_auc'])\n",
        "\n",
        "# Calculate the best, worst, and average values for each metric\n",
        "best_accuracy = round(max(accuracies), 2)\n",
        "worst_accuracy = round(min(accuracies), 2)\n",
        "average_accuracy = round(sum(accuracies) / len(accuracies), 2)\n",
        "\n",
        "best_precision = round(max(precisions), 2)\n",
        "worst_precision = round(min(precisions), 2)\n",
        "average_precision = round(sum(precisions) / len(precisions), 3)\n",
        "\n",
        "best_recall = round(max(recalls), 2)\n",
        "worst_recall = round(min(recalls), 2)\n",
        "average_recall = round(sum(recalls) / len(recalls), 2)\n",
        "\n",
        "best_f1_score = round(max(f1_scores), 2)\n",
        "worst_f1_score = round(min(f1_scores), 2)\n",
        "average_f1_score = round(sum(f1_scores) / len(f1_scores), 2)\n",
        "\n",
        "best_kappa = round(max(kappas), 2)\n",
        "worst_kappa = round(min(kappas), 2)\n",
        "average_kappa = round(sum(kappas) / len(kappas), 2)\n",
        "\n",
        "best_Inference_Time = round(max(Inference_Time), 5)\n",
        "worst_Inference_Time = round(min(Inference_Time), 5)\n",
        "average_Inference_Time = round(sum(Inference_Time) / len(Inference_Time), 5)\n",
        "\n",
        "best_Training_time = round(max(Training_time), 5)\n",
        "worst_Training_time = round(min(Training_time), 5)\n",
        "average_Training_time = round(sum(Training_time) / len(Training_time), 5)\n",
        "\n",
        "best_roc_auc = round(max(roc_auc), 2)\n",
        "worst_roc_auc = round(min(roc_auc), 2)\n",
        "average_roc_auc = round(sum(roc_auc) / len(roc_auc), 2)\n",
        "\n",
        "# Print the results\n",
        "print(\"Best Accuracy:\", best_accuracy)\n",
        "print(\"Worst Accuracy:\", worst_accuracy)\n",
        "print(\"Average Accuracy:\", average_accuracy)\n",
        "print(\"************************************************\")\n",
        "\n",
        "print(\"Best Precision:\", best_precision)\n",
        "print(\"Worst Precision:\", worst_precision)\n",
        "print(\"Average Precision:\", average_precision)\n",
        "print(\"************************************************\")\n",
        "\n",
        "print(\"Best Recall:\", best_recall)\n",
        "print(\"Worst Recall:\", worst_recall)\n",
        "print(\"Average Recall:\", average_recall)\n",
        "print(\"************************************************\")\n",
        "\n",
        "print(\"Best F1 Score:\", best_f1_score)\n",
        "print(\"Worst F1 Score:\", worst_f1_score)\n",
        "print(\"Average F1 Score:\", average_f1_score)\n",
        "print(\"************************************************\")\n",
        "\n",
        "print(\"Best Kappa:\", best_kappa)\n",
        "print(\"Worst Kappa:\", worst_kappa)\n",
        "print(\"Average Kappa:\", average_kappa)\n",
        "print(\"************************************************\")\n",
        "\n",
        "print(\"Best Inference_Time:\", best_Inference_Time)\n",
        "print(\"Worst Inference_Time:\", worst_Inference_Time)\n",
        "print(\"Average Inference_Time:\", average_Inference_Time)\n",
        "print(\"************************************************\")\n",
        "\n",
        "print(\"Best Training_time:\", best_Training_time)\n",
        "print(\"Worst Training_time:\", worst_Training_time)\n",
        "print(\"Average Training_time:\", average_Training_time)\n",
        "print(\"************************************************\")\n",
        "\n",
        "print(\"Best roc_auc:\", best_roc_auc)\n",
        "print(\"Worst roc_auc:\", worst_roc_auc)\n",
        "print(\"Average roc_auc:\", average_roc_auc)\n"
      ],
      "metadata": {
        "id": "2_M1bkZmcOcZ",
        "outputId": "b448ecd5-17fd-4956-eec6-ca191022965f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Accuracy: 0.86\n",
            "Worst Accuracy: 0.84\n",
            "Average Accuracy: 0.85\n",
            "************************************************\n",
            "Best Precision: 0.86\n",
            "Worst Precision: 0.83\n",
            "Average Precision: 0.84\n",
            "************************************************\n",
            "Best Recall: 0.89\n",
            "Worst Recall: 0.86\n",
            "Average Recall: 0.88\n",
            "************************************************\n",
            "Best F1 Score: 0.87\n",
            "Worst F1 Score: 0.84\n",
            "Average F1 Score: 0.86\n",
            "************************************************\n",
            "Best Kappa: 0.72\n",
            "Worst Kappa: 0.68\n",
            "Average Kappa: 0.71\n",
            "************************************************\n",
            "Best Inference_Time: 0.18141\n",
            "Worst Inference_Time: 0.05345\n",
            "Average Inference_Time: 0.08274\n",
            "************************************************\n",
            "Best Training_time: 9.28012\n",
            "Worst Training_time: 4.6348\n",
            "Average Training_time: 6.19955\n",
            "************************************************\n",
            "Best roc_auc: 0.86\n",
            "Worst roc_auc: 0.84\n",
            "Average roc_auc: 0.85\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.concatenate([X_trainO, X_testO], axis=0)\n",
        "y = np.concatenate([y_trainO, y_testO], axis=0)\n",
        "X_df = pd.DataFrame(X)\n",
        "y_df = pd.DataFrame(y)\n",
        "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, VotingClassifier, BaggingClassifier"
      ],
      "metadata": {
        "id": "7e58frWkhtFT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1-Ensemble DT,RF,AdaBoost"
      ],
      "metadata": {
        "id": "LMA8BOo4hZJx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier, BaggingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, cohen_kappa_score, roc_auc_score\n",
        "import time\n",
        "\n",
        "# Data preparation\n",
        "kf = KFold(n_splits=10, random_state=42, shuffle=True)\n",
        "X_df = pd.DataFrame(X)  # Assuming X is predefined\n",
        "y_df = pd.DataFrame(y)  # Assuming y is predefined\n",
        "\n",
        "# Base models\n",
        "adaboost = AdaBoostClassifier(n_estimators=100, random_state=42)\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "dt = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "# Ensemble configurations\n",
        "hard_voting = VotingClassifier(estimators=[('AdaBoost', adaboost), ('RF', rf), ('DT', dt)], voting='hard')\n",
        "soft_voting = VotingClassifier(estimators=[('AdaBoost', adaboost), ('RF', rf), ('DT', dt)], voting='soft')\n",
        "bagging = BaggingClassifier(base_estimator=rf, n_estimators=10, random_state=42)\n",
        "boosting = adaboost  # Boosting via AdaBoost\n",
        "\n",
        "# Dictionary to hold results, ensuring unique keys for all classifier configurations\n",
        "results = {\n",
        "    'Hard Voting': [],\n",
        "    'Soft Voting': [],\n",
        "    'Bagging': [],\n",
        "    'Boosting': []\n",
        "}\n",
        "\n",
        "# Cross-validation\n",
        "for train_index, test_index in kf.split(X_df):\n",
        "    X_train, X_test = X_df.iloc[train_index], X_df.iloc[test_index]\n",
        "    y_train, y_test = y_df.iloc[train_index], y_df.iloc[test_index]\n",
        "\n",
        "    for model, model_name in zip([hard_voting, soft_voting, bagging, boosting], ['Hard Voting', 'Soft Voting', 'Bagging', 'Boosting']):\n",
        "        start_train_time = time.time()\n",
        "        model.fit(X_train, y_train.values.ravel())\n",
        "        train_time = time.time() - start_train_time\n",
        "\n",
        "        start_infer_time = time.time()\n",
        "        predictions = model.predict(X_test)\n",
        "        infer_time = time.time() - start_infer_time\n",
        "\n",
        "        metrics = {\n",
        "            'Accuracy': accuracy_score(y_test, predictions),\n",
        "            'Precision': precision_score(y_test, predictions, average='macro'),\n",
        "            'Recall': recall_score(y_test, predictions, average='macro'),\n",
        "            'F1 Score': f1_score(y_test, predictions, average='macro'),\n",
        "            'Kappa': cohen_kappa_score(y_test, predictions),\n",
        "            'Training Time': train_time,\n",
        "            'Inference Time': infer_time\n",
        "        }\n",
        "\n",
        "        if hasattr(model, \"predict_proba\"):\n",
        "            metrics['ROC AUC'] = roc_auc_score(y_test, model.predict_proba(X_test)[:, 1])\n",
        "\n",
        "        results[model_name].append(metrics)\n",
        "\n",
        "# Print best, worst, and average results\n",
        "for key, value in results.items():\n",
        "    print(f\"\\nResults for {key}:\")\n",
        "    for metric in ['Accuracy', 'Precision', 'Recall', 'F1 Score', 'Kappa', 'Training Time', 'Inference Time']:\n",
        "        metric_values = [v[metric] for v in value]\n",
        "        print(f\"{metric} - Best: {max(metric_values):.4f}, Worst: {min(metric_values):.4f}, Average: {np.mean(metric_values):.4f}\")\n",
        "\n",
        "    if any('ROC AUC' in metric for metric in value):\n",
        "        roc_auc_values = [v['ROC AUC'] for v in value if 'ROC AUC' in v]\n",
        "        print(f\"ROC AUC - Best: {max(roc_auc_values):.4f}, Worst: {min(roc_auc_values):.4f}, Average: {np.mean(roc_auc_values):.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VRAYNDpNhdPE",
        "outputId": "37d26489-5142-42be-d6d0-2d7ce5c9a76d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Results for Hard Voting:\n",
            "Accuracy - Best: 0.9597, Worst: 0.9515, Average: 0.9549\n",
            "Precision - Best: 0.9617, Worst: 0.9531, Average: 0.9563\n",
            "Recall - Best: 0.9592, Worst: 0.9510, Average: 0.9549\n",
            "F1 Score - Best: 0.9595, Worst: 0.9514, Average: 0.9549\n",
            "Kappa - Best: 0.9190, Worst: 0.9028, Average: 0.9099\n",
            "Training Time - Best: 18.7184, Worst: 12.0514, Average: 13.2698\n",
            "Inference Time - Best: 0.1977, Worst: 0.1411, Average: 0.1527\n",
            "\n",
            "Results for Soft Voting:\n",
            "Accuracy - Best: 0.9494, Worst: 0.9368, Average: 0.9438\n",
            "Precision - Best: 0.9508, Worst: 0.9388, Average: 0.9457\n",
            "Recall - Best: 0.9493, Worst: 0.9372, Average: 0.9437\n",
            "F1 Score - Best: 0.9494, Worst: 0.9367, Average: 0.9437\n",
            "Kappa - Best: 0.8988, Worst: 0.8736, Average: 0.8875\n",
            "Training Time - Best: 14.1141, Worst: 12.0856, Average: 12.9306\n",
            "Inference Time - Best: 0.3454, Worst: 0.1282, Average: 0.1595\n",
            "ROC AUC - Best: 0.9935, Worst: 0.9893, Average: 0.9912\n",
            "\n",
            "Results for Bagging:\n",
            "Accuracy - Best: 0.9590, Worst: 0.9416, Average: 0.9498\n",
            "Precision - Best: 0.9605, Worst: 0.9430, Average: 0.9507\n",
            "Recall - Best: 0.9581, Worst: 0.9413, Average: 0.9498\n",
            "F1 Score - Best: 0.9588, Worst: 0.9415, Average: 0.9497\n",
            "Kappa - Best: 0.9177, Worst: 0.8830, Average: 0.8995\n",
            "Training Time - Best: 49.9117, Worst: 46.0569, Average: 47.7028\n",
            "Inference Time - Best: 0.7817, Worst: 0.6383, Average: 0.6909\n",
            "ROC AUC - Best: 0.9906, Worst: 0.9860, Average: 0.9888\n",
            "\n",
            "Results for Boosting:\n",
            "Accuracy - Best: 0.8622, Worst: 0.8411, Average: 0.8544\n",
            "Precision - Best: 0.8623, Worst: 0.8415, Average: 0.8551\n",
            "Recall - Best: 0.8624, Worst: 0.8412, Average: 0.8544\n",
            "F1 Score - Best: 0.8622, Worst: 0.8411, Average: 0.8543\n",
            "Kappa - Best: 0.7245, Worst: 0.6822, Average: 0.7087\n",
            "Training Time - Best: 5.6010, Worst: 4.3780, Average: 4.8595\n",
            "Inference Time - Best: 0.0717, Worst: 0.0558, Average: 0.0615\n",
            "ROC AUC - Best: 0.9462, Worst: 0.9313, Average: 0.9401\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2-Ensemble:DT,RF"
      ],
      "metadata": {
        "id": "5XumebpPlume"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier, BaggingClassifier, VotingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, cohen_kappa_score, roc_auc_score\n",
        "import time\n",
        "\n",
        "# Data preparation\n",
        "kf = KFold(n_splits=10, random_state=42, shuffle=True)\n",
        "X_df = pd.DataFrame(X)  # Assuming X is predefined\n",
        "y_df = pd.DataFrame(y)  # Assuming y is predefined\n",
        "\n",
        "# Base models\n",
        "dt = DecisionTreeClassifier(random_state=42)\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Ensemble configurations\n",
        "hard_voting = VotingClassifier(estimators=[('DT', dt), ('RF', rf)], voting='hard')\n",
        "soft_voting = VotingClassifier(estimators=[('DT', dt), ('RF', rf)], voting='soft')\n",
        "bagging = BaggingClassifier(base_estimator=rf, n_estimators=10, random_state=42)\n",
        "boosting = AdaBoostClassifier(n_estimators=100, random_state=42)  # Boosting via AdaBoost\n",
        "\n",
        "# Dictionary to hold results, ensuring unique keys for all classifier configurations\n",
        "results = {\n",
        "    'Hard Voting': [],\n",
        "    'Soft Voting': [],\n",
        "    'Bagging': [],\n",
        "    'Boosting': []\n",
        "}\n",
        "\n",
        "# Cross-validation\n",
        "for train_index, test_index in kf.split(X_df):\n",
        "    X_train, X_test = X_df.iloc[train_index], X_df.iloc[test_index]\n",
        "    y_train, y_test = y_df.iloc[train_index], y_df.iloc[test_index]\n",
        "\n",
        "    for model, model_name in zip([hard_voting, soft_voting, bagging, boosting], ['Hard Voting', 'Soft Voting', 'Bagging', 'Boosting']):\n",
        "        start_train_time = time.time()\n",
        "        model.fit(X_train, y_train.values.ravel())\n",
        "        train_time = time.time() - start_train_time\n",
        "\n",
        "        start_infer_time = time.time()\n",
        "        predictions = model.predict(X_test)\n",
        "        infer_time = time.time() - start_infer_time\n",
        "\n",
        "        metrics = {\n",
        "            'Accuracy': accuracy_score(y_test, predictions),\n",
        "            'Precision': precision_score(y_test, predictions, average='macro'),\n",
        "            'Recall': recall_score(y_test, predictions, average='macro'),\n",
        "            'F1 Score': f1_score(y_test, predictions, average='macro'),\n",
        "            'Kappa': cohen_kappa_score(y_test, predictions),\n",
        "            'Training Time': train_time,\n",
        "            'Inference Time': infer_time\n",
        "        }\n",
        "\n",
        "        if hasattr(model, \"predict_proba\"):\n",
        "            metrics['ROC AUC'] = roc_auc_score(y_test, model.predict_proba(X_test)[:, 1])\n",
        "\n",
        "        results[model_name].append(metrics)\n",
        "\n",
        "# Print best, worst, and average results\n",
        "for key, value in results.items():\n",
        "    print(f\"\\nResults for {key}:\")\n",
        "    for metric in ['Accuracy', 'Precision', 'Recall', 'F1 Score', 'Kappa', 'Training Time', 'Inference Time']:\n",
        "        metric_values = [v[metric] for v in value]\n",
        "        print(f\"{metric} - Best: {max(metric_values):.4f}, Worst: {min(metric_values):.4f}, Average: {np.mean(metric_values):.4f}\")\n",
        "\n",
        "    if any('ROC AUC' in metric for metric in value):\n",
        "        roc_auc_values = [v['ROC AUC'] for v in value if 'ROC AUC' in v]\n",
        "        print(f\"ROC AUC - Best: {max(roc_auc_values):.4f}, Worst: {min(roc_auc_values):.4f}, Average: {np.mean(roc_auc_values):.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nwljPIYilz11",
        "outputId": "32682148-2891-473c-c6a1-581166a434f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Results for Hard Voting:\n",
            "Accuracy - Best: 0.9672, Worst: 0.9573, Average: 0.9624\n",
            "Precision - Best: 0.9675, Worst: 0.9573, Average: 0.9626\n",
            "Recall - Best: 0.9668, Worst: 0.9572, Average: 0.9624\n",
            "F1 Score - Best: 0.9671, Worst: 0.9573, Average: 0.9624\n",
            "Kappa - Best: 0.9342, Worst: 0.9145, Average: 0.9248\n",
            "Training Time - Best: 12.6509, Worst: 6.9717, Average: 7.8770\n",
            "Inference Time - Best: 0.1212, Worst: 0.0838, Average: 0.0996\n",
            "\n",
            "Results for Soft Voting:\n",
            "Accuracy - Best: 0.9491, Worst: 0.9364, Average: 0.9436\n",
            "Precision - Best: 0.9505, Worst: 0.9385, Average: 0.9455\n",
            "Recall - Best: 0.9489, Worst: 0.9368, Average: 0.9435\n",
            "F1 Score - Best: 0.9490, Worst: 0.9364, Average: 0.9435\n",
            "Kappa - Best: 0.8981, Worst: 0.8729, Average: 0.8871\n",
            "Training Time - Best: 9.5211, Worst: 7.6445, Average: 8.1955\n",
            "Inference Time - Best: 0.0824, Worst: 0.0694, Average: 0.0730\n",
            "ROC AUC - Best: 0.9934, Worst: 0.9888, Average: 0.9909\n",
            "\n",
            "Results for Bagging:\n",
            "Accuracy - Best: 0.9590, Worst: 0.9416, Average: 0.9498\n",
            "Precision - Best: 0.9605, Worst: 0.9430, Average: 0.9507\n",
            "Recall - Best: 0.9581, Worst: 0.9413, Average: 0.9498\n",
            "F1 Score - Best: 0.9588, Worst: 0.9415, Average: 0.9497\n",
            "Kappa - Best: 0.9177, Worst: 0.8830, Average: 0.8995\n",
            "Training Time - Best: 54.3951, Worst: 46.0618, Average: 48.0455\n",
            "Inference Time - Best: 0.8236, Worst: 0.6491, Average: 0.7165\n",
            "ROC AUC - Best: 0.9906, Worst: 0.9860, Average: 0.9888\n",
            "\n",
            "Results for Boosting:\n",
            "Accuracy - Best: 0.8622, Worst: 0.8411, Average: 0.8544\n",
            "Precision - Best: 0.8623, Worst: 0.8415, Average: 0.8551\n",
            "Recall - Best: 0.8624, Worst: 0.8412, Average: 0.8544\n",
            "F1 Score - Best: 0.8622, Worst: 0.8411, Average: 0.8543\n",
            "Kappa - Best: 0.7245, Worst: 0.6822, Average: 0.7087\n",
            "Training Time - Best: 6.1898, Worst: 4.5942, Average: 5.1805\n",
            "Inference Time - Best: 0.0969, Worst: 0.0575, Average: 0.0727\n",
            "ROC AUC - Best: 0.9462, Worst: 0.9313, Average: 0.9401\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3-Ensemble: ExtraTrees-RF"
      ],
      "metadata": {
        "id": "W6T-6L9qpPI7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.ensemble import AdaBoostClassifier, ExtraTreesClassifier, BaggingClassifier, VotingClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, cohen_kappa_score, roc_auc_score\n",
        "import time\n",
        "\n",
        "# Data preparation\n",
        "kf = KFold(n_splits=10, random_state=42, shuffle=True)\n",
        "X_df = pd.DataFrame(X)  # Assuming X is predefined\n",
        "y_df = pd.DataFrame(y)  # Assuming y is predefined\n",
        "\n",
        "# Base models\n",
        "extra_trees = ExtraTreesClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Ensemble configurations\n",
        "hard_voting = VotingClassifier(estimators=[('ExtraTrees', extra_trees)], voting='hard')\n",
        "soft_voting = VotingClassifier(estimators=[('ExtraTrees', extra_trees)], voting='soft')\n",
        "bagging = BaggingClassifier(base_estimator=extra_trees, n_estimators=10, random_state=42)\n",
        "boosting = AdaBoostClassifier(n_estimators=100, random_state=42)  # Boosting via AdaBoost\n",
        "\n",
        "# Dictionary to hold results, ensuring unique keys for all classifier configurations\n",
        "results = {\n",
        "    'Hard Voting': [],\n",
        "    'Soft Voting': [],\n",
        "    'Bagging': [],\n",
        "    'Boosting': []\n",
        "}\n",
        "\n",
        "# Cross-validation\n",
        "for train_index, test_index in kf.split(X_df):\n",
        "    X_train, X_test = X_df.iloc[train_index], X_df.iloc[test_index]\n",
        "    y_train, y_test = y_df.iloc[train_index], y_df.iloc[test_index]\n",
        "\n",
        "    for model, model_name in zip([hard_voting, soft_voting, bagging, boosting], ['Hard Voting', 'Soft Voting', 'Bagging', 'Boosting']):\n",
        "        start_train_time = time.time()\n",
        "        model.fit(X_train, y_train.values.ravel())\n",
        "        train_time = time.time() - start_train_time\n",
        "\n",
        "        start_infer_time = time.time()\n",
        "        predictions = model.predict(X_test)\n",
        "        infer_time = time.time() - start_infer_time\n",
        "\n",
        "        metrics = {\n",
        "            'Accuracy': accuracy_score(y_test, predictions),\n",
        "            'Precision': precision_score(y_test, predictions, average='macro'),\n",
        "            'Recall': recall_score(y_test, predictions, average='macro'),\n",
        "            'F1 Score': f1_score(y_test, predictions, average='macro'),\n",
        "            'Kappa': cohen_kappa_score(y_test, predictions),\n",
        "            'Training Time': train_time,\n",
        "            'Inference Time': infer_time\n",
        "        }\n",
        "\n",
        "        if hasattr(model, \"predict_proba\"):\n",
        "            metrics['ROC AUC'] = roc_auc_score(y_test, model.predict_proba(X_test)[:, 1])\n",
        "\n",
        "        results[model_name].append(metrics)\n",
        "\n",
        "# Print best, worst, and average results\n",
        "for key, value in results.items():\n",
        "    print(f\"\\nResults for {key}:\")\n",
        "    for metric in ['Accuracy', 'Precision', 'Recall', 'F1 Score', 'Kappa', 'Training Time', 'Inference Time']:\n",
        "        metric_values = [v[metric] for v in value]\n",
        "        print(f\"{metric} - Best: {max(metric_values):.4f}, Worst: {min(metric_values):.4f}, Average: {np.mean(metric_values):.4f}\")\n",
        "\n",
        "    if any('ROC AUC' in metric for metric in value):\n",
        "        roc_auc_values = [v['ROC AUC'] for v in value if 'ROC AUC' in v]\n",
        "        print(f\"ROC AUC - Best: {max(roc_auc_values):.4f}, Worst: {min(roc_auc_values):.4f}, Average: {np.mean(roc_auc_values):.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bn1oIq8DpYMB",
        "outputId": "6b4b7667-d636-4ac6-c31b-27874998fd1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Results for Hard Voting:\n",
            "Accuracy - Best: 0.9692, Worst: 0.9542, Average: 0.9639\n",
            "Precision - Best: 0.9702, Worst: 0.9553, Average: 0.9643\n",
            "Recall - Best: 0.9686, Worst: 0.9540, Average: 0.9639\n",
            "F1 Score - Best: 0.9691, Worst: 0.9542, Average: 0.9638\n",
            "Kappa - Best: 0.9383, Worst: 0.9084, Average: 0.9277\n",
            "Training Time - Best: 6.7052, Worst: 2.7608, Average: 3.5900\n",
            "Inference Time - Best: 0.1642, Worst: 0.1171, Average: 0.1309\n",
            "\n",
            "Results for Soft Voting:\n",
            "Accuracy - Best: 0.9692, Worst: 0.9542, Average: 0.9639\n",
            "Precision - Best: 0.9702, Worst: 0.9553, Average: 0.9643\n",
            "Recall - Best: 0.9686, Worst: 0.9540, Average: 0.9639\n",
            "F1 Score - Best: 0.9691, Worst: 0.9542, Average: 0.9638\n",
            "Kappa - Best: 0.9383, Worst: 0.9084, Average: 0.9277\n",
            "Training Time - Best: 4.7213, Worst: 2.7778, Average: 3.1816\n",
            "Inference Time - Best: 0.1689, Worst: 0.0998, Average: 0.1200\n",
            "ROC AUC - Best: 0.9946, Worst: 0.9907, Average: 0.9928\n",
            "\n",
            "Results for Bagging:\n",
            "Accuracy - Best: 0.9675, Worst: 0.9494, Average: 0.9598\n",
            "Precision - Best: 0.9685, Worst: 0.9508, Average: 0.9605\n",
            "Recall - Best: 0.9669, Worst: 0.9492, Average: 0.9598\n",
            "F1 Score - Best: 0.9674, Worst: 0.9494, Average: 0.9597\n",
            "Kappa - Best: 0.9349, Worst: 0.8988, Average: 0.9195\n",
            "Training Time - Best: 30.2400, Worst: 21.9132, Average: 23.5419\n",
            "Inference Time - Best: 1.6779, Worst: 0.9550, Average: 1.1342\n",
            "ROC AUC - Best: 0.9934, Worst: 0.9898, Average: 0.9916\n",
            "\n",
            "Results for Boosting:\n",
            "Accuracy - Best: 0.8622, Worst: 0.8411, Average: 0.8544\n",
            "Precision - Best: 0.8623, Worst: 0.8415, Average: 0.8551\n",
            "Recall - Best: 0.8624, Worst: 0.8412, Average: 0.8544\n",
            "F1 Score - Best: 0.8622, Worst: 0.8411, Average: 0.8543\n",
            "Kappa - Best: 0.7245, Worst: 0.6822, Average: 0.7087\n",
            "Training Time - Best: 6.2352, Worst: 4.6987, Average: 5.3782\n",
            "Inference Time - Best: 0.0903, Worst: 0.0546, Average: 0.0646\n",
            "ROC AUC - Best: 0.9462, Worst: 0.9313, Average: 0.9401\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#4-Ensemble:Extra,Rf,XGBoost"
      ],
      "metadata": {
        "id": "xCCWaFZQrj6_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier, VotingClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, cohen_kappa_score, roc_auc_score\n",
        "from xgboost import XGBClassifier\n",
        "import time\n",
        "\n",
        "# Data preparation\n",
        "kf = KFold(n_splits=10, random_state=42, shuffle=True)\n",
        "X_df = pd.DataFrame(X)  # Assuming X is predefined\n",
        "y_df = pd.DataFrame(y)  # Assuming y is predefined\n",
        "\n",
        "# Base models\n",
        "extra_trees = ExtraTreesClassifier(n_estimators=100, random_state=42)\n",
        "random_forest = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "xgboost = XGBClassifier(n_estimators=100, random_state=42, use_label_encoder=False, eval_metric='logloss')\n",
        "\n",
        "# Hard Voting ensemble configuration\n",
        "hard_voting = VotingClassifier(estimators=[('ExtraTrees', extra_trees), ('RF', random_forest), ('XGBoost', xgboost)], voting='hard')\n",
        "\n",
        "# Dictionary to hold results\n",
        "results = {'Hard Voting': []}\n",
        "\n",
        "# Cross-validation\n",
        "for train_index, test_index in kf.split(X_df):\n",
        "    X_train, X_test = X_df.iloc[train_index], X_df.iloc[test_index]\n",
        "    y_train, y_test = y_df.iloc[train_index], y_df.iloc[test_index]\n",
        "\n",
        "    start_train_time = time.time()\n",
        "    hard_voting.fit(X_train, y_train.values.ravel())\n",
        "    train_time = time.time() - start_train_time\n",
        "\n",
        "    start_infer_time = time.time()\n",
        "    predictions = hard_voting.predict(X_test)\n",
        "    infer_time = time.time() - start_infer_time\n",
        "\n",
        "    metrics = {\n",
        "        'Accuracy': accuracy_score(y_test, predictions),\n",
        "        'Precision': precision_score(y_test, predictions, average='macro'),\n",
        "        'Recall': recall_score(y_test, predictions, average='macro'),\n",
        "        'F1 Score': f1_score(y_test, predictions, average='macro'),\n",
        "        'Kappa': cohen_kappa_score(y_test, predictions),\n",
        "        'Training Time': train_time,\n",
        "        'Inference Time': infer_time\n",
        "    }\n",
        "\n",
        "    if hasattr(hard_voting, \"predict_proba\"):\n",
        "        metrics['ROC AUC'] = roc_auc_score(y_test, hard_voting.predict_proba(X_test)[:, 1])\n",
        "\n",
        "    results['Hard Voting'].append(metrics)\n",
        "\n",
        "# Print best, worst, and average results for Hard Voting\n",
        "for key, value in results.items():\n",
        "    print(f\"\\nResults for {key}:\")\n",
        "    for metric in ['Accuracy', 'Precision', 'Recall', 'F1 Score', 'Kappa', 'Training Time', 'Inference Time']:\n",
        "        metric_values = [v[metric] for v in value]\n",
        "        print(f\"{metric} - Best: {max(metric_values):.4f}, Worst: {min(metric_values):.4f}, Average: {np.mean(metric_values):.4f}\")\n",
        "\n",
        "    if any('ROC AUC' in metric for metric in value):\n",
        "        roc_auc_values = [v['ROC AUC'] for v in value if 'ROC AUC' in v]\n",
        "        print(f\"ROC AUC - Best: {max(roc_auc_values):.4f}, Worst: {min(roc_auc_values):.4f}, Average: {np.mean(roc_auc_values):.4f}\")\n"
      ],
      "metadata": {
        "id": "5kIKDfVqhb0p",
        "outputId": "e4957539-0e4f-4548-f4dc-32aa1e4081db",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Results for Hard Voting:\n",
            "Accuracy - Best: 0.9682, Worst: 0.9556, Average: 0.9633\n",
            "Precision - Best: 0.9695, Worst: 0.9567, Average: 0.9639\n",
            "Recall - Best: 0.9674, Worst: 0.9553, Average: 0.9632\n",
            "F1 Score - Best: 0.9681, Worst: 0.9555, Average: 0.9632\n",
            "Kappa - Best: 0.9362, Worst: 0.9111, Average: 0.9265\n",
            "Training Time - Best: 30.4731, Worst: 10.8075, Average: 13.9080\n",
            "Inference Time - Best: 0.2889, Worst: 0.2002, Average: 0.2285\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier, VotingClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, cohen_kappa_score, roc_auc_score\n",
        "from xgboost import XGBClassifier\n",
        "import time\n",
        "\n",
        "# Data preparation\n",
        "kf = KFold(n_splits=10, random_state=42, shuffle=True)\n",
        "X_df = pd.DataFrame(X)  # Assuming X is predefined\n",
        "y_df = pd.DataFrame(y)  # Assuming y is predefined\n",
        "\n",
        "# Base models\n",
        "extra_trees = ExtraTreesClassifier(n_estimators=100, random_state=42)\n",
        "random_forest = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "xgboost = XGBClassifier(n_estimators=100, random_state=42, use_label_encoder=False, eval_metric='logloss')\n",
        "\n",
        "# Soft Voting ensemble configuration\n",
        "soft_voting = VotingClassifier(estimators=[('ExtraTrees', extra_trees), ('RF', random_forest), ('XGBoost', xgboost)], voting='soft')\n",
        "\n",
        "# Dictionary to hold results\n",
        "results = {'Soft Voting': []}\n",
        "\n",
        "# Cross-validation\n",
        "for train_index, test_index in kf.split(X_df):\n",
        "    X_train, X_test = X_df.iloc[train_index], X_df.iloc[test_index]\n",
        "    y_train, y_test = y_df.iloc[train_index], y_df.iloc[test_index]\n",
        "\n",
        "    start_train_time = time.time()\n",
        "    soft_voting.fit(X_train, y_train.values.ravel())\n",
        "    train_time = time.time() - start_train_time\n",
        "\n",
        "    start_infer_time = time.time()\n",
        "    predictions = soft_voting.predict(X_test)\n",
        "    infer_time = time.time() - start_infer_time\n",
        "\n",
        "    metrics = {\n",
        "        'Accuracy': accuracy_score(y_test, predictions),\n",
        "        'Precision': precision_score(y_test, predictions, average='macro'),\n",
        "        'Recall': recall_score(y_test, predictions, average='macro'),\n",
        "        'F1 Score': f1_score(y_test, predictions, average='macro'),\n",
        "        'Kappa': cohen_kappa_score(y_test, predictions),\n",
        "        'Training Time': train_time,\n",
        "        'Inference Time': infer_time\n",
        "    }\n",
        "\n",
        "    if hasattr(soft_voting, \"predict_proba\"):\n",
        "        metrics['ROC AUC'] = roc_auc_score(y_test, soft_voting.predict_proba(X_test)[:, 1])\n",
        "\n",
        "    results['Soft Voting'].append(metrics)\n",
        "\n",
        "# Print best, worst, and average results for Soft Voting\n",
        "for key, value in results.items():\n",
        "    print(f\"\\nResults for {key}:\")\n",
        "    for metric in ['Accuracy', 'Precision', 'Recall', 'F1 Score', 'Kappa', 'Training Time', 'Inference Time']:\n",
        "        metric_values = [v[metric] for v in value]\n",
        "        print(f\"{metric} - Best: {max(metric_values):.4f}, Worst: {min(metric_values):.4f}, Average: {np.mean(metric_values):.4f}\")\n",
        "\n",
        "    if any('ROC AUC' in metric for metric in value):\n",
        "        roc_auc_values = [v['ROC AUC'] for v in value if 'ROC AUC' in v]\n",
        "        print(f\"ROC AUC - Best: {max(roc_auc_values):.4f}, Worst: {min(roc_auc_values):.4f}, Average: {np.mean(roc_auc_values):.4f}\")\n"
      ],
      "metadata": {
        "id": "4O1fXhekjL7H",
        "outputId": "9184d6d5-6eef-4736-da8a-84370f8668e1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Results for Soft Voting:\n",
            "Accuracy - Best: 0.9696, Worst: 0.9573, Average: 0.9648\n",
            "Precision - Best: 0.9708, Worst: 0.9585, Average: 0.9654\n",
            "Recall - Best: 0.9688, Worst: 0.9570, Average: 0.9647\n",
            "F1 Score - Best: 0.9695, Worst: 0.9572, Average: 0.9647\n",
            "Kappa - Best: 0.9390, Worst: 0.9145, Average: 0.9295\n",
            "Training Time - Best: 25.6122, Worst: 11.3138, Average: 17.4647\n",
            "Inference Time - Best: 0.2897, Worst: 0.1895, Average: 0.2457\n",
            "ROC AUC - Best: 0.9964, Worst: 0.9934, Average: 0.9949\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#5.Ensemble:NaiveBayes,RF,Extratrees"
      ],
      "metadata": {
        "id": "el1HCiNEyqmZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier, VotingClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, cohen_kappa_score, roc_auc_score\n",
        "import time\n",
        "\n",
        "# Data preparation\n",
        "kf = KFold(n_splits=10, random_state=42, shuffle=True)\n",
        "X_df = pd.DataFrame(X)  # Assuming X is predefined\n",
        "y_df = pd.DataFrame(y)  # Assuming y is predefined\n",
        "\n",
        "# Base models\n",
        "naive_bayes = GaussianNB()\n",
        "random_forest = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "extra_trees = ExtraTreesClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Hard Voting ensemble configuration\n",
        "hard_voting = VotingClassifier(estimators=[('NaiveBayes', naive_bayes), ('RF', random_forest), ('ExtraTrees', extra_trees)], voting='hard')\n",
        "\n",
        "# Dictionary to hold results\n",
        "results = {'Hard Voting': []}\n",
        "\n",
        "# Cross-validation\n",
        "for train_index, test_index in kf.split(X_df):\n",
        "    X_train, X_test = X_df.iloc[train_index], X_df.iloc[test_index]\n",
        "    y_train, y_test = y_df.iloc[train_index], y_df.iloc[test_index]\n",
        "\n",
        "    start_train_time = time.time()\n",
        "    hard_voting.fit(X_train, y_train.values.ravel())\n",
        "    train_time = time.time() - start_train_time\n",
        "\n",
        "    start_infer_time = time.time()\n",
        "    predictions = hard_voting.predict(X_test)\n",
        "    infer_time = time.time() - start_infer_time\n",
        "\n",
        "    metrics = {\n",
        "        'Accuracy': accuracy_score(y_test, predictions),\n",
        "        'Precision': precision_score(y_test, predictions, average='macro'),\n",
        "        'Recall': recall_score(y_test, predictions, average='macro'),\n",
        "        'F1 Score': f1_score(y_test, predictions, average='macro'),\n",
        "        'Kappa': cohen_kappa_score(y_test, predictions),\n",
        "        'Training Time': train_time,\n",
        "        'Inference Time': infer_time\n",
        "    }\n",
        "\n",
        "    if hasattr(hard_voting, \"predict_proba\"):\n",
        "        metrics['ROC AUC'] = roc_auc_score(y_test, hard_voting.predict_proba(X_test)[:, 1])\n",
        "\n",
        "    results['Hard Voting'].append(metrics)\n",
        "\n",
        "# Print best, worst, and average results for Hard Voting\n",
        "for key, value in results.items():\n",
        "    print(f\"\\nResults for {key}:\")\n",
        "    for metric in ['Accuracy', 'Precision', 'Recall', 'F1 Score', 'Kappa', 'Training Time', 'Inference Time']:\n",
        "        metric_values = [v[metric] for v in value]\n",
        "        print(f\"{metric} - Best: {max(metric_values):.4f}, Worst: {min(metric_values):.4f}, Average: {np.mean(metric_values):.4f}\")\n",
        "\n",
        "    if any('ROC AUC' in metric for metric in value):\n",
        "        roc_auc_values = [v['ROC AUC'] for v in value if 'ROC AUC' in v]\n",
        "        print(f\"ROC AUC - Best: {max(roc_auc_values):.4f}, Worst: {min(roc_auc_values):.4f}, Average: {np.mean(roc_auc_values):.4f}\")\n"
      ],
      "metadata": {
        "id": "o9dno98QnN-k",
        "outputId": "51ba2562-5b35-4c63-9cbc-042158c96beb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Results for Hard Voting:\n",
            "Accuracy - Best: 0.9641, Worst: 0.9494, Average: 0.9566\n",
            "Precision - Best: 0.9663, Worst: 0.9518, Average: 0.9580\n",
            "Recall - Best: 0.9630, Worst: 0.9491, Average: 0.9566\n",
            "F1 Score - Best: 0.9640, Worst: 0.9493, Average: 0.9566\n",
            "Kappa - Best: 0.9280, Worst: 0.8988, Average: 0.9132\n",
            "Training Time - Best: 21.8307, Worst: 10.1082, Average: 13.0387\n",
            "Inference Time - Best: 0.3457, Worst: 0.1750, Average: 0.2222\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier, VotingClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, cohen_kappa_score, roc_auc_score\n",
        "import time\n",
        "\n",
        "# Data preparation\n",
        "kf = KFold(n_splits=10, random_state=42, shuffle=True)\n",
        "X_df = pd.DataFrame(X)  # Assuming X is predefined\n",
        "y_df = pd.DataFrame(y)  # Assuming y is predefined\n",
        "\n",
        "# Base models\n",
        "naive_bayes = GaussianNB()\n",
        "random_forest = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "extra_trees = ExtraTreesClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Soft Voting ensemble configuration\n",
        "soft_voting = VotingClassifier(estimators=[('NaiveBayes', naive_bayes), ('RF', random_forest), ('ExtraTrees', extra_trees)], voting='soft')\n",
        "\n",
        "# Dictionary to hold results\n",
        "results = {'Soft Voting': []}\n",
        "\n",
        "# Cross-validation\n",
        "for train_index, test_index in kf.split(X_df):\n",
        "    X_train, X_test = X_df.iloc[train_index], X_df.iloc[test_index]\n",
        "    y_train, y_test = y_df.iloc[train_index], y_df.iloc[test_index]\n",
        "\n",
        "    start_train_time = time.time()\n",
        "    soft_voting.fit(X_train, y_train.values.ravel())\n",
        "    train_time = time.time() - start_train_time\n",
        "\n",
        "    start_infer_time = time.time()\n",
        "    predictions = soft_voting.predict(X_test)\n",
        "    infer_time = time.time() - start_infer_time\n",
        "\n",
        "    metrics = {\n",
        "        'Accuracy': accuracy_score(y_test, predictions),\n",
        "        'Precision': precision_score(y_test, predictions, average='macro'),\n",
        "        'Recall': recall_score(y_test, predictions, average='macro'),\n",
        "        'F1 Score': f1_score(y_test, predictions, average='macro'),\n",
        "        'Kappa': cohen_kappa_score(y_test, predictions),\n",
        "        'Training Time': train_time,\n",
        "        'Inference Time': infer_time\n",
        "    }\n",
        "\n",
        "    if hasattr(soft_voting, \"predict_proba\"):\n",
        "        metrics['ROC AUC'] = roc_auc_score(y_test, soft_voting.predict_proba(X_test)[:, 1])\n",
        "\n",
        "    results['Soft Voting'].append(metrics)\n",
        "\n",
        "# Print best, worst, and average results for Soft Voting\n",
        "for key, value in results.items():\n",
        "    print(f\"\\nResults for {key}:\")\n",
        "    for metric in ['Accuracy', 'Precision', 'Recall', 'F1 Score', 'Kappa', 'Training Time', 'Inference Time']:\n",
        "        metric_values = [v[metric] for v in value]\n",
        "        print(f\"{metric} - Best: {max(metric_values):.4f}, Worst: {min(metric_values):.4f}, Average: {np.mean(metric_values):.4f}\")\n",
        "\n",
        "    if any('ROC AUC' in metric for metric in value):\n",
        "        roc_auc_values = [v['ROC AUC'] for v in value if 'ROC AUC' in v]\n",
        "        print(f\"ROC AUC - Best: {max(roc_auc_values):.4f}, Worst: {min(roc_auc_values):.4f}, Average: {np.mean(roc_auc_values):.4f}\")\n"
      ],
      "metadata": {
        "id": "S5POlO1enUAj",
        "outputId": "df12c402-7055-467b-99fa-6b8c806d88ab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Results for Soft Voting:\n",
            "Accuracy - Best: 0.9337, Worst: 0.9221, Average: 0.9272\n",
            "Precision - Best: 0.9421, Worst: 0.9290, Average: 0.9342\n",
            "Recall - Best: 0.9313, Worst: 0.9224, Average: 0.9272\n",
            "F1 Score - Best: 0.9330, Worst: 0.9219, Average: 0.9269\n",
            "Kappa - Best: 0.8666, Worst: 0.8446, Average: 0.8544\n",
            "Training Time - Best: 23.5373, Worst: 9.8217, Average: 13.7203\n",
            "Inference Time - Best: 0.8388, Worst: 0.1571, Average: 0.2758\n",
            "ROC AUC - Best: 0.9942, Worst: 0.9909, Average: 0.9923\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#6-Ensemble:MLP,DT,XGB"
      ],
      "metadata": {
        "id": "PHlgdfTm1Ofl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, cohen_kappa_score, roc_auc_score\n",
        "import time\n",
        "\n",
        "# Data preparation\n",
        "kf = KFold(n_splits=10, random_state=42, shuffle=True)\n",
        "X_df = pd.DataFrame(X)  # Assuming X is predefined\n",
        "y_df = pd.DataFrame(y)  # Assuming y is predefined\n",
        "\n",
        "# Base models\n",
        "mlp = MLPClassifier(random_state=42)\n",
        "decision_tree = DecisionTreeClassifier(random_state=42)\n",
        "xgboost = XGBClassifier(n_estimators=100, random_state=42, use_label_encoder=False, eval_metric='logloss')\n",
        "\n",
        "# Hard Voting ensemble configuration\n",
        "hard_voting = VotingClassifier(estimators=[('MLP', mlp), ('DT', decision_tree), ('XGBoost', xgboost)], voting='hard')\n",
        "\n",
        "# Dictionary to hold results\n",
        "results = {'Hard Voting': []}\n",
        "\n",
        "# Cross-validation\n",
        "for train_index, test_index in kf.split(X_df):\n",
        "    X_train, X_test = X_df.iloc[train_index], X_df.iloc[test_index]\n",
        "    y_train, y_test = y_df.iloc[train_index], y_df.iloc[test_index]\n",
        "\n",
        "    start_train_time = time.time()\n",
        "    hard_voting.fit(X_train, y_train.values.ravel())\n",
        "    train_time = time.time() - start_train_time\n",
        "\n",
        "    start_infer_time = time.time()\n",
        "    predictions = hard_voting.predict(X_test)\n",
        "    infer_time = time.time() - start_infer_time\n",
        "\n",
        "    metrics = {\n",
        "        'Accuracy': accuracy_score(y_test, predictions),\n",
        "        'Precision': precision_score(y_test, predictions, average='macro'),\n",
        "        'Recall': recall_score(y_test, predictions, average='macro'),\n",
        "        'F1 Score': f1_score(y_test, predictions, average='macro'),\n",
        "        'Kappa': cohen_kappa_score(y_test, predictions),\n",
        "        'Training Time': train_time,\n",
        "        'Inference Time': infer_time\n",
        "    }\n",
        "\n",
        "    if hasattr(hard_voting, \"predict_proba\"):\n",
        "        metrics['ROC AUC'] = roc_auc_score(y_test, hard_voting.predict_proba(X_test)[:, 1])\n",
        "\n",
        "    results['Hard Voting'].append(metrics)\n",
        "\n",
        "# Print best, worst, and average results for Hard Voting\n",
        "for key, value in results.items():\n",
        "    print(f\"\\nResults for {key}:\")\n",
        "    for metric in ['Accuracy', 'Precision', 'Recall', 'F1 Score', 'Kappa', 'Training Time', 'Inference Time']:\n",
        "        metric_values = [v[metric] for v in value]\n",
        "        print(f\"{metric} - Best: {max(metric_values):.4f}, Worst: {min(metric_values):.4f}, Average: {np.mean(metric_values):.4f}\")\n",
        "\n",
        "    if any('ROC AUC' in metric for metric in value):\n",
        "        roc_auc_values = [v['ROC AUC'] for v in value if 'ROC AUC' in v]\n",
        "        print(f\"ROC AUC - Best: {max(roc_auc_values):.4f}, Worst: {min(roc_auc_values):.4f}, Average: {np.mean(roc_auc_values):.4f}\")\n"
      ],
      "metadata": {
        "id": "fwd3V1kToX-Z",
        "outputId": "81cdf65b-05a1-4c17-a1c3-2f0867b8933b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Results for Hard Voting:\n",
            "Accuracy - Best: 0.9532, Worst: 0.9381, Average: 0.9465\n",
            "Precision - Best: 0.9556, Worst: 0.9418, Average: 0.9488\n",
            "Recall - Best: 0.9526, Worst: 0.9377, Average: 0.9464\n",
            "F1 Score - Best: 0.9531, Worst: 0.9380, Average: 0.9464\n",
            "Kappa - Best: 0.9062, Worst: 0.8762, Average: 0.8929\n",
            "Training Time - Best: 95.2529, Worst: 36.1461, Average: 56.7432\n",
            "Inference Time - Best: 0.1203, Worst: 0.0453, Average: 0.0627\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, cohen_kappa_score, roc_auc_score\n",
        "import time\n",
        "\n",
        "# Data preparation\n",
        "kf = KFold(n_splits=10, random_state=42, shuffle=True)\n",
        "X_df = pd.DataFrame(X)  # Assuming X is predefined\n",
        "y_df = pd.DataFrame(y)  # Assuming y is predefined\n",
        "\n",
        "# Base models\n",
        "mlp = MLPClassifier(random_state=42)\n",
        "decision_tree = DecisionTreeClassifier(random_state=42)\n",
        "xgboost = XGBClassifier(n_estimators=100, random_state=42, use_label_encoder=False, eval_metric='logloss')\n",
        "\n",
        "# Soft Voting ensemble configuration\n",
        "soft_voting = VotingClassifier(estimators=[('MLP', mlp), ('DT', decision_tree), ('XGBoost', xgboost)], voting='soft')\n",
        "\n",
        "# Dictionary to hold results\n",
        "results = {'Soft Voting': []}\n",
        "\n",
        "# Cross-validation\n",
        "for train_index, test_index in kf.split(X_df):\n",
        "    X_train, X_test = X_df.iloc[train_index], X_df.iloc[test_index]\n",
        "    y_train, y_test = y_df.iloc[train_index], y_df.iloc[test_index]\n",
        "\n",
        "    start_train_time = time.time()\n",
        "    soft_voting.fit(X_train, y_train.values.ravel())\n",
        "    train_time = time.time() - start_train_time\n",
        "\n",
        "    start_infer_time = time.time()\n",
        "    predictions = soft_voting.predict(X_test)\n",
        "    infer_time = time.time() - start_infer_time\n",
        "\n",
        "    metrics = {\n",
        "        'Accuracy': accuracy_score(y_test, predictions),\n",
        "        'Precision': precision_score(y_test, predictions, average='macro'),\n",
        "        'Recall': recall_score(y_test, predictions, average='macro'),\n",
        "        'F1 Score': f1_score(y_test, predictions, average='macro'),\n",
        "        'Kappa': cohen_kappa_score(y_test, predictions),\n",
        "        'Training Time': train_time,\n",
        "        'Inference Time': infer_time\n",
        "    }\n",
        "\n",
        "    if hasattr(soft_voting, \"predict_proba\"):\n",
        "        metrics['ROC AUC'] = roc_auc_score(y_test, soft_voting.predict_proba(X_test)[:, 1])\n",
        "\n",
        "    results['Soft Voting'].append(metrics)\n",
        "\n",
        "# Print best, worst, and average results for Soft Voting\n",
        "for key, value in results.items():\n",
        "    print(f\"\\nResults for {key}:\")\n",
        "    for metric in ['Accuracy', 'Precision', 'Recall', 'F1 Score', 'Kappa', 'Training Time', 'Inference Time']:\n",
        "        metric_values = [v[metric] for v in value]\n",
        "        print(f\"{metric} - Best: {max(metric_values):.4f}, Worst: {min(metric_values):.4f}, Average: {np.mean(metric_values):.4f}\")\n",
        "\n",
        "    if any('ROC AUC' in metric for metric in value):\n",
        "        roc_auc_values = [v['ROC AUC'] for v in value if 'ROC AUC' in v]\n",
        "        print(f\"ROC AUC - Best: {max(roc_auc_values):.4f}, Worst: {min(roc_auc_values):.4f}, Average: {np.mean(roc_auc_values):.4f}\")\n"
      ],
      "metadata": {
        "id": "tEMYo9H2oos8",
        "outputId": "c4b587b9-ddd5-4317-da1e-140612a99782",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Results for Soft Voting:\n",
            "Accuracy - Best: 0.9566, Worst: 0.9470, Average: 0.9519\n",
            "Precision - Best: 0.9592, Worst: 0.9496, Average: 0.9535\n",
            "Recall - Best: 0.9554, Worst: 0.9467, Average: 0.9518\n",
            "F1 Score - Best: 0.9564, Worst: 0.9469, Average: 0.9518\n",
            "Kappa - Best: 0.9128, Worst: 0.8940, Average: 0.9037\n",
            "Training Time - Best: 46.5124, Worst: 35.7839, Average: 39.4984\n",
            "Inference Time - Best: 0.0539, Worst: 0.0181, Average: 0.0311\n",
            "ROC AUC - Best: 0.9910, Worst: 0.9869, Average: 0.9885\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#7.Ensemble:DT,Adaboost"
      ],
      "metadata": {
        "id": "ZRjhY7e61W1N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.ensemble import VotingClassifier, AdaBoostClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, cohen_kappa_score, roc_auc_score\n",
        "import time\n",
        "\n",
        "# Data preparation\n",
        "kf = KFold(n_splits=10, random_state=42, shuffle=True)\n",
        "X_df = pd.DataFrame(X)  # Assuming X is predefined\n",
        "y_df = pd.DataFrame(y)  # Assuming y is predefined\n",
        "\n",
        "# Base models\n",
        "decision_tree = DecisionTreeClassifier(random_state=42)\n",
        "adaboost = AdaBoostClassifier(n_estimators=100, random_state=42, base_estimator=DecisionTreeClassifier(random_state=42))\n",
        "\n",
        "# Hard Voting ensemble configuration\n",
        "hard_voting = VotingClassifier(estimators=[('DT', decision_tree), ('AdaBoost', adaboost)], voting='hard')\n",
        "\n",
        "# Dictionary to hold results\n",
        "results = {'Hard Voting': []}\n",
        "\n",
        "# Cross-validation\n",
        "for train_index, test_index in kf.split(X_df):\n",
        "    X_train, X_test = X_df.iloc[train_index], X_df.iloc[test_index]\n",
        "    y_train, y_test = y_df.iloc[train_index], y_df.iloc[test_index]\n",
        "\n",
        "    start_train_time = time.time()\n",
        "    hard_voting.fit(X_train, y_train.values.ravel())\n",
        "    train_time = time.time() - start_train_time\n",
        "\n",
        "    start_infer_time = time.time()\n",
        "    predictions = hard_voting.predict(X_test)\n",
        "    infer_time = time.time() - start_infer_time\n",
        "\n",
        "    metrics = {\n",
        "        'Accuracy': accuracy_score(y_test, predictions),\n",
        "        'Precision': precision_score(y_test, predictions, average='macro'),\n",
        "        'Recall': recall_score(y_test, predictions, average='macro'),\n",
        "        'F1 Score': f1_score(y_test, predictions, average='macro'),\n",
        "        'Kappa': cohen_kappa_score(y_test, predictions),\n",
        "        'Training Time': train_time,\n",
        "        'Inference Time': infer_time\n",
        "    }\n",
        "\n",
        "    if hasattr(hard_voting, \"predict_proba\"):\n",
        "        metrics['ROC AUC'] = roc_auc_score(y_test, hard_voting.predict_proba(X_test)[:, 1])\n",
        "\n",
        "    results['Hard Voting'].append(metrics)\n",
        "\n",
        "# Print best, worst, and average results for Hard Voting\n",
        "for key, value in results.items():\n",
        "    print(f\"\\nResults for {key}:\")\n",
        "    for metric in ['Accuracy', 'Precision', 'Recall', 'F1 Score', 'Kappa', 'Training Time', 'Inference Time']:\n",
        "        metric_values = [v[metric] for v in value]\n",
        "        print(f\"{metric} - Best: {max(metric_values):.4f}, Worst: {min(metric_values):.4f}, Average: {np.mean(metric_values):.4f}\")\n",
        "\n",
        "    if any('ROC AUC' in metric for metric in value):\n",
        "        roc_auc_values = [v['ROC AUC'] for v in value if 'ROC AUC' in v]\n",
        "        print(f\"ROC AUC - Best: {max(roc_auc_values):.4f}, Worst: {min(roc_auc_values):.4f}, Average: {np.mean(roc_auc_values):.4f}\")\n"
      ],
      "metadata": {
        "id": "xr7Erfuyo94Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9c43b85-7ddd-47eb-c6aa-1baafffdccd7"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Results for Hard Voting:\n",
            "Accuracy - Best: 0.9627, Worst: 0.9552, Average: 0.9594\n",
            "Precision - Best: 0.9627, Worst: 0.9554, Average: 0.9596\n",
            "Recall - Best: 0.9628, Worst: 0.9551, Average: 0.9594\n",
            "F1 Score - Best: 0.9627, Worst: 0.9552, Average: 0.9594\n",
            "Kappa - Best: 0.9255, Worst: 0.9104, Average: 0.9188\n",
            "Training Time - Best: 62.7197, Worst: 33.5996, Average: 45.8676\n",
            "Inference Time - Best: 0.3451, Worst: 0.0955, Average: 0.1654\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.ensemble import VotingClassifier, AdaBoostClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, cohen_kappa_score, roc_auc_score\n",
        "import time\n",
        "\n",
        "# Data preparation\n",
        "kf = KFold(n_splits=10, random_state=42, shuffle=True)\n",
        "X_df = pd.DataFrame(X)  # Assuming X is predefined\n",
        "y_df = pd.DataFrame(y)  # Assuming y is predefined\n",
        "\n",
        "# Base models\n",
        "decision_tree = DecisionTreeClassifier(random_state=42)\n",
        "adaboost = AdaBoostClassifier(n_estimators=100, random_state=42, base_estimator=DecisionTreeClassifier(random_state=42))\n",
        "\n",
        "# Soft Voting ensemble configuration\n",
        "soft_voting = VotingClassifier(estimators=[('DT', decision_tree), ('AdaBoost', adaboost)], voting='soft')\n",
        "\n",
        "# Dictionary to hold results\n",
        "results = {'Soft Voting': []}\n",
        "\n",
        "# Cross-validation\n",
        "for train_index, test_index in kf.split(X_df):\n",
        "    X_train, X_test = X_df.iloc[train_index], X_df.iloc[test_index]\n",
        "    y_train, y_test = y_df.iloc[train_index], y_df.iloc[test_index]\n",
        "\n",
        "    start_train_time = time.time()\n",
        "    soft_voting.fit(X_train, y_train.values.ravel())\n",
        "    train_time = time.time() - start_train_time\n",
        "\n",
        "    start_infer_time = time.time()\n",
        "    predictions = soft_voting.predict(X_test)\n",
        "    infer_time = time.time() - start_infer_time\n",
        "\n",
        "    metrics = {\n",
        "        'Accuracy': accuracy_score(y_test, predictions),\n",
        "        'Precision': precision_score(y_test, predictions, average='macro'),\n",
        "        'Recall': recall_score(y_test, predictions, average='macro'),\n",
        "        'F1 Score': f1_score(y_test, predictions, average='macro'),\n",
        "        'Kappa': cohen_kappa_score(y_test, predictions),\n",
        "        'Training Time': train_time,\n",
        "        'Inference Time': infer_time\n",
        "    }\n",
        "\n",
        "    if hasattr(soft_voting, \"predict_proba\"):\n",
        "        metrics['ROC AUC'] = roc_auc_score(y_test, soft_voting.predict_proba(X_test)[:, 1])\n",
        "\n",
        "    results['Soft Voting'].append(metrics)\n",
        "\n",
        "# Print best, worst, and average results for Soft Voting\n",
        "for key, value in results.items():\n",
        "    print(f\"\\nResults for {key}:\")\n",
        "    for metric in ['Accuracy', 'Precision', 'Recall', 'F1 Score', 'Kappa', 'Training Time', 'Inference Time']:\n",
        "        metric_values = [v[metric] for v in value]\n",
        "        print(f\"{metric} - Best: {max(metric_values):.4f}, Worst: {min(metric_values):.4f}, Average: {np.mean(metric_values):.4f}\")\n",
        "\n",
        "    if any('ROC AUC' in metric for metric in value):\n",
        "        roc_auc_values = [v['ROC AUC'] for v in value if 'ROC AUC' in v]\n",
        "        print(f\"ROC AUC - Best: {max(roc_auc_values):.4f}, Worst: {min(roc_auc_values):.4f}, Average: {np.mean(roc_auc_values):.4f}\")\n"
      ],
      "metadata": {
        "id": "wk46bq5so-oC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78cd5465-cf55-4896-fc7d-abd19dbdbb7e"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Results for Soft Voting:\n",
            "Accuracy - Best: 0.9477, Worst: 0.9388, Average: 0.9440\n",
            "Precision - Best: 0.9501, Worst: 0.9411, Average: 0.9457\n",
            "Recall - Best: 0.9465, Worst: 0.9385, Average: 0.9440\n",
            "F1 Score - Best: 0.9475, Worst: 0.9387, Average: 0.9439\n",
            "Kappa - Best: 0.8950, Worst: 0.8776, Average: 0.8879\n",
            "Training Time - Best: 62.3020, Worst: 28.5478, Average: 43.1898\n",
            "Inference Time - Best: 0.1394, Worst: 0.0747, Average: 0.1058\n",
            "ROC AUC - Best: 0.9873, Worst: 0.9781, Average: 0.9834\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#8.Ensemble: ANN,Adaboost,DT"
      ],
      "metadata": {
        "id": "Wj7InmH6339o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.ensemble import VotingClassifier, AdaBoostClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, cohen_kappa_score, roc_auc_score\n",
        "import time\n",
        "\n",
        "# Data preparation\n",
        "kf = KFold(n_splits=10, random_state=42, shuffle=True)\n",
        "X_df = pd.DataFrame(X)  # Assuming X is predefined\n",
        "y_df = pd.DataFrame(y)  # Assuming y is predefined\n",
        "\n",
        "# Base models\n",
        "ann = MLPClassifier(random_state=42)\n",
        "adaboost = AdaBoostClassifier(n_estimators=100, random_state=42)\n",
        "decision_tree = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "# Hard Voting ensemble configuration\n",
        "hard_voting = VotingClassifier(estimators=[('ANN', ann), ('AdaBoost', adaboost), ('DT', decision_tree)], voting='hard')\n",
        "\n",
        "# Dictionary to hold results\n",
        "results = {'Hard Voting': []}\n",
        "\n",
        "# Cross-validation\n",
        "for train_index, test_index in kf.split(X_df):\n",
        "    X_train, X_test = X_df.iloc[train_index], X_df.iloc[test_index]\n",
        "    y_train, y_test = y_df.iloc[train_index], y_df.iloc[test_index]\n",
        "\n",
        "    start_train_time = time.time()\n",
        "    hard_voting.fit(X_train, y_train.values.ravel())\n",
        "    train_time = time.time() - start_train_time\n",
        "\n",
        "    start_infer_time = time.time()\n",
        "    predictions = hard_voting.predict(X_test)\n",
        "    infer_time = time.time() - start_infer_time\n",
        "\n",
        "    metrics = {\n",
        "        'Accuracy': accuracy_score(y_test, predictions),\n",
        "        'Precision': precision_score(y_test, predictions, average='macro'),\n",
        "        'Recall': recall_score(y_test, predictions, average='macro'),\n",
        "        'F1 Score': f1_score(y_test, predictions, average='macro'),\n",
        "        'Kappa': cohen_kappa_score(y_test, predictions),\n",
        "        'Training Time': train_time,\n",
        "        'Inference Time': infer_time\n",
        "    }\n",
        "\n",
        "    if hasattr(hard_voting, \"predict_proba\"):\n",
        "        metrics['ROC AUC'] = roc_auc_score(y_test, hard_voting.predict_proba(X_test)[:, 1])\n",
        "\n",
        "    results['Hard Voting'].append(metrics)\n",
        "\n",
        "# Print best, worst, and average results for Hard Voting\n",
        "for key, value in results.items():\n",
        "    print(f\"\\nResults for {key}:\")\n",
        "    for metric in ['Accuracy', 'Precision', 'Recall', 'F1 Score', 'Kappa', 'Training Time', 'Inference Time']:\n",
        "        metric_values = [v[metric] for v in value]\n",
        "        print(f\"{metric} - Best: {max(metric_values):.4f}, Worst: {min(metric_values):.4f}, Average: {np.mean(metric_values):.4f}\")\n",
        "\n",
        "    if any('ROC AUC' in metric for metric in value):\n",
        "        roc_auc_values = [v['ROC AUC'] for v in value if 'ROC AUC' in v]\n",
        "        print(f\"ROC AUC - Best: {max(roc_auc_values):.4f}, Worst: {min(roc_auc_values):.4f}, Average: {np.mean(roc_auc_values):.4f}\")\n"
      ],
      "metadata": {
        "id": "rmaAaogmo-_M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41d862a2-00e1-4cf1-f1c0-7167f1c23862"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Results for Hard Voting:\n",
            "Accuracy - Best: 0.9056, Worst: 0.8885, Average: 0.8972\n",
            "Precision - Best: 0.9115, Worst: 0.8932, Average: 0.9016\n",
            "Recall - Best: 0.9053, Worst: 0.8883, Average: 0.8972\n",
            "F1 Score - Best: 0.9053, Worst: 0.8882, Average: 0.8969\n",
            "Kappa - Best: 0.8112, Worst: 0.7770, Average: 0.7944\n",
            "Training Time - Best: 64.4295, Worst: 44.5354, Average: 51.6776\n",
            "Inference Time - Best: 0.1985, Worst: 0.1167, Average: 0.1422\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.ensemble import VotingClassifier, AdaBoostClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, cohen_kappa_score, roc_auc_score\n",
        "import time\n",
        "\n",
        "# Data preparation\n",
        "kf = KFold(n_splits=10, random_state=42, shuffle=True)\n",
        "X_df = pd.DataFrame(X)  # Assuming X is predefined\n",
        "y_df = pd.DataFrame(y)  # Assuming y is predefined\n",
        "\n",
        "# Base models\n",
        "ann = MLPClassifier(random_state=42)\n",
        "adaboost = AdaBoostClassifier(n_estimators=100, random_state=42)\n",
        "decision_tree = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "# Soft Voting ensemble configuration\n",
        "soft_voting = VotingClassifier(estimators=[('ANN', ann), ('AdaBoost', adaboost), ('DT', decision_tree)], voting='soft')\n",
        "\n",
        "# Dictionary to hold results\n",
        "results = {'Soft Voting': []}\n",
        "\n",
        "# Cross-validation\n",
        "for train_index, test_index in kf.split(X_df):\n",
        "    X_train, X_test = X_df.iloc[train_index], X_df.iloc[test_index]\n",
        "    y_train, y_test = y_df.iloc[train_index], y_df.iloc[test_index]\n",
        "\n",
        "    start_train_time = time.time()\n",
        "    soft_voting.fit(X_train, y_train.values.ravel())\n",
        "    train_time = time.time() - start_train_time\n",
        "\n",
        "    start_infer_time = time.time()\n",
        "    predictions = soft_voting.predict(X_test)\n",
        "    infer_time = time.time() - start_infer_time\n",
        "\n",
        "    metrics = {\n",
        "        'Accuracy': accuracy_score(y_test, predictions),\n",
        "        'Precision': precision_score(y_test, predictions, average='macro'),\n",
        "        'Recall': recall_score(y_test, predictions, average='macro'),\n",
        "        'F1 Score': f1_score(y_test, predictions, average='macro'),\n",
        "        'Kappa': cohen_kappa_score(y_test, predictions),\n",
        "        'Training Time': train_time,\n",
        "        'Inference Time': infer_time\n",
        "    }\n",
        "\n",
        "    if hasattr(soft_voting, \"predict_proba\"):\n",
        "        metrics['ROC AUC'] = roc_auc_score(y_test, soft_voting.predict_proba(X_test)[:, 1])\n",
        "\n",
        "    results['Soft Voting'].append(metrics)\n",
        "\n",
        "# Print best, worst, and average results for Soft Voting\n",
        "for key, value in results.items():\n",
        "    print(f\"\\nResults for {key}:\")\n",
        "    for metric in ['Accuracy', 'Precision', 'Recall', 'F1 Score', 'Kappa', 'Training Time', 'Inference Time']:\n",
        "        metric_values = [v[metric] for v in value]\n",
        "        print(f\"{metric} - Best: {max(metric_values):.4f}, Worst: {min(metric_values):.4f}, Average: {np.mean(metric_values):.4f}\")\n",
        "\n",
        "    if any('ROC AUC' in metric for metric in value):\n",
        "        roc_auc_values = [v['ROC AUC'] for v in value if 'ROC AUC' in v]\n",
        "        print(f\"ROC AUC - Best: {max(roc_auc_values):.4f}, Worst: {min(roc_auc_values):.4f}, Average: {np.mean(roc_auc_values):.4f}\")\n"
      ],
      "metadata": {
        "id": "1z18DN2Ho_Ig",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d04fa208-7ec8-4160-a2ae-713540308c47"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Results for Soft Voting:\n",
            "Accuracy - Best: 0.9480, Worst: 0.9388, Average: 0.9444\n",
            "Precision - Best: 0.9505, Worst: 0.9410, Average: 0.9461\n",
            "Recall - Best: 0.9472, Worst: 0.9385, Average: 0.9444\n",
            "F1 Score - Best: 0.9478, Worst: 0.9387, Average: 0.9443\n",
            "Kappa - Best: 0.8957, Worst: 0.8776, Average: 0.8887\n",
            "Training Time - Best: 46.8390, Worst: 43.3636, Average: 45.1191\n",
            "Inference Time - Best: 0.1765, Worst: 0.0854, Average: 0.1093\n",
            "ROC AUC - Best: 0.9797, Worst: 0.9759, Average: 0.9774\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "8C0gi-ouCuyy",
        "U_LiaLFyCz2Y",
        "4f8O4rioDCxX",
        "NDFnMS8EDnPv",
        "Nh6d23_pMt15",
        "drD5yBy_dqDN",
        "CgFOGBDkqV17",
        "B4gM0qjjP4uA",
        "PGhYYjDsPtu9",
        "fat2Y4lHted_",
        "CO3St7wZTctK",
        "2iafVolEVEH_",
        "5iE19hDDVhO5",
        "F-5HOOddZ-T-",
        "LMA8BOo4hZJx",
        "5XumebpPlume",
        "W6T-6L9qpPI7",
        "xCCWaFZQrj6_",
        "el1HCiNEyqmZ",
        "PHlgdfTm1Ofl",
        "Wj7InmH6339o"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}